<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[深入分析ConcurrentHashMap]]></title>
      <url>%2F20170503%2Fjava%2FconcurrentHashMap%2F</url>
      <content type="text"><![CDATA[HashMap的问题HashMap是不支持并发操作的，多线程情况下HashMap可能会导致死循环的发生，导致CPU占用率达到100%。 Hash表的数据结构HashMap通常会用一个指针数组（假设为table[]）来做分散所有的key，当一个key被加入时，会通过Hash算法通过key算出这个数组的下标i，然后就把这个插到table[i]中，如果有两个不同的key被算在了同一个i，那么就叫冲突，又叫碰撞，这样会在table[i]上形成一个链表。如果table[] 大小很小，那么要放入更多的元素的时候，产生的碰撞就会非常频繁，这样会影响Hash表的性能。所以，hash表的容量非常重要，如果有元素要插入时候，如果超过了设定的threshold，那么就必须增大hash表的大小，hash表的每个元素就必须重新被计算一边，也就是rehash。 HashMap的源码12345678910111213141516171819202122232425public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); //计算Hash值 int hash = hash(key); int i = indexFor(hash, table.length); //如果存在值，替换旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; //增加节点 addEntry(hash, key, value, i); return null;&#125; 上面代码是HashMap进行put一个元素时候的源码。 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; //如果大小大于现在的threshold时候，需要resize if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 在增加节点时候会判断是否需要rehash操作。 1234567891011121314 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; //新建一个Hash Table Entry[] newTable = new Entry[newCapacity]; //吧旧oldtable 迁移到新的newTable上 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; resize源码会新建个更大的hash表 12345678910111213141516void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 从OldTable里摘一个元素出来，然后放到NewTable中 for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 迁移源代码 正常ReHash过程就像代码中一样，新建一个新的table容量比oldtale要大，然后将oldtable中元素迁移到newtable中，在单线程下这样没什么问题。 并发下的Rehash假设有两个线程，当第一个线程执行到1Entry&lt;K, V&gt; next = e.next; 时候被挂起。1234假设有三个值， &lt;3,a&gt;,&lt;7,b&gt;,&lt;5,c&gt;,HashMap的初始大小是2 ______ e next|__0___| _______ _______ _______ |__1___| ---&gt; |_&lt;3,a&gt;_| -----&gt; |_&lt;7,b&gt;_| -----&gt; |_&lt;5,c&gt;_| 那么现在线程1如下：12345 ______ |__0___| |__1___| |__2___| |__3___| 那么线程2开始rehash：123456 ______ |__0___| _______|__1___| ----------&gt; |_&lt;5,c&gt;_| ---------&gt; null |__2___| _______ _______ |__3___| ---&gt; |_&lt;7,b&gt;_| -----&gt; |_&lt;3,a&gt;_| ----&gt; null next e 那么如果现在线程1被调度开始执行：12newTable[i] = e;e = next; 先是执行 newTalbe[i] = e; 然后是e = next，导致了e指向了key(7)， 而下一次循环的next = e.next导致了next指向了key(3)123456 ______ |__0___| _______|__1___| ----------&gt; |_&lt;5,c&gt;_| ---------&gt; null |__2___| _______ _______ |__3___| ---&gt; |_&lt;7,b&gt;_| -----&gt; |_&lt;3,a&gt;_| ----&gt; null e next 这样就会导致123456线程1 ______ |__0___| __________________ |__1___| | | |__2___| ___|___ ____|__ |__3___| ---&gt; |_&lt;3,a&gt;_| -----&gt; |_&lt;7,b&gt;_| ----&gt; null 产生循环链表，导致死循环。 concurrentHashMap原理concurrentHashMap采用锁分段技术：假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 HashEntry源码:12345static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; volatile关键字保证了多线程读取的时候一定是最新值。 ConcurrentHashMap包含一个Segment数组,每个Segment包含一个HashEntry数组,当修改HashEntry数组采用开链法处理冲突,所以它的每个HashEntry元素又是链表结构的元素。 基本操作源码分析构造方法:1234567891011121314151617181920212223242526272829public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; //1 int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; //2 &#125; this.segmentShift = 32 - sshift; //3 this.segmentMask = ssize - 1; //4 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]);//5 Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; //6 UNSAFE.putOrderedObject(ss, SBASE, s0); this.segments = ss;&#125; 整个初始化是通过参数initialCapacity(初始容量)，loadFactor(增长因子)和concurrencyLevel(并发等级)来初始化segmentShift（段偏移量）、segmentMask（段掩码）和segment数组。 注释1: 最大的并发等级不能超过MAX_SEGMENTS 1&lt;&lt;16(也就是1的二进制向左移16位,65535) 注释2: 如果你传入的是15 就是向上取2的4次方倍 也就是16. 注释3和4: segmentShift和segmentMask在定位segment使用，segmentShift = 32 - ssize向左移位的次数，segmentMask = ssize - 1。ssize的最大长度是65536，对应的 segmentShift最大值为16，segmentMask最大值是65535，对应的二进制16位全为1； 注释5和6: 初始化segment 初始化每个segment的HashEntry长度； 创建segment数组和segment[0]。 HashEntry长度cap同样也是2的N次方，默认情况，ssize = 16，initialCapacity = 16，loadFactor = 0.75f，那么cap = 1，threshold = (int) cap * loadFactor = 0。 get操作1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; HashEntry&lt;K,V&gt;[] tab; int h = hash(key); //1 long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; //2 (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; 注释1: 根据key计算hash值 注释2: 根据计算出的hash值定位segment 如果segment不为null segment.table也不为null 跳转进里面的循环 里面的一大段东西 大致讲的就是通过hash值定位segment中对应的HashEntry 遍历HashEntry,如果key存在,返回key对应的value 如果不存在则返回null put操作1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); return s.put(key, hash, value, false);&#125; 判断值是否为null 计算hash值 定位segment 如果不存在，则创建 调用segment的put方法 还有一个putifAbsent的方法 ,唯一的不同就是最后的false变为了true再来看看Segment的put方法12345678910111213141516171819202122232425262728293031323334353637383940414243final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); //1 V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); //2 for (HashEntry&lt;K,V&gt; e = first;;) &#123; //3 if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 注释1: 获取锁 ，保证线程安全 注释2:定位到具体的HashEntry 注释3: 遍历HashEntry链表,如果key已存在 再判断传入的onlyIfAbsent的值 ,再决定是否覆盖旧值. 最后释放锁,返回旧值. 再说明一下put 和 putifAbsent的用法 这两个方法本身是线程安全的,但是要看你的用法是否恰当 例子:12345678910private static ConcurrentHashMap&lt;String,AtomicInteger&gt; map = new ConcurrentHashMap&lt;&gt;();public static void putInTo(String key) &#123; AtomicInteger obj = map.get(key); if(obj == null)&#123; map.put(key, new AtomicInteger(0)); &#125;else&#123; obj.incrementAndGet(); map.put(key, obj); &#125;&#125; 这段代码可以用最开始提供的测试代码进行测试，会发现如果多个线程调用putInTo方法 最后值会确定不了,每一次都是不一样。 就算是保证原子性的AtomicInteger 也会有误差,可能误差比较小罢了。这个误差的出现就会出现在前几次的操作。 原因: 多个线程同时进入putInTo 比如线程1已经把不存在的键值对存入,而线程2还没完成操作 再继续存入key相同的键值对,从而覆盖了前面存入的数据,导致数据丢失。 这段代码就能保证线程安全 而不用通过synchronized关键字来锁定方法12345678910111213private static ConcurrentMap&lt;String, AtomicLong&gt; wordCounts = newConcurrentHashMap&lt;&gt;(); public static long increase(String word) &#123; AtomicLong number = wordCounts.get(word); if(number == null) &#123; AtomicLong newNumber = newAtomicLong(0); number = wordCounts.putIfAbsent(word, newNumber); if(number == null) &#123; number = newNumber; &#125; &#125; return number.incrementAndGet(); &#125; 获取size12345678910111213141516171819202122232425262728293031323334353637public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; long sum; long last = 0L; int retries = -1; try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; //1 for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; //2 int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 注释1 : RETRIES_BEFORE_LOCK为不变常量2 尝试两次不锁住Segment的方式来统计每个Segment的大小,如果在统计的过程中Segment的count发生变化,这时候再加锁统计Segment的count]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解volatile]]></title>
      <url>%2F20170502%2Fjava%2Fvolatile%2F</url>
      <content type="text"><![CDATA[java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 VolatileVolatile变量具有synchronized的可见性特性，但是不具备原子性。线程可以自动发现volatile变量的最新值，volatile可以用于线程安全，但是只能作用于很有限的一组用例：多个变量之间或者某个变量的当前值与修改后值之间没有约束。 正确使用volatile变量的条件如果说要想使用volatile变量来替代锁，保证线程安全，必须满足一下两个条件： 该变量的写操作不依赖当前值 该变量没有包含在具有其他变量的不变式中 大多数的编程情况都于这两个条件其中之一冲突，所以计数器、互斥锁或任何具有多个变量相关的不定式不能单独用volatile解决。 使用volatile和不用volatile的一个例子jdk版本：jdk1.7.0_412345678910111213141516171819202122232425262728293031323334package com.fk.Thread;/** * Created by fengkai on 02/05/17. */public class VolatileTest &#123; private static boolean flag ; public static void main(String[] args) throws InterruptedException &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; if (flag == !flag) &#123; System.out.println(&quot;end !&quot;); System.exit(1); &#125; &#125; &#125; &#125;).start(); Thread.sleep(1); new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; flag = !flag; &#125; &#125; &#125;).start(); &#125;&#125; 运行后程序会进入死循环，一直运行。 在当前的Java内存模型下，线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 12345678910111213141516171819202122232425262728293031323334package com.fk.Thread;/** * Created by fengkai on 02/05/17. */public class VolatileTest &#123; private static volatile boolean flag ; public static void main(String[] args) throws InterruptedException &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; if (flag == !flag) &#123; System.out.println(&quot;end !&quot;); System.exit(1); &#125; &#125; &#125; &#125;).start(); Thread.sleep(1); new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; flag = !flag; &#125; &#125; &#125;).start(); &#125;&#125; 程序输出end，然后马上退出。 把该变量声明为volatile（不稳定的），这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。 正确使用volatile的模式状态标志也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 1234567891011volatile boolean shutdownRequested;...public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 这样使用volatiile简化了编码。这种类型标记通常只有一个状态转换，然后程序停止。 用于一次安全的发布缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原语值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。（这就是造成著名的双重检查锁定（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象）。实现安全发布对象的一种技术就是将对象引用定义为 volatile 类型。下面一个示例，其中后台线程在启动阶段从数据库加载一些数据。其他代码在能够利用这些数据时，在使用之前将检查这些数据是否曾经发布过。12345678910111213141516171819public class BackgroundFloobleLoader &#123; public volatile Flooble theFlooble; public void initInBackground() &#123; // do lots of stuff theFlooble = new Flooble(); // this is the only write to theFlooble &#125;&#125;public class SomeOtherClass &#123; public void doWork() &#123; while (true) &#123; // do some stuff... // use the Flooble, but only if it is ready if (floobleLoader.theFlooble != null) doSomething(floobleLoader.theFlooble); &#125; &#125;&#125; 如果 theFlooble 引用不是 volatile 类型，doWork() 中的代码在解除对 theFlooble 的引用时，将会得到一个不完全构造的 Flooble。该模式的一个必要条件是：被发布的对象必须是线程安全的，或者是有效的不可变对象（有效不可变意味着对象的状态在发布之后永远不会被修改）。volatile 类型的引用可以确保对象的发布形式的可见性，但是如果对象的状态在发布后将发生更改，那么就需要额外的同步。 独立观察模式安全使用 volatile 的另一种简单模式是：定期 “发布” 观察结果供程序内部使用。例如，假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的 volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。使用该模式的另一种应用程序就是收集程序的统计信息。下面展示了身份验证机制如何记忆最近一次登录的用户的名字。将反复使用 lastUser 引用来发布值，以供程序的其他部分使用。 12345678910111213public class UserManager &#123; public volatile String lastUser; public boolean authenticate(String user, String password) &#123; boolean valid = passwordIsValid(user, password); if (valid) &#123; User u = new User(); activeUsers.add(u); lastUser = user; &#125; return valid; &#125;&#125; 该模式是前面模式的扩展；将某个值发布以在程序内的其他地方使用，但是与一次性事件的发布不同，这是一系列独立事件。这个模式要求被发布的值是有效不可变的 —— 即值的状态在发布后不会更改。使用该值的代码需要清楚该值可能随时发生变化。 volatile bean 模式volatile bean 模式适用于将 JavaBeans 作为“荣誉结构”使用的框架。在 volatile bean 模式中，JavaBean 被用作一组具有 getter 和 setter 方法 的独立属性的容器。volatile bean 模式的基本原理是：很多框架为易变数据的持有者（例如 HttpSession）提供了容器，但是放入这些容器中的对象必须是线程安全的。在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。（这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义）。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性。下面的示例展示了遵守 volatile bean 模式的 JavaBean：12345678910111213141516171819202122@ThreadSafepublic class Person &#123; private volatile String firstName; private volatile String lastName; private volatile int age; public String getFirstName() &#123; return firstName; &#125; public String getLastName() &#123; return lastName; &#125; public int getAge() &#123; return age; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 开销较低的读－写锁策略目前为止，了解了 volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作（读、添加、存储）的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。然而，如果读操作远远超过写操作，您可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。下面显示的线程安全的计数器使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。123456789101112@ThreadSafepublic class CheesyCounter &#123; // Employs the cheap read-write lock trick // All mutative operations MUST be done with the &apos;this&apos; lock held @GuardedBy(&quot;this&quot;) private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; 之所以将这种技术称之为 “开销较低的读－写锁” 是因为您使用了不同的同步机制进行读写操作。因为本例中的写操作违反了使用 volatile 的第一个条件，因此不能使用 volatile 安全地实现计数器 —— 您必须使用锁。然而，您可以在读操作中使用 volatile 确保当前值的可见性，因此可以使用锁进行所有变化的操作，使用 volatile 进行只读操作。其中，锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作，因此当使用 volatile 保证读代码路径时，要比使用锁执行全部代码路径获得更高的共享度 —— 就像读－写操作一样。然而，要随时牢记这种模式的弱点：如果超越了该模式的最基本应用，结合这两个竞争的同步机制将变得非常困难。 性能考虑使用 volatile 变量的主要原因是其简易性：在某些情形下，使用 volatile 变量要比使用相应的锁简单得多。使用 volatile 变量次要原因是其性能：某些情况下，volatile 变量同步机制的性能要优于锁。很难做出准确、全面的评价，例如 “X 总是比 Y 快”，尤其是对 JVM 内在的操作而言。（例如，某些情况下 VM 也许能够完全删除锁机制，这使得我们难以抽象地比较 volatile 和 synchronized 的开销。）就是说，在目前大多数的处理器架构上，volatile 读操作开销非常低 —— 几乎和非 volatile 读操作一样。而 volatile 写操作的开销要比非 volatile 写操作多很多，因为要保证可见性需要实现内存界定（Memory Fence），即便如此，volatile 的总开销仍然要比锁获取低。volatile 操作不会像锁一样造成阻塞，因此，在能够安全使用 volatile 的情况下，volatile 可以提供一些优于锁的可伸缩特性。如果读操作的次数要远远超过写操作，与锁相比，volatile 变量通常能够减少同步的性能开销。 学习资料 ： Java 理论与实践: 正确使用 Volatile 变量]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo初步使用]]></title>
      <url>%2F20170417%2Fstart%2F</url>
      <content type="text"><![CDATA[HexoHexo是一个可以快速搭建博客的框架，使用Markdown解析文章，生成静态的网页。（可以部署在github上哦） hexo的安装hexo只依赖于 Node.js Git 上面的两个的安装就不说了，自行百度，hexo基于上述环境可以使用nmp安装 1npm install -g hexo-cli hexo的基本命令 hexo init [folder] #新建一个网站 hexo n [layout] #新建一篇文章 hexo g #生成静态文件 hexo d #部署网站。 hexo publish [layout] #发表草稿 hexo s #启动服务器 hexo clean #清除缓存文件 (db.json) 和已生成的静态文件 (public) hexo的配置配置内容来自官网 ####网站|参数|描述||—|—-||title| 网站标题||subtitle| 网站副标题||description| 网站描述||author| 您的名字||language| 网站使用的语言||timezone |网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。| 其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。 ####网址|参数| 描述| 默认值||———|———|——–||url| 网址 | ||root |网站根目录 | ||permalink |文章的 永久链接 格式 |:year/:month/:day/:title/||permalink_defaults| 永久链接中各部分的默认值 | | 网站存放在子目录如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/。 ####目录|参数| 描述| 默认值||——|——|——-||source_dir| 资源文件夹，这个文件夹用来存放内容。| source||public_dir |公共文件夹，这个文件夹用于存放生成的站点文件。| public||tag_dir |标签文件夹| tags||archive_dir| 归档文件夹| archives||category_dir| 分类文件夹 |categories||code_dir |Include code 文件夹| downloads/code||i18n_dir| 国际化（i18n）文件夹 |:lang||skip_render |跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 | | 提示如果您刚刚开始接触Hexo，通常没有必要修改这一部分的值。 ####文章|参数| 描述 |默认值||—–|——–|———–||new_post_name |新文章的文件名称 |:title.md||_layout |预设布局| post||auto_spacing |在中文和英文之间加入空格 |false||titlecase |把标题转换为 title case| false||external_link |在新标签中打开链接| true||filename_case| 把文件名称转换为 (1) 小写或 (2) 大写 |0||render_drafts |显示草稿| false||post_asset_folder |启动 Asset 文件夹| false||relative_link |把链接改为与根目录的相对位址| false||future |显示未来的文章| true||highlight |代码块的设置| 相对地址默认情况下，Hexo生成的超链接都是绝对地址。例如，如果您的网站域名为example.com,您有一篇文章名为hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。 ####分类 &amp; 标签|参数| 描述| 默认值||——-|———|————||default_category| 默认分类| uncategorized||category_map| 分类别名 | ||tag_map| 标签别名 | | ####日期 / 时间格式Hexo 使用 Moment.js 来解析和显示时间。 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 H:mm:ss ####分页|参数 |描述 |默认值||——-|———|———||per_page| 每页显示的文章量 (0 = 关闭分页功能) |10||pagination_dir| 分页目录 |page| ####扩展|参数 |描述||———-|———-||theme |当前主题名称。值为false时禁用主题||deploy| 部署部分的设置 | ###我的坑我吧整个hexo init初始化的项目放到github个人blog下……然后github就说解析不了博客了……然后想了想，我把master分支放hexo生成的public里面的东西，然后新建个分支放hexo的东西，这样就可以在哪里有环境就可以写，然后！！在编译器clone自己的项目，不能在同一个项目文件夹写完然后复制public的文件放到master分支，这样hexo的命令就用不了了，提示加载不到一个模块。最后吧一个项目clone两次，一个专门该mater分支，一个写…………坑了一上午]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Programming in Scala 阅读]]></title>
      <url>%2F20170417%2Fscala%2Fscalastart%2F</url>
      <content type="text"><![CDATA[##scala Scala现在视为聪明人创造的，以后也是维拉聪明人服务的。 —— 马丁·奥德斯 Scala是一门多凡是的编程预览，是一种纯面向对象的语言，又无缝结合了命令式编程和函数式编程风格。可以和java相互操作，运行在JVM上。 未完待续……]]></content>
    </entry>

    
  
  
</search>
