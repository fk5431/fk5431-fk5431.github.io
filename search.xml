<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[mysql索引（B+)]]></title>
      <url>%2F20191222%2Fmysql%2F%E7%B4%A2%E5%BC%95%2F</url>
      <content type="text"><![CDATA[MySQL的B+树索引在MySQL中记录都存储在数据页中，各个数据页可以组成一个双向链表，每个数据页中的记录会按照主键值从小到大的顺序组成一个单向链表，每个数据页会为它里面的记录生成一个页目录，在通过主键查找某条记录的时候可以用二分查找法快速定位对应的槽，然后在遍历该槽对应的分组记录即可快速找到对应的记录。 如果没有建立索引，在mysql中查找记录可分为2种情况： 以主键为搜索条件（如果没有设置主键，mysql也会隐式的生成主键）：在页目录中使用二分法快速定位到对应的槽，然后再遍历该槽对应分组中的记录即可快速找到指定的记录。 以其他列作为搜索条件：因为在数据页中没有对非主键列建立所谓的页目录，所以无法快速定位到对应的槽。所以只能从最小记录开始遍历单链表中的每条记录，然后对比搜索条件，显然这样的效率是非常慢的。 InnoDB中的索引方案InnoDB采用存储数据的数据页来来存储目录项，只不过目录项中的两列是主键和页号，通过数据页中记录头信息中record_type来区分是目录项还是数据页。 0：普通的用户记录 1：目录项记录 2：最小记录 3：最大记录 所以记录在InnoDB的索引存储下来可能如下： 多条记录存储在一个页中，以单链表的方法存储，多个数据页组成了双向链表，都是按索引值从小到大的。然后生成一个数据页来存储目录项记录。目录项和数据页的区别如下： 目录项记录的record_type值是1，而普通用户记录的record_type值是0。 目录项记录只有主键值和页的编号两个列，而普通的用户记录的列是用户自己定义的，可能包含很多列，另外还有InnoDB自己添加的隐藏列。 数据页记录头信息中的min_rec_mask的属性，只有在存储目录项记录的页中的主键值最小的目录项记录的min_rec_mask值为1，其他别的记录的min_rec_mask值都是0。 这样根据索引去查找一条记录的时候，先到存储目录项记录的页，也就是页30中通过二分法快速定位到对应目录项，然后在到对应存储用户记录去查找到对应的记录。 InnoDB中规定一个数据页的大小是16KB，因此能存放的目录项也是有限的，当表中记录太多导致一个数据页不足以存放这么多目录项，那就在分配一个数据页存储目录项，然后这些存储目录项的数据页也组成了一个双向链表： 此时我们在查找一条数据的时候，需要先确定目录项记录页，然后通过目录项记录页确定用户记录真实所在的页，最后在真实存储用户记录的页中定位到具体的记录。这样如果目录项记录页非常多(用户存储记录量非常大)，因为这些目录项记录页相互也不挨着，是通过双向链表来连接着，这样第一步定位就会很慢。此时为这些存储目录项记录的页再生成一个更高级的目录，就像是一个多级目录一样，大目录里嵌套小目录，小目录里才是实际的数据，所以现在各个页的示意图就是这样子： 随着表中记录的增加，这个目录的层级还会增加，将示意图简化下就如下： 这样的一个结构就是B+树，不论是存放用户记录的数据页，还是存放目录项记录的数据页，我们都把它们存放到B+树这个数据结构中了，所以我们也称这些数据页为节点。从图中可以看出，实际用户记录其实都存放在B+树的最底层的节点上，这些节点也被称为叶子节点或叶节点，其余用来存放目录项的节点称为非叶子节点或者内节点，其中B+树最上边的那个节点也称为根节点。 聚簇索引 使用记录主键值的大小进行记录和页的排序，这包括三个方面的含义： 页内的记录是按照主键的大小顺序排成一个单向链表。 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。 B+树的叶子节点存储的是完整的用户记录。所谓完整的用户记录，就是指这个记录中存储了所有列的值（包括隐藏列）。 具有这两种特性的B+树为聚簇索引，所有完整的用户记录都存储在这个B+的树的叶子节点处。这种聚簇索引并不需要在MySQL语句中显示的用INDEX去创建，InnoDB存储引擎能自动的创建聚簇索引。在InnoDB存储引擎中，聚簇索引就是数据的存储方式（所有的用户记录都存储在了叶子节点），也就是所谓的索引即数据，数据即索引。 二级索引（非聚簇索引）聚簇索引是按照主键的顺序来进行排序的，如果想按表中其他列进行查询，为了查询速度就需要以其他列来建立索引，这样的索引是二级索引。二级索引就是在建立了一颗B+树，这个B+树的排序规则是按指定索引列来进行排序的，B+树的叶子节点存储的也不是完整的用户记录，而是指定列+主键。我们通过二级索引查询数据的时候： 确定目录项记录页（通过根节点来进行查找）。 通过目录项记录页确定用户记录真实所在的页。 在真实存储用户记录的页中定位到具体的记录。 叶子节点只存储了主键和二级索引列值，如果要查询的字段还包括其他字段，就需要根据主键在去聚簇索引中进行查询。 因为这种按照非主键列建立的B+树需要一次回表操作才可以定位到完整的用户记录，所以这种B+树也被称为二级索引。 联合索引我们也可以同时以多个列的大小作为排序规则，也就是同时为多个列建立索引，比方说我们想让B+树按照A2和A3列的大小进行排序，这个包含两层含义： 先把各个记录和页按照c2列进行排序。 在记录的c2列相同的情况下，采用c3列进行排序。 这样以c2和c3列的大小为排序规则建立的B+树称为联合索引。建立联合索引也只会生成一颗B+树 B+树索引根页面B+树的形成过程如下： 每当为某个表创建一个B+树索引的时候，都会为这个索引去创建一个数据页。最开始表中没有数据的时候，每个B+树索引对应的根节点中既没有用户记录，也没有目录项记录。 当向表中插入数据时，就先吧记录存储在根节点的数据页中。 当根节点可用空间使用完后继续插入，此时会将根节点数据页中的数据全都复制到一个新分配的数据页中（例如页A），然后对这个页进行页分裂的操作（得到的新页为页B）。这时新插入的记录根据键值的大小就会被分配到页a或者页b中，而根节点便升级为存储目录项记录的页。 一个B+树索引的根节点被创建后就不会再被移动。这样我们对一个表建立索引，那它的根节点的数据页的页号就会被存储在某个地方，然后InnoDB存储引擎用到这个索引的时候，就会从固定的地方取出来，从而去访问。 B+树索引的使用索引的代价 空间上的代价：每建立一个索引就要建立一个B+树，每一个B+树的每一个节点都是一个数据页，一个页会默认占用16K的大小，一颗很大的B+树由很多数据页组成，会占用不少的空间。 时间上的代价：每次对表中的数据进行增删改查的时候，都需要去修改各个B+树。B+树每层节点都是按照索引列值按小到大排列组成了双向链表。而增、删、改操作可能会对节点和记录的排序造成破坏，所以存储引擎需要额外的时间进行一些记录移位，页面分裂、页面回收等操作来维护好节点和记录的排序。 B+树的适用条件 全值匹配：如果我们的搜索条件中的列和索引列一致的话，这种情况就称为全值匹配。通过联合索引来进行全值匹配，where中条件的顺序不会影响查询效率，优化器会分析这些搜索条件并且按照可以使用的索引中列的顺序来决定先使用哪个搜索条件，后使用哪个搜索条件。 匹配左边的列：我们在搜索语句中也不需要包含联合索引中所有的列，只包含左边的就行，也可以包含多个左边的列。因为联合索引，B+树是先按列A排序，如果列A相等在按列B排序，以此类推，所以我们想使用联合索引中尽可能多的列，那搜索条件必须是联合索引中从最左边连续的列。 匹配列的前缀：索引按列的大小进行排序，字符串排序的本质就是比较哪个字符串大一点儿，会按第一个字符相比较，相等则比较第二个字符，以此类推。所以字符串的前缀也是排好序，因此在where条件中使用 ‘ab%’ 这样的前缀匹配也会使用到索引。 匹配范围值：所有记录都是按照索引列的值从小到大的顺序排好序的，所以这极大的方便我们查找索引列的值在某个范围内的记录。 精确匹配某一列并范围匹配另外一列：对于同一个联合索引来说，虽然对多个列都进行范围查找时只能用到最左边那个索引列，但是如果左边的列是精确查找，则右边的列可以进行范围查找。 用于排序：如果ORDER BY子句里使用到了索引列，就有可能省去在内存或文件中排序的过程。（使用联合索引，ORDER BY中排序列排序的顺秀需要和联合索引的顺序一致） 不可以使用索引进行排序的几种情况： ASC、DESC混用：对于使用联合索引进行排序的场景，我们要求各个排序列的排序顺序是一致的，也就是要么各个列都是ASC规则排序，要么都是DESC规则排序。 WHERE子句中出现非排序使用到的索引列：如果WHERE子句中出现了非排序使用到的索引列，那么排序依然是使用不到索引的。 排序列包含非同一个索引的列：有时候用来排序的多个列不是一个索引里的，这种情况也不能使用索引进行排序。 排序列使用了复杂的表达式：要想使用索引进行排序操作，必须保证索引列是以单独列的形式出现，而不是修饰过的形式。 用于分组：和使用B+树索引进行排序是一个道理，分组列的顺序也需要和索引列的顺序一致，也可以只使用索引列中左边的列进行分组。 索引的选择 只为用于搜索、排序或分组的列创建索引：只为出现在WHERE子句中的列、连接子句中的连接列，或者出现在ORDER BY或GROUP BY子句中的列创建索引。而出现在查询列表中的列就没必要建立索引了。 考虑列的基数：列的基数指的是某一列中不重复数据的个数，比方说某个列包含值2, 5, 8, 2, 5, 8, 2, 5, 8，虽然有9条记录，但该列的基数却是3。也就是说，在记录行数一定的情况下，列的基数越大，该列中的值越分散，列的基数越小，该列中的值越集中。最好为那些列的基数大的列建立索引，为基数太小列的建立索引效果可能不好。 索引列的类型尽量小：数据类型越小，在查询时进行的比较操作越快；数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘I/O带来的性能损耗，也就意味着可以把更多的数据页缓存在内存中，从而加快读写效率。 索引字符串值的前缀：我们可以只对字符串的前几个字符进行索引也就是说在二级索引的记录中只保留字符串前几个字符。这样在查找记录时虽然不能精确的定位到记录的位置，但是能定位到相应前缀所在的位置，然后根据前缀相同的记录的主键值回表查询完整的字符串值，再对比就好了。（这样的索引无法支持排序的时候使用索引） 索引列在比较表达式中单独出现：如果索引列在比较表达式中不是以单独列的形式出现，而是以某个表达式，或者函数调用形式出现的话，是用不到索引的。 主键插入顺序：如果一个主键插入的值一会大一会小，会导致页分裂和记录移位，这意味着性能损耗，所以最好让主键具有AUTO_INCREMENT，让存储引擎自己为表生成主键，而不是我们手动插入。 冗余和重复索引：冗余和重复索引只会增加维护索引的成本。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[存储引擎介绍（MySql）]]></title>
      <url>%2F20191221%2Fmysql%2F%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%2F</url>
      <content type="text"><![CDATA[存储引擎介绍数据库存储引擎是数据库底层软件引擎，数据库管理系统使用数据引擎进行创建、查询、更新和删除操作。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎还可以获得特定的功能。 mysql5.7中支持的存储引擎有InnoDB、MyISAM、Memory、Merge、Archive、Federated、CSV、BLACKHOLE等。 不同存储引擎的特点： 功能 MylSAM MEMORY InnoDB Archive 存储限制 256TB RAM 64TB None 支持事务 No No Yes No 支持全文索引 Yes No No No 支持树索引 Yes Yes Yes No 支持哈希索引 No Yes Yes No 支持数据缓存 No N/A Yes No 支持外键 No No Yes No InnoDBInnoDB底层存储结构为B+树，B树的每个节点对应innodb的一个page，page大小是固定的，一般设为16k。其中非叶子节点只有键值，叶子节点包含完成数据。 适用场景： 经常更新的表，适合处理多重并发的更新请求。 支持事务。 可以从灾难中恢复(通过 bin-log 日志等)。 外键约束。只有他支持外键。 支持自动增加列属性 auto_increment。 MyIASMMyISAM是MySql5.6之前的默认引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT或UPDATE数据时需要锁定整个表，效率会更低一些。ISAM执行读取操作的速度很快，而且不占用大量的内存和存储资源。在设计之初就预想数据组织成有固定长度的记录，按顺序存储的。（ISAM是一种静态索引结构）缺点是它不支持事务处理。 MemoryMemory堆内存：使用存在内存中的内容来创建表。Memory表只实际对应一个磁盘文件。由于它的数据是放在内存中的并默认使用HASH索引，因此访问速度很快。但是服务一但关闭，表中的数据就会丢失。Memory同时支持hash索引和B树索引，B树索引可以使用部分和通配查询，也可以使用&lt;,&gt;和&gt;=等操作符方便数据挖掘，hash索引相等的比较快但是对于范围的比较慢很多。 选择 如果要提供提交、回滚和恢复的事务安全（ACID 兼容）能力，并要求实现并发控制，InnoDB 是一个很好的选择。 如果数据表主要用来插入和查询记录，则 MyISAM 引擎提供较高的处理效率。 如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存的 MEMORY 引擎中，MySQL 中使用该引擎作为临时表，存放查询的中间结果。 如果只有 INSERT 和 SELECT 操作，可以选择Archive 引擎，Archive 存储引擎支持高并发的插入操作，但是本身并不是事务安全的。Archive 存储引擎非常适合存储归档数]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PriorityQueue阅读]]></title>
      <url>%2F20191218%2Fjavasource%2Futil%2F10_PriorityQueue%2F</url>
      <content type="text"><![CDATA[PriorityQueuePriorityQueue是一个优先队列，优先队列不允许空值，而且不支持non-comparable的对象（自定义的对象）。 优先队列的使用比较简单，常用的方法如下： peek()//返回队首元素 poll()//返回队首元素，队首元素出队列 add()/offer()//添加元素 size()//返回队列元素个数 isEmpty()//判断队列是否为空，为空返回true,不空返回false 优先对列通过小顶堆来实现，可以用一个完全二叉树来表示（任意一个非叶子节点的权值，都不大于其左右子节点的权值）。 一般通过add方法来添加元素：123public boolean add(E e) &#123; return offer(e);&#125; add方法其实也是调用了offer：1234567891011121314public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1);//扩容 size = i + 1; if (i == 0) queue[0] = e; else siftUp(i, e);//加入树 return true;&#125; offer方法比较简单，不允许元素为空，如果超过现在数组的长度就进行扩容，如果是第一个元素，将数组第一个（根结点）设为此元素，否则进行调整加入完全二叉树。 1234567891011private void grow(int minCapacity) &#123; int oldCapacity = queue.length; // Double size if small; else grow by 50% int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); queue = Arrays.copyOf(queue, newCapacity);&#125; 扩容方法就是申请一个更大的数组，将原来数组复制过去，所以可以看出是线程不安全的。 1234567891011121314151617181920212223242526272829private void siftUp(int k, E x) &#123; if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x);&#125;private void siftUpUsingComparator(int k, E x) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (comparator.compare(x, (E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = x;&#125;private void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (key.compareTo((E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = key;&#125; 将此节点加入树的过程，就是调用默认的比较方法或者传入的比较方法去和父节点比较，如果小于，那就和parent交换位置。过程如下： 我们通过poll方法返回第一个对象并移除：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public E poll() &#123; if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0]; E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x);//调整 return result;&#125;private void siftDown(int k, E x) &#123; if (comparator != null) siftDownUsingComparator(k, x); else siftDownComparable(k, x);&#125;private void siftDownComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;)x; int half = size &gt;&gt;&gt; 1; // loop while a non-leaf while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; // 左节点 Object c = queue[child]; int right = child + 1;//右节点 if (right &lt; size &amp;&amp; ((Comparable&lt;? super E&gt;) c).compareTo((E) queue[right]) &gt; 0) c = queue[child = right];//找到更小的那个 if (key.compareTo((E) c) &lt;= 0) break; queue[k] = c;//替换 k = child; &#125; queue[k] = key;&#125;private void siftDownUsingComparator(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; int child = (k &lt;&lt; 1) + 1; Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c; k = child; &#125; queue[k] = x;&#125; 将根节点删除的过程，找到根节点左右孩子中最小的那个，然后和最后一个节点比较，如果大于等于最后一个节点，此节点替换根节点，递归调用即可。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CAP]]></title>
      <url>%2F20191217%2Fdistributed%2FCAP%2F</url>
      <content type="text"><![CDATA[CAP理论CAP原则又称CAP定理，指的是在一个分布式系统中，一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）。CAP原则指的是，这三个要素最多只能同时实现两点，不能三者兼顾。 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否完全一致。对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如果能容忍后续的部分或者全部访问不到，则是弱一致性。如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。CAP中说，不可能同时满足的这个一致性指的是强一致性。 可用性（A）：在集群中一部分节点故障后，集群整体是否还能对请求作出响应。 分区容错性（P）：是指在分布式系统在遇到某节点或者网络分区故障的时候，仍然能够对外提供满足一致性和可用性的服务。 CAP证明假设有两台服务器，一台放着应用A和数据库，一台放着应用B和数据库，他们之间的网络可以互通，也就相当于分布式系统的两个部分。 在满足一致性的时候，两台服务器 N1和N2，一开始两台服务器的数据是一样的，DB0=DB0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。 当用户通过N1中的A应用请求数据更新到服务器DB0后，这时N1中的服务器DB0变为DB1，通过分布式系统的数据同步更新操作，N2服务器中的数据库也更新为了DB1，这时，用户通过B向数据库发起请求得到的数据就是即时更新后的数据DB1。上面是正常运作的情况，但分布式系统中，最大的问题就是网络传输问题，现在假设一种极端情况，N1和N2之间的网络断开了，但我们仍要支持这种网络异常，也就是满足分区容错性。假设N1和N2之间通信的时候网络突然出现故障，有用户向N1发送数据更新请求，那N1中的数据DB0将被更新为DB1，由于网络是断开的，N2中的数据库仍旧是DB0；如果这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据DB1，怎么办呢？有二种选择，第一，牺牲数据一致性，响应旧的数据DB0给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作完成之后，再给用户响应最新的数据DB1。这就说明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。也就是说分布式系统不可能同时满足三个特性。 CAP权衡 CA：这种情况在分布式系统几乎不存在。因为在分布式环境下，网络分区是一个自然的事实。所以分区是必然的，如果舍弃了P，那就没有分布式系统的概念了，就没有必要讨论CAP原则了。对于一个分布式系统来说，P是一个基本要求，CAP三者中，只能在CA两者之间做权衡，并且要想尽办法提升P。 CP：如果一个分布式系统不要求强的可用性，容许系统停机或者长时间无响应，那可以舍弃A。设计成CP的系统其实也不少，其中最典型的就是很多分布式数据库，他们都是设计成CP的。在发生极端情况时，优先保证数据的强一致性，代价就是舍弃系统的可用性。如Redis、HBase等，还有分布式系统中常用的Zookeeper也是在CAP三者之中选择优先保证CP的。 AP：要高可用并允许分区，则需放弃一致性。一旦网络问题发生，节点之间可能会失去联系。为了保证高可用，需要在用户访问时可以马上得到返回，则每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。但是大部分系统中舍弃了一致性选择可用性，其实舍弃了强一致性，保证了最终一次性。例如买火车票时，下单时还有票但是实际可能没票了，会出现短暂的数据不一致的情况，但是最终数据会保证一致。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[一致性hash]]></title>
      <url>%2F20191216%2Falgorithm%2F%E4%B8%80%E8%87%B4%E6%80%A7hash%2F</url>
      <content type="text"><![CDATA[一致性hash一致性hash算法是一种特殊的hash算法，在移除或添加一个服务器时，能尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。普通的hash算法通过hash某个维度的值去得到余数，这样在新增或者下线服务的时候，原来的映射关系就会发生大量失效。例如使用分布式缓存来缓存用户的数据，通过用户id % 服务数，当增加一个缓存服务时，原有的hash映射关系大部分都失效，这会造成缓存雪崩，导致严重的后果。 原理一致性哈希算法将整个哈希值空间映射成一个虚拟的圆环，整个哈希空间的取值范围为0~2^32-1。整个空间按顺时针方向组织。0~2^32-1在零点方向重合。接下来使用如下算法对服务请求进行映射，将服务请求使用哈希算法算出对应的hash值，然后根据hash值的位置沿圆环顺时针查找，第一台遇到的服务器就是所对应的处理请求服务器。当增加一台新的服务器，受影响的数据仅仅是新添加的服务器到其环空间中前一台的服务器（也就是顺着逆时针方向遇到的第一台服务器）之间的数据，其他都不会受到影响。综上所述，一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性 。 假设有4台服务器，地址为ip1,ip2,ip3,ip4。一致性hash会先计算四个ip对应的hash值，这样四个服务在一致性hash环上如下： 此时用户在请求时，根据hash(userId)计算路由规则，看hash到环上哪个位置，然后从环上位置顺时针找到下一个服务作为请求的服务。 如上图可知user1,user2的请求会落到服务器ip2进行处理，User3的请求会落到服务器ip3进行处理，user4的请求会落到服务器ip4进行处理，user5,user6的请求会落到服务器ip1进行处理。 当ip2的服务器挂了的时候，一致性hash环大致如下图： 根据顺时针规则可知user1,user2的请求会被服务器ip3进行处理，而其它用户的请求对应的处理服务器不变，只有ip1到iP2环之间的请求映射关系会被破坏。 如果是新增一个ip5服务： 也只有ip4到ip5之间的请求映射关系会被改变，从请求到ip1变为了请求到ip5。 特性 单调性：单调性是指如果已经有一些请求通过hash分派到了相应的服务器进行处理，又有新的服务器加入系统时，应保证原有的请求可以被映射到原有的或新的服务器中，而不会被映射到原来的其他服务器上。 分散性：分布式环境中，客户端请求的时候可能不知道所有的服务器，可能只知道一部分服务器，在客户端看来他看到部分服务器会形成一个完整的还。如果多个客户端把部分服务器作为一个完整的hash环，那么可能导致，同一个用户的请求被路由到不同的服务进行处理。这种情况是应该避免的，因为不能保证同一个用户的请求落到同一个服务器。分散性就是只上述情况发生的严重程度。一致性hash具有很低的分散性。 平衡性：平衡性也就是说负载均衡，是指客户端hash后的请求应该能够分散到不同的服务器去。一致性hash可以做到每个服务器都进行处理请求，但是不能保证每个服务器处理的请求大致相同（如下）。 服务器ip1,ip2,ip3经过hash后落到了一致性hash环上，从图中hash值分布可知ip1会负责处理大概80%的请求，而ip2和ip3则只会负责处理大概20%的请求，虽然三个机器都在处理请求，但是明显每个机器的负载不均衡，这样称为一致性hash的倾斜，虚拟节点的出现就是为了解决这个问题。 虚拟节点当服务器节点比较少的时候会出现上节所说的一致性hash倾斜的问题，一个解决方法是多加机器，但是加机器是有成本的，那么就加虚拟节点，比如上面三个机器，每个机器引入1个虚拟节点后的一致性hash环的图如下： 其中ip1-1是ip1的虚拟节点，ip2-1是ip2的虚拟节点，ip3-1是ip3的虚拟节点。可知当物理机器数目为M，虚拟节点为N的时候，实际hash环上节点个数为M*N。比如当客户端计算的hash值处于ip2和ip3或者处于ip2-1和ip3-1之间时候使用ip3服务器进行处理。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JDK常用命令（虚拟机性能监控故障处理）]]></title>
      <url>%2F20191211%2Fjvm%2F5_JDK%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%EF%BC%88%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%EF%BC%89%2F</url>
      <content type="text"><![CDATA[jps：虚拟机进程状况工具jps的功能：可以列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main()函数所在的类）名称以及这些进程的本地虚拟机唯一ID。它是使用频率最高的JDK命令行工具，因为其他的JDK工具大多需要输入它查询到LVMID来确定要监控的是哪一个虚拟机进程。 对于本地虚拟机进程来讲，LVMID和操作系统的进程ID是一致的，使用PS（LINUX）也可以查询到虚拟机进程的LVMID，但是如果启动了多个虚拟机进程就无法根据进程名称定位。jps命令格式：jps [options] [hostid] 选项 作用 -q 只输出LVMID，省略主类的名称 -m 输出虚拟机进程启动时传递给主类main函数的参数 -l 输出主类的全名，如果执行的是jar包，输出jar路径 -v 输出虚拟机进程启动时jvm参数 jstat：虚拟机统计信息监视工具jstat (JVM Statistics Monitoring Tool)用于监视虚拟机各种运行状态信息的命令行工具。 它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾会搜、JIT编译等运行数据。 jstat的命令格式：jstat [ option vmid [interval[s|ms] [count]]] 对于命令格式中的VMID和LVMID，如果是本地虚拟机进程，两者一致。如果是远程虚拟机进程，则VMID的格式为[protocol:][//]lvmind[@hostname[:port]/servername]interval : 查询间隔 count：查询次数 如果省略interval和count，则只查询一次选项option代表用户希望查询的虚拟机信息，主要分为3类：类装载、垃圾收集、运行期编译状况。 选项 作用 -class 监视类装载、卸载数量，总空间以及类装载锁耗费的时间 -gc 监视Java堆状况，包括eden区、两个Survivor区、老年代、永久代等的容量、已使用空间、GC时间合计等信息 -gccapacity 监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用的最大、最小空间 -gcutil 监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -gccause 与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因 -gcnew 监视新生代GC状况 -gcnewcapacity 监视内容与-gcnew 基本相同，但输出主要关注Java堆各个区域使用的最大、最小空间 -gcold 监视老年代代GC状况 -gcoldcapacity 监视内容与-gcold 基本相同，但输出主要关注Java堆各个区域使用的最大、最小空间 -gcpermcapacity 输出永久代使用的最大、最小空间 -compiler 输出JIT编译器编译过的方法、耗时等信息 -printcompilation 输出已经被JIT编译的方法 输入:1jstat -gc 2780 1000 20 查看进程2780的GC情况，每隔1s查一次，查20次,部分返回如下： 1234567S0C S1C S0U S1U EC EU OC OU PC PU YGC YGCT FGC FGCT GCT4352.0 4352.0 1713.6 0.0 34944.0 13334.2 164708.0 149426.3 ? ? 1042 13.752 14 0.445 14.1964352.0 4352.0 1713.6 0.0 34944.0 13966.0 164708.0 149426.3 ? ? 1042 13.752 14 0.445 14.1964352.0 4352.0 1713.6 0.0 34944.0 14611.7 164708.0 149426.3 ? ? 1042 13.752 14 0.445 14.1964352.0 4352.0 1713.6 0.0 34944.0 15243.8 164708.0 149426.3 ? ? 1042 13.752 14 0.445 14.1964352.0 4352.0 1713.6 0.0 34944.0 15886.3 164708.0 149426.3 ? ? 1042 13.752 14 0.445 14.1964352.0 4352.0 1713.6 0.0 34944.0 16527.8 164708.0 149426.3 ? ? 1042 13.752 14 0.445 14.196 S0C：第一个幸存区的大小 S1C：第二个幸存区的大小 S0U：第一个幸存区的使用大小 S1U：第二个幸存区的使用大小 EC：年轻代的大小 EU：年轻代使用大小 OC：老年代大小 OU：老年代使用大小 PC：perm内存大小（永久区） PU：perm内存使用大小 YGC：年轻代垃圾回收次数 YGCT：年轻代垃圾回收消耗时间 FGC：老年代垃圾回收次数 FGCT：老年代垃圾回收消耗时间 GCT： 垃圾回收消耗总时间 jinfo：java配置信息工具jinfo的作用是实时的查看和调整虚拟机各项参数。 语法：jinfo [option] pid 执行 jinfo -flags pid 命令后查询结果中，Non-default VM flags为虚拟机默认的设置参数，Command line为用户自行设置的参数 jmap：java内存映像工具jmap命令用于生成堆转储快照（一般称为heapdump或dump文件）。jmap不仅仅为了获取dump文件，它还可以查询finalize执行队列、Java堆、永久代的详细信息，如空间使用率、当前使用的是那种收集器等。 jmap 命令格式： jmap [option] vmid 选项 作用 -dump 生成java堆转储快照。 格式为 -dump:[live,] format=b,file= 其中live子参数说明是否只dump出存活的对象 -finalizeinfo 显示在F-Queue中等待Finalizer线程执行finalize方法的对象。 只在linux/solaris平台有效 -heap 只显示Java堆详细信息。如使用脑胀回收器、参数配置、分代状况等。只在linux/solaris平台有效 -histo 显示堆中对象统计信息，包括类、实例数量、合计容量 -permstat 以ClassLoader为统计口径显示永久代内存状态。 只在linux/solaris平台有效 -F 当虚拟机进程对-dump选项没有响应时，可以使用这个选项强制生成dump快照。只在linux/solaris平台有效 jhat：虚拟机堆转储快照分析工具jhat与jmap搭配使用，用于分析jmap生成的堆转储快照。jhat内置了一个微型的HTTP/HTML服务器，生成的dump文件的分析结果后，可以在浏览器中输入“http://localhost:7000”进行查看。 使用：12jmap -dump:format=b,file=test.bin 2780jhat test.bin jstack：java堆栈跟踪工具jstack作用：用于生成虚拟机当前时刻的线程快照。 线程快照是指当前虚拟机内的每一个线程正在执行的方法堆栈的集合。 生成线程快照的作用是可用于定位线程出现长时间停顿的原因，如线程间死锁 、死循环、请求外部资源导致的长时间等待等等问题，当线程出现停顿现象时，就可以用jstack查看各个线程调用的堆栈情况。 jstack命令格式：jstack [option] vmid 选项 作用 -F 当正常输出的请求不被响应时，强制输出线程堆栈 -m 如果调用到本地方法的话，可以显示C/C++的堆栈 -l 除了堆栈信息，显示关于锁的附件信息]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM类加载机制]]></title>
      <url>%2F20191209%2Fjvm%2F4_JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
      <content type="text"><![CDATA[虚拟机类加载机制类加载的时机类从被加载到虚拟机内存开始，到卸载出内存为止，它的整个生命周期包括，加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）和卸载（UNloading）7个阶段。其中验证、准备、解析三个节点统称为连接（Linking），这7个阶段的发生顺序如下： 加载、验证、准备、初始化和卸载这5个阶段的顺序是确定，类的加载必须按这个顺序进行，但是解析阶段不一定：它在某些情况下可以在初始化阶段之后进行，为了支持java的运行时绑定。虚拟机规范严格规定了有且只有5中情况必须对类进行初始化： 遇到new、getstatic、putstatic活invokestatic这4条字节码指定时，如果类没有进行过初始化，则必须先触发初始化。生成这四条指令最常见的java代码场景：使用new关键词实例化对象、读取或设置一个类的静态字段（被final修饰、在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法时候。 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先进行初始化。 当初始化一个类的时候，如果发现其父类还没有进行初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类，虚拟机会先初始化这个类。 当使用动态语言支持时，如果一个java.lang.invoke.MethodHandle实例最后的解析结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先触发初始化。 类加载的过程加载 通过一个类的全限定名来获取定义此类的二进制字节流。（不一定从class文件获取，也可以从ZIP包、网络、运行时计算生成（动态代理）、其他文件（JSP）、数据库获取） 将这个字节流所代表的静态存储结构转换为方法区的运行时数据结构。 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口。 验证此阶段主要确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机的自身安全。 文件格式验证：基于字节流验证。 元数据验证：基于方法区的存储结构验证。 字节码验证：基于方法区的存储结构验证。 符号引用验证：基于方法区的存储结构验证。 准备为类变量分配内存，并将其初始化为默认值。（此时为默认值，在初始化的时候才会给变量赋值）即在方法区中分配这些变量所使用的内存空间。例如：1public static int value = 123; 此时在准备阶段过后的初始值为0而不是123；将value赋值为123的putstatic指令是程序被编译后，存放于类构造器方法之中，所以把value赋值为123的过程在初始化阶段才会进行。 1public static final int value = 123; 此时value的值在准备阶段过后就是123（类字段属性表中存在ConstantValue属性，编译时Javac会为value生成ConstantValue属性，在准备过程就会根据ConstantValue的设置将value复制为123）。 解析把类型中的符号引用转换为直接引用。 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在 主要有以下四种： 类或接口的解析 字段解析 类方法解析 接口方法解析 初始化初始化阶段是执行类构造器方法的过程。方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证方法执行之前，父类的方法已经执行完毕。如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成()方法。 类加载器对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在java虚拟机中的唯一性，每一个类加载器都拥有一个独立的类名称空间。比较两个类是否相等，只有在这两个类是同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类必定不相等。 123456789101112131415161718192021222324public class ClassLoaderTest &#123; public static void main(String[] args) throws Exception &#123; ClassLoader loader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if(is == null) &#123; return super.loadClass(name); &#125; byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (Exception e) &#123; throw new ClassNotFoundException(name); &#125; &#125; &#125;; Object obj = loader.loadClass(&quot;classloader.ClassLoaderTest&quot;); System.out.println(obj); System.out.println(obj instanceof ClassLoaderTest); &#125;&#125; 以上代码会输出12class classloader.ClassLoaderTestfalse 可以看出这个object的确是ClassLoaderTest实例化出来的对象，但是这个类与classloader.ClassLoaderTest做类型检查却返回false。 双亲委派模式从Java虚拟机的江都讲，只存在两种不同的类加载器：一种是启动类加载器（Bootstrap ClassLoader）,这个类加载器由C++实现，是虚拟机的一部分；另一种就是所有其他的类加载器，这些类加载器都由Java实现，全都继承于抽象类java.lang.ClassLoader。 JVM提供了以下3种系统的类加载器： 启动类加载器（Bootstrap ClassLoader）：最顶层的类加载器，负责加载 JAVA_HOME\lib 目录中的，或通过-Xbootclasspath参数指定路径中的，且被虚拟机认可（按文件名识别，如rt.jar）的类。 扩展类加载器(Extension ClassLoader)：负责加载 JAVA_HOME\lib\ext 目录中的，或通过java.ext.dirs系统变量指定路径中的类库。 应用程序类加载器(Application ClassLoader)：也叫做系统类加载器，可以通过getSystemClassLoader()获取，负责加载用户路径（classpath）上的类库。如果没有自定义类加载器，一般这个就是默认的类加载器。 类加载器之间的这种层次关系叫做双亲委派模型。双亲委派模型要求除了顶层的启动类加载器（Bootstrap ClassLoader）外，其余的类加载器都应当有自己的父类加载器。这里的类加载器之间的父子关系一般不是以继承关系实现的，而是用组合实现的。 双亲委派模型的工作过程如果一个类接受到类加载请求，他自己不会去加载这个请求，而是将这个类加载请求委派给父类加载器，这样一层一层传送，直到到达启动类加载器（Bootstrap ClassLoader）。只有当父类加载器无法加载这个请求时，子加载器才会尝试自己去加载。 双亲委派模型的代码实现双亲委派模型的代码实现集中在java.lang.ClassLoader的loadClass()方法当中。 首先检查类是否被加载，没有则调用父类加载器的loadClass()方法； 若父类加载器为空，则默认使用启动类加载器作为父加载器； 若父类加载失败，抛出ClassNotFoundException 异常后，再调用自己的findClass() 方法。 1234567891011121314151617181920212223protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; //1 首先检查类是否被加载 Class c = findLoadedClass(name); if (c == null) &#123; try &#123; if (parent != null) &#123; //2 没有则调用父类加载器的loadClass()方法； c = parent.loadClass(name, false); &#125; else &#123; //3 若父类加载器为空，则默认使用启动类加载器作为父加载器； c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //4 若父类加载失败，抛出ClassNotFoundException 异常后 c = findClass(name); &#125; &#125; if (resolve) &#123; //5 再调用自己的findClass() 方法。 resolveClass(c); &#125; return c;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[GC垃圾收集器]]></title>
      <url>%2F20191208%2Fjvm%2F3_GC%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%E5%99%A8%2F</url>
      <content type="text"><![CDATA[垃圾收集器java虚拟机规范没有对垃圾收集器如何实现做任何规定，因此不同厂商、版本提供的垃圾收集器都不一样，JDK1.7中垃圾收集器如下: 如果两个收集器之间存在连线，则说明他们之间可以搭配使用。 Serial收集器（单线程复制算法）这个收集器是一个单线程的收集器，但它单线程的意义不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾回收，它在进行垃圾回收的时，必须暂停其他所有工作线程，直到它收集完毕。 Serial收集器运行时如下： 当Serial收集器工作时候，会造成Stop-The-World，这对很多应用是不可能接受的。但是对于限定单个CPU的环境来说，没有线程交互的开销，专心做GC，和其他收集器相比是简单而高效的（单线程情况）。在用户的桌面应用场景中，可用内存一般不大（几十M至一两百M），可以在较短时间内完成垃圾收集（几十MS至一百多MS）,只要不频繁发生，这是可以接受的。因此，Serial收集器对于运行在Client模式下的虚拟机来说是个比较好的选择。 ParNew 收集器（Serial+多线程）ParNew收集器其实就是Serial收集器的多线程版本，也使用复制算法，除了使用多线程进行垃圾收集之外，其余的行为和Serial收集器完全一样，ParNew垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。它是许多运行在Server模式下的虚拟机的首要选择，除了Serial收集器外，目前只有它能与CMS收集器配合工作。 CMS收集器是一个被认为具有划时代意义的并发收集器，因此如果有一个垃圾收集器能和它一起搭配使用让其更加完美，那这个收集器必然也是一个不可或缺的部分了。 ParNew收集器的运行过程如下图所示: 在Server模式下，ParNew收集器是一个非常重要的收集器，因为除Serial外，目前只有它能与CMS收集器配合工作；但在单个CPU环境中，不会比Serail收集器有更好的效果，因为存在线程交互开销，该收集器通过超线程技术实现的两个CPU的环境中都不能百分百的保证超过Serial收集器。 Parallel Scavenge 收集器(多线程复制算法)Parallel Scavenge收集器是一个新生代收集器，它也是使用复制算法的收集器，又是并行的多线程收集器。Parallel Scavenge收集器的特点是它的关注点和其他收集器不同，CMS等收集器关注点是尽可能的缩短垃圾收集时用户的停顿时间，而Parallel Scavenge关注点是吞吐量（如何高效率的利用CPU）。所谓吞吐量就是CPU中用于运行用户代码的时间与CPU总消耗时间的比值。（吞吐量：CPU用于用户代码的时间/CPU总消耗时间的比值，即=运行用户代码的时间/(运行用户代码时间+垃圾收集时间)。比如，虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。） 当应用程序运行在具有多个CPU上，对暂停时间没有特别高的要求时，即程序主要在后台进行计算，而不需要与用户进行太多交互，例如，那些执行批量处理、订单处理、工资支付、科学计算的应用程序；可以采用Parallel Scavenge收集器。 Serial Old收集器（单线程标记整理）Serial收集器的老年代版本，同样是一个单线程收集器。 它主要有两大用途：一种用途是在JDK1.5以及以前的版本中与Parallel Scavenge收集器搭配使用，另一种用途是作为CMS收集器的后备方案 Parallel Old收集器（多线程标记整理）Parallel Old 收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在JDK1.6才开始提供。在JDK1.6之前，新生代使用ParallelScavenge收集器只能搭配年老代的Serial Old收集器，只能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old 正是为了在年老代同样提供吞吐量优先的垃圾收集器，如果系统对吞吐量要求比较高，可以优先考虑新生代 Parallel Scavenge 和年老代 Parallel Old 收集器的搭配策略。 CMS收集器（多线程标记清除）CMS 收集器是一种以获取最短回收时间为目标的收集器。它的整个过程分为4个步骤：初始标记、并发标记、重新标记、并发清除。 初始标记： 暂停所有的其他线程，初始标记仅仅标记GC Roots能直接关联到的对象，速度很快； 并发标记： 并发标记就是进行GC Roots Tracing的过程；同时开启GC和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以GC线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方； 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录（采用多线程并行执行来提升效率）；需要”Stop The World”，且停顿时间比初始标记稍长，但远比并发标记短； 并发清除： 开启用户线程，同时GC线程开始对为标记的区域做清扫，回收所有的垃圾对象； 由于整个过程耗时最长的并发标记和并发清除过程收集器线程都可以与用户线程一起工作，所以总体来说，CMS的内存回收是与用户线程一起“并发”执行的。 CMS有三个明显的缺点； 对CPU资源敏感：面向并发设计的程序都对CPU资源比较敏感（并发程序的特点）。在并发阶段，它虽然不会导致用户线程停顿，但会因为占用了一部分线程（或者说CPU资源）而导致应用程序变慢，总吞吐量会降低。 CMS的默认收集线程数量是=(CPU数量+3)/4；当CPU数量多于4个，收集线程占用的CPU资源多于25%，对用户程序影响可能较大；不足4个时，影响更大，可能无法接受。 无法处理浮动垃圾：在并发清除时，用户线程新产生的垃圾，称为浮动垃圾；这使得并发清除时需要预留一定的内存空间，不能像其他收集器在老年代几乎填满再进行收集；也可以认为CMS所需要的空间比其他垃圾收集器大； 产生大量内存碎片：由于CMS是基于“标记+清除”算法来回收老年代对象的，因此长时间运行后会产生大量的空间碎片问题，由于碎片过多，将会给大对象的分配带来麻烦。因此会出现这样的情况，老年代还有很多剩余的空间，但是找不到连续的空间来分配当前对象，这样不得不提前触发一次Full GC。。 为了解决空间碎片问题，CMS收集器提供−XX:+UseCMSCompactAlFullCollection标志，使得CMS出现上面这种情况时不进行Full GC，而开启内存碎片的合并整理过程；但合并整理过程无法并发，停顿时间会变长； G1收集器G1是一款面向服务端应用的垃圾收集器。HotSpot开发团队赋予它的使命是未来可以替换JDK1.5发布的CMS收集器。与其他收集器相比，G1具备以下特点： 并行与并发：G1能充分利用CPU、多核环境下的硬件优势，使用多个CPU（CPU或者CPU核心）STW停顿时间。部分其他收集器原本需要停顿Java线程执行的GC动作，G1收集器仍然可以通过并发的方式让java程序继续执行。 分代收集：虽然G1可以不需要其他收集器配合就能独立管理整个GC堆，但它能够采用不同的方式去处理新创建的对象和已经存活了一段时间的对象，熬过多次GC的旧对象以获取更好的收集效果。 空间整合：与CMS的“标记–清理”算法不同，G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。 可预测的停顿：这是G1相对于CMS的另一个大优势，降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型。可以明确指定M毫秒时间片内，垃圾收集消耗的时间不超过N毫秒。在低停顿的同时实现高吞吐量。 G1收集器将整个java堆分为多个大小相等的独立区域（Region），虽然还保留了新生代和老年代的概念，但是新生代和老年代不是物理隔离，它们都是一部分Region的集合。 G1收集器可以有计划的避免在整个java堆进行全局的垃圾回收。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需要的时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的Region。这就保证了在有限的时间内可以获取尽可能高的收集效率。因此G1是可预测停顿的。 一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？这个问题在其他的分代收集器，也存在这样的问题，只是在G1更加突出。无论G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描：每个Region都有一个对应的Remembered Set，每次Reference类型数据写操作时，都会产生一个Write Barrier暂时中断操作，然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象），如果不同，通过CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中。当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set，就可以保证不进行全局扫描，也不会有遗漏。 如果不计算维护Remembered Set操作，G1收集器的运作大致可划分为以下几个步骤： 初始标记：仅标记一下GC Roots能直接关联到的对象，且修改TAMS（Next Top at Mark Start）,让下一阶段并发运行时，用户程序能在正确可用的Region中创建新对象，需要”Stop The World”，但速度很快； 并发标记：从GC Roots开始进行可达性分析，找出存活对象，耗时长，可与用户线程并发执行，并不能保证可以标记出所有的存活对象；（在分析过程中会产生新的存活对象） 最终标记：修正并发标记阶段因用户线程继续运行而导致标记发生变化的那部分对象的标记记录，上一阶段对象的变化记录在线程的Remembered Set Log，这里把Remembered Set Log合并到Remembered Set中，需要”Stop The World”，且停顿时间比初始标记稍长，但远比并发标记短； 筛选回收：首先排序各个Region的回收价值和成本，然后根据用户期望的GC停顿时间来制定回收计划，最后按计划回收一些价值高的Region中垃圾对象，回收时采用”复制”算法，从一个或多个Region复制存活对象到堆上的另一个空的Region，并且在此过程中压缩和释放内存，可以并发进行，降低停顿时间，并增加吞吐量；]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM垃圾回收算法]]></title>
      <url>%2F20191207%2Fjvm%2F2_JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95%2F</url>
      <content type="text"><![CDATA[垃圾回收在java运行过程中，程序计数器、虚拟机栈、本地方法栈3个区域都是线程私有的，都会随着线程而创建，随着线程而销毁。这三个区域不需要考虑内存的回收，在方法结束或者线程结束后，内存就会被回收。但是在java堆和方法区却不能这样，只有在程序运行的过程中才能知道会创建哪些对象，这些对象的创建和回收都是动态的，因为这部分区域的内容是需要垃圾回收的。 如何确定垃圾引用计数法给对象添加一个引用计数器，每当有一个地方引用它时，计数器就+1；当引用失效的时候，计数器就-1；在任何时候，计数器为0的对象就是不可在被使用的，这个对象就是可回收对象。 引用计数法的实现很简单，判定效率也比较高，但是它无法解决对象之前相互引用的问题。 1234567891011public class Test &#123; public Object instance = null; public static void main(String[] args) &#123; Test t1 = new Test(); Test t2 = new Test(); t1.instance = t2; t2.instance = t1; t1 = null; t2 = null; &#125;&#125; 以上两个对象都已经为空且无任何引用，而且已经不可被访问，但是它们相互引用的对方，它们的引用计数器都不为0，使用引用计数法就无法进行回收内存。 可达性分析这个算法就是通过一系列 GC Roots的对象作为起点，从这些节点开始向下搜索，搜索走过的路径就是引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。 像上图，对象o5-o6虽然互相有关联，但是到GC Roots都是不可达的，因此都会被判为可回收对象。 在java中，可被作为GC Roots对象的包括： 虚拟机栈中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（Native）引用的对象。 java中的引用Java中因为可分为强引用、软引用、弱引用、虚引用4种，这四种引用强度依次逐渐减弱。 强引用：强引用就是平时new 出来的对象的这类的引用，只要强引用存在，对象就不会被回收。 软引用：用来描述一些有用但是不是必须的对象。在系统要发生内存溢出之前，会将这些对象列入回收范围内进行第二次回收，如果还没有足够内存才会抛出异常。（SoftReference来实现） 弱引用：被弱引用关联的对象只能生存到下一次垃圾回收之前。（WeakReference来实现） 虚引用：为一个对象设置虚引用关联的唯一目的是能在这个对象被垃圾回收器回收时能得到一个系统通知。（PhantomReference来实现） 垃圾的自救被标记为不可用的对象也不会直接被回收，一个对象的回收至少要经历两次标记的过程。如果一个对象经过可达性分析后没有与GC Roots相连接的引用链，那就会被进行第一次标记并进行一个筛选，筛选的条件是这个对象是否有必要执行finalize方法。如果没有覆盖finalize方法或者finalize方法已经被执行过，这都没有必要执行。 如果这个对象有必要执行finalize方法，那这个对象会放在是一个F-Queue队列中，由虚拟机自动建立的、优先级低的Finalizer线程来执行，即这个方法会被触发，但是不保证会等待运行结束。如果对象在finalize方法中重新与引用链上的任何一个对象相关联，则在第二次标记时就会被移出即将回收的集合，否则就会被回收。 1234567891011121314151617181920212223242526272829303132public class FinalizeGC &#123; public static FinalizeGC gc = null; @Override protected void finalize() throws Throwable &#123; System.out.println(&quot;finalize method executed&quot;); FinalizeGC.gc = this; &#125; public static void main(String[] args) throws Exception &#123; gc = new FinalizeGC(); //第一次自救 gc = null; System.gc(); Thread.sleep(500);//优先级很低，等待执行下 if(gc != null) &#123; System.out.println(&quot;still alive&quot;); &#125; else &#123; System.out.println(&quot;dead&quot;); &#125; //第二次 gc = null; System.gc(); Thread.sleep(500); if(gc != null) &#123; System.out.println(&quot;still alive&quot;); &#125; else &#123; System.out.println(&quot;dead&quot;); &#125; &#125;&#125; 以上代码会输出 123finalize method executedstill alivedead 可以看出gc对象的finalize方法的确被执行过了，而且也自救了一次。 垃圾回收算法标记-清除算法标记-清除（Mark-Sweep）算法分为标记和清除两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象。（后续的收集算法都是基于这种思路并对其不足进行改造而得到的） Mark-Sweeo的不足： 效率问题，标记和清除两个过程的效率都不高 空间问题，标记清除后会产生大量不连续的内存碎片，空间碎片太多可能导致以后在程序运行的过程中分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾回收。 从上图可以看出在进行标记清除后，内存碎片化非常严重。 复制算法复制算法将可用容量划分为大小相等的两块，每次只使用其中的一块，当这一块内存用完了就将还存储着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这样每次都是对整个半区进行内存回收，内存分配也不需要考虑内存碎片的问题。这种算法虽然实现简单，运行高效，只是代价是将内存缩小为原来的一半，代价太高了。 现在的商业虚拟机都采用这种回收算法来回收新生代，但是研究表明新生代中的对象98%是朝生夕死，所以不需要按1:1划分内存空间，而是将内存分为一块较大的Eden空间和两次较小的Survivor空间，每次使用Eden和其中一块Survivor空间。HotSpot默认Eden和Survivor大小比例是8:1（也就是只有百分10的空间会被浪费）。当Survivor空间不够用时，需要依赖其他内存（老年代）进行分配担保。 标记-整理算法复制算法在对象存活率较高时就要进行较多的复制操作，复制效率就会变低，老年代一般不直接使用复制算法。根据老年代的特征，有人提出了标记整理算法，在对对象进行标记之后，让所有活的对象都想一端移动，然后直接清理掉边界以外的内存。 分代收集算法分代收集法是目前大部分JVM所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况下将GC堆划分为老生代和新生代。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法。 新生代与复制算法目前大部分JVM的GC对于新生代都采取复制算法，因为新生代中每次垃圾回收都要回收大部分对象，即要复制的操作比较少，但通常并不是按照 1:1 来划分新生代。一般将新生代划分为一块较大的Eden空间和两个较小的Survivor空间(From Space, To Space)，每次使用Eden空间和其中的一块Survivor空间，当进行回收时，将该两块空间中还存活的对象复制到另一块Survivor空间中。 老年代与标记复制算法而老年代因为每次只回收少量对象，因而采用标记整理算法。 对象从新生代到老年代： 当新生代的 Eden Space 和 From Space 空间不足时就会发生一次GC，进行GC后，Eden Space 和 From Space 区的存活对象会被挪到 To Space，然后将 Eden Space 和 From Space 进行清理。 如果 To Space 无法足够存储某个对象，则将这个对象存储到老生代。 在进行 GC 后，使用的便是 Eden Space 和 To Space 了，如此反复循环。 当对象在 Survivor 区躲过一次 GC 后，其年龄就会+1。默认情况下年龄到达15的对象会被移到老生代中。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[字典树]]></title>
      <url>%2F20191206%2Fstructure%2F1_trie%2F</url>
      <content type="text"><![CDATA[字典树字典树又称单词查找树，是一种树形的结构，是一种哈希数的变种。典型应用是用于统计、排序和保存大量的字符串，经常被用于文本词频的统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 基本性质 根节点不包含字符，除根节点意外每个节点只包含一个字符。 从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符串不相同。 实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class Trie &#123; private static class Node &#123; public Map&lt;Character, Node&gt; next; public boolean isWord; public int count; public Node() &#123; next = new TreeMap&lt;&gt;(); isWord = true; count = 0; &#125; &#125; private Node root; public Trie() &#123; root = new Node(); &#125; public void addWord(String word) &#123; char[] chars = word.toCharArray(); Node current = root; for (char c : chars) &#123; Node next = current.next.get(c); if (next == null) &#123; current.next.put(c, new Node()); &#125; current = current.next.get(c); &#125; if (!current.isWord) &#123; current.isWord = true; &#125; current.count++; &#125; public int query(String str) &#123; Node current = root; if (root == null) &#123; return 0; &#125; char[] chars = str.toCharArray(); for (char c : chars) &#123; Node next = current.next.get(c); if (next == null) &#123; return 0; &#125; current = next; &#125; return current.count; &#125; public boolean search(String str) &#123; Node current = root; if (root == null) &#123; return false; &#125; char[] chars = str.toCharArray(); for (char c : chars) &#123; Node next = current.next.get(c); if (next == null) &#123; return false; &#125; current = next; &#125; return current.isWord; &#125; public static void main(String[] args) &#123; Trie trie = new Trie(); trie.addWord(&quot;abc&quot;); trie.addWord(&quot;abc&quot;); System.out.println(trie.query(&quot;abc&quot;)); &#125;&#125; 字典树一般仅进行插入操作，然后去判断某个字段串是否存在，或者这个字符串存在的次数。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM内存区域]]></title>
      <url>%2F20191205%2Fjvm%2F1_JVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%2F</url>
      <content type="text"><![CDATA[JVM内存区域Java虚拟机在执行Java程序的过程中会把所管理的内存划分为若干个不同的数据区域。Java虚拟机所管理的内存将会包括以下几个运行时数据区域（Java虚拟机规范（Java SE7））： 线程隔离的数据区生命周期与线程相同，依赖用户线程的启动/结束。线程共享区随着虚拟机的启动/关闭而创建/销毁。 程序计数器程序计数器是一块比较小的空间，可以看作是当前线程所执行的字节码的行号指示器。字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要程序计数器来完成。 如果线程在执行的是一个java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果是Native方法则为空。 这是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 虚拟机栈每个方法在执行的时候都会去创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法调用到执行完成就对应着一个栈帧在虚拟机中入栈到出栈的过程。 局部变量存放了编译期可知的各种基本数据类型、对象引用和returnAddress类型（指向了一条字节码指令的地址）。 此区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机栈所允许的深度，将抛出StackOverflowError；如果虚拟机栈可以动态扩展，如果扩展时无法申请到足够的内存，将会抛出OutOfMemoryError异常。 本地方法栈本地方法栈和虚拟机栈的作用很相似，它们之间的区别是虚拟机栈为虚拟机执行java方法服务，而本地方法栈为虚拟机使用到的Native方法服务。如果一个VM实现使用C-linkage模型支持Native调用，那么该栈将是一个C栈，但HotSpot VM直接把本地方法栈和虚拟机栈合二为一。 与虚拟机栈区域一样，本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 java堆java堆是被所有线程共享的一块区域，在虚拟机启动时创建。几乎所有的对象实例都会在java堆上分配内存。（java虚拟机规范中描述的是：所有对象实例以及数组都要在堆上分配） Java堆是垃圾收集器管理的主要区域，从内存回收的角度来看，现在的收集器基本采用分代手机算法，所以java堆还可以细分为：新生代和老年代；在细一点有Eden空间、From Survivor空间、To Survivor空间等。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，就像磁盘空间一样。如果在堆中没有内存完成实例分配，并且堆也无法在扩展时，就是抛出OutOfMemoryError异常。 方法区（永久代）方法区与Java堆一样，是各个线程共享的内存区域，用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。HotSpot VM把GC分代收集扩展至方法区，即使用Java堆的永久代来实现方法区，这样HotSpot的垃圾收集器就可以像管理Java堆一样管理这部分内存，而不用为方法区开发专门的内存管理器。 当方法区无法满足内存分配需求，就是抛出OutOfMemoryError异常。 运行时常量池运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述符信息外，还有一项信息就是常量池，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法的运行时常量池中的存放。 当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 直接内存直接内存不是虚拟机运行时数据的一部分，也不是java虚拟机规范中定义的内存区域。但是这部分内存也频繁被使用，也可能导致OutOfMemoryError异常出现。在JDK1.4引入的NIO提供了基于通道（Channel）与缓冲区（Buffer）的IO方式，它可以使用Native函数直接分配对外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象座位这块内存的引用进行数据。这样可以在一些场景中显著提升性能，因为避免了在Java堆和Native堆中来回复制数据。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CyclicBarrier阅读]]></title>
      <url>%2F20191204%2Fjavasource%2Futil%2F7_CyclicBarrier%2F</url>
      <content type="text"><![CDATA[CyclicBarrierCyclicBarrier我们叫做栅栏，其实与CountDownLatch的功能类似（CyclicBarrier也可实现CountDownLatch的功能），都是等待多个线程执行完成之后在进行最后的动作，只不过CountDownLatch是一次性的，而CyclicBarrier是可循环的 CyclicBarrier可以使一定数量的线程反复地在栅栏位置处汇集。当线程到达栅栏位置时将调用await方法，这个方法将阻塞直到所有线程都到达栅栏位置。如果所有线程都到达栅栏位置，那么栅栏将打开，此时所有的线程都将被释放，而栅栏将被重置以便下次使用。 源码CyclicBarrier内部主要使用了ReentrantLock和Condition两个类。 构造函数12345678910public CyclicBarrier(int parties, Runnable barrierAction) &#123; if (parties &lt;= 0) throw new IllegalArgumentException(); this.parties = parties; this.count = parties; this.barrierCommand = barrierAction;&#125;public CyclicBarrier(int parties) &#123; this(parties, null);&#125; CyclicBarrier默认的构造函数设置了栅栏拦截的线程数量，每个线程使用await方法告诉CyclicBarrier到达了栅栏，然后当前线程被阻塞。另一个构造函数的第二个参数代表所有线程都到达栅栏时，优先执行的动作（barrierAction）。 await12345678910111213public int await() throws InterruptedException, BrokenBarrierException &#123; try &#123; return dowait(false, 0L); &#125; catch (TimeoutException toe) &#123; throw new Error(toe); // cannot happen &#125;&#125;public int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; return dowait(true, unit.toNanos(timeout));&#125; await方法有两个，默认的没有设置超时等待，第二个设置了超市等待的时间，两个方法最终都是调用的dowait来完成的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; final ReentrantLock lock = this.lock; lock.lock();//独占式加锁 try &#123; final Generation g = generation; if (g.broken)//broken为true抛异常，默认为false throw new BrokenBarrierException(); if (Thread.interrupted()) &#123;//线程中断了 breakBarrier();//broken为true 通知阻塞在栅栏上的其他线程 throw new InterruptedException(); &#125; int index = --count;//获取下标 if (index == 0) &#123; // tripped 如果是0，则说明最后一个线程调用了此方法 boolean ranAction = false; try &#123; final Runnable command = barrierCommand; if (command != null) command.run(); //如果command不为空 就先执行 最后的动作 ranAction = true;//执行完 nextGeneration();//唤醒所有阻塞的线程并重新初始化 return 0; &#125; finally &#123; if (!ranAction)//如果执行栅栏任务的时候失败了，就将broken设置为true breakBarrier(); &#125; &#125; for (;;) &#123;//最后一个线程还没执行到 try &#123; if (!timed)//没有时间限制 则直接阻塞等待，直到被唤醒 trip.await(); else if (nanos &gt; 0L) nanos = trip.awaitNanos(nanos);//阻塞指定时间 &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123;//当前代broken是false，设置broken为false，抛异常，代表此待结束 breakBarrier(); throw ie; &#125; else &#123; Thread.currentThread().interrupt();//不是当前代，中断标记 &#125; &#125; if (g.broken)// 当有任何一个线程中断了，会唤醒其他线程，剩余线程也要跑异常 throw new BrokenBarrierException(); if (g != generation)//换代 （因为一个线程可以使用多个栅栏，当别的栅栏唤醒了这个线程，就会走到这里，所以需要判断是否是当前代。） return index; // 如果有时间限制，且时间小于等于0，销毁栅栏并抛出异常 if (timed &amp;&amp; nanos &lt;= 0L) &#123; breakBarrier(); throw new TimeoutException(); &#125; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 如果该线程不是最后一个调用await方法的线程，则它会一直处于等待状态，除非发生以下情况： 最后一个线程到达，即index == 0 某个参与线程等待超时 某个参与线程被中断 调用了CyclicBarrier的reset()方法。重新初始化栅栏 总结 CyclicBarrier使用ReentrantLock独占锁来执行await，并发性会受影响。 如果等待过程，线程被中断了就会抛异常。 如果线程被其他的CyclicBarrier线程唤醒，g肯定是当前代，循环阻塞。否则是被当前CyclicBarrier唤醒的，返回下标完成一次全抵达栅栏的过程。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ReentrantReadWriteLock阅读]]></title>
      <url>%2F20191203%2Fjavasource%2Futil%2F6_ReentrantReadWriteLock%2F</url>
      <content type="text"><![CDATA[ReentrantReadWriteLockReentrantReadWriteLock实现的是ReadWriteLock接口，ReadWriteLock接口中只定义了 readLock 和 writeLock 方法。 readLock 和 writeLock方法分别返回了内部的读锁和写锁。12public ReentrantReadWriteLock.WriteLock writeLock() &#123; return writerLock; &#125;public ReentrantReadWriteLock.ReadLock readLock() &#123; return readerLock; &#125; ReadLock和WriteLock方法都是通过Sync的方法实现的，所以Sync是读写锁的核心： 对同一线程，读，写读，写写是共享的，读写是互斥的；对于不同线程而言，读是共享的，读写、写写、写读都是互斥的。 SyncSync中的常量和结构1234567891011121314151617181920212223242526//低16位为写锁状态，高16位为读锁状态static final int SHARED_SHIFT = 16;//读锁每次增加的单位static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT);//读锁的最大数static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1;//写锁的掩码static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1;//返回读锁的数量static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125;//返回写锁的数量 EXCLUSIVE_MASK 高位都是0static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125;//当前读线程的计数器static final class HoldCounter &#123; int count = 0;//当前读线程的重入数 final long tid = getThreadId(Thread.currentThread());&#125;static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; &#123;//本地程序计数器 public HoldCounter initialValue() &#123; return new HoldCounter(); &#125;&#125;private transient ThreadLocalHoldCounter readHolds;private transient HoldCounter cachedHoldCounter;//当前线程缓存的HoldCounterprivate transient Thread firstReader = null;//第一个读线程private transient int firstReaderHoldCount; 构造方法Sync的构造方法设置了本地线程计数器和AQS的状态 1234Sync() &#123;readHolds = new ThreadLocalHoldCounter();setState(getState()); // ensures visibility of readHolds&#125; tryAcquire 写锁的获取1234567891011121314151617181920protected final boolean tryAcquire(int acquires) &#123; Thread current = Thread.currentThread(); int c = getState(); int w = exclusiveCount(c);//写锁的重入数 if (c != 0) &#123;//已经有其他线程获取了读锁或者写锁 //1.写锁状态为0，说明读锁已被获取 2.写锁不为0，而且获取写锁的不是当前线程 if (w == 0 || current != getExclusiveOwnerThread()) return false; //判断统一线程获取写锁是否超过最大数 if (w + exclusiveCount(acquires) &gt; MAX_COUNT) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(c + acquires);//当前线程已有写锁，设置写锁的数量（重入） return true; &#125; if (writerShouldBlock() || //是否被阻塞 !compareAndSetState(c, c + acquires))//获取锁 return false; setExclusiveOwnerThread(current); return true;&#125; 写锁的获取： 获取state的状态，如果不为0说明已经被获取过锁了； 如果读锁被获取（写锁为0）或者 写锁被获取 但不是当前线程，返回false。 如果写锁是当前线程获取的，判断是不是超过写锁的最大数，没有就设置现在写锁的个数，返回true。 如果state为0，就代表还没有线程获取到读锁和写锁，此时判断writerShouldBlock是否该被阻塞，如果不被阻塞，设置state也成功，就把当前线程设置为owner。 tryRelease 写锁的释放12345678910protected final boolean tryRelease(int releases) &#123; if (!isHeldExclusively())//检查是不是当前线程 throw new IllegalMonitorStateException(); int nextc = getState() - releases;//新占用数 boolean free = exclusiveCount(nextc) == 0;//独占模式重入数为0，代表独占模式释放了 if (free) setExclusiveOwnerThread(null);//把owner设置为空 setState(nextc); return free;&#125; 先检查此线程是不是持有读锁的线程，不是就抛异常。 然后检查释放后写锁的占用数是不是0，如果为0则表示写锁释放，释放锁资源将锁的持有线程设置为null，否则仅仅修改state。 tryAcquireShared 读锁的获取123456789101112131415161718192021222324252627282930protected final int tryAcquireShared(int unused) &#123; Thread current = Thread.currentThread(); int c = getState(); //有写锁占用，并且不是当前线程 if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) return -1; int r = sharedCount(c);//读锁数量 if (!readerShouldBlock() &amp;&amp;//读锁是否需要阻塞 r &lt; MAX_COUNT &amp;&amp;//小于最大数 compareAndSetState(c, c + SHARED_UNIT)) &#123;//设置读锁成功 if (r == 0) &#123;//没有读锁，初始化 firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++;//第一个读锁线程重入 &#125; else &#123;//不是第一个读锁的线程 HoldCounter rh = cachedHoldCounter; // 计数器为空或者计数器的tid不为当前正在运行的线程的tid if (rh == null || rh.tid != getThreadId(current)) // 获取当前线程对应的计数器 cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) // 计数为0 readHolds.set(rh);//加入到readHolds中 rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 先判断写锁不为0，并且不是当前线程，直接返回-1； 然后判断如果读锁不需要阻塞，小于最大读锁的数，并且比较设置state成功： 如果没有读锁，则初始化第一个读锁 如果第一个读锁线程已持有读锁，进行重入 如果不是第一个读锁的线程：计数器为空或者tid不是当前线程，获取当前线程的计数器；获取计数器为0，加入到readHolds中。最后计数+1 读锁不需要阻塞、小于最大读锁的数、比较设置state成功这三个条件有一个为false会执行 fullTryAcquireShared 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344final int fullTryAcquireShared(Thread current) &#123; HoldCounter rh = null; for (;;) &#123; int c = getState(); if (exclusiveCount(c) != 0) &#123;//有写锁 if (getExclusiveOwnerThread() != current)//不是当前线程 return -1; &#125; else if (readerShouldBlock()) &#123;//读锁要被阻塞（公平） if (firstReader == current) &#123;//当前线程是第一个读线程 &#125; else &#123; if (rh == null) &#123; rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; rh = readHolds.get();//获取到当前线程的计数器 if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT)//读锁是最大值了 throw new Error(&quot;Maximum lock count exceeded&quot;); if (compareAndSetState(c, c + SHARED_UNIT)) &#123;//设置读锁成功 if (sharedCount(c) == 0) &#123;//没有读锁初始化 firstReader = current; firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123;//重入 firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125;&#125; 此方法与tryAcquireShared方法类似，保证了相关操作可以执行 tryReleaseShared 读锁的释放123456789101112131415161718192021222324252627protected final boolean tryReleaseShared(int unused) &#123; Thread current = Thread.currentThread(); if (firstReader == current) &#123;//第一个读线程 if (firstReaderHoldCount == 1)//第一个读线程重入数为1 firstReader = null;// else firstReaderHoldCount--;//第一个读线程重入数-1 &#125; else &#123; HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get();//获取到当前线程的计数器 int count = rh.count; if (count &lt;= 1) &#123; readHolds.remove(); if (count &lt;= 0) throw unmatchedUnlockException(); &#125; //减少计数 --rh.count; &#125; for (;;) &#123;//CAS设置state int c = getState(); int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 首先判断当前线程是否是第一个读线程，是的话，而且计数器为1，将firstReader设置为null，否则将firstReaderHoldCount-1； 如不是第一个读线程，先获取当前线程的计数器，若计数器的count小于等于1，则移除当前线程的计数器，如果计数器的计数count小于等于0，则抛出异常，之后再减少计数即可。 CAS设置state NonfairSync（非公平模式）123456789static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -8159625535654395037L; final boolean writerShouldBlock() &#123; return false; // writers can always barge &#125; final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive(); &#125;&#125; 非公平模式的NonfairSync也是继承了Sync，实现了Sync的writerShouldBlock 和 readerShouldBlock 方法： writerShouldBlock：非公平模式下，写锁不需要被阻塞。 readerShouldBlock：调用apparentlyFirstQueuedIsExclusive，如果队列中第一个节点是独占式，则返回true，堵塞读锁。 如果同步队列中的第一个线程是以独占模式获取锁（写锁），那么当前获取读锁的线程需要阻塞，让队列中的第一个线程先执行。 FairSync（公平模式）123456789static final class FairSync extends Sync &#123; private static final long serialVersionUID = -2274990926593161451L; final boolean writerShouldBlock() &#123; return hasQueuedPredecessors(); &#125; final boolean readerShouldBlock() &#123; return hasQueuedPredecessors(); &#125;&#125; 公平模式下的实现了Sync的writerShouldBlock 和 readerShouldBlock 方法实现都一样：判断是否是等待队列中是否有前置节点，有则返回true。 ReadLock 和 WriteLockReentrantReadWriteLock中的ReadLock和WriteLock内部的Sync都是使用的ReentrantReadWriteLock的Sync，读锁和写锁的实现也都是通过调用Sync的方法来实现的，具体不就看了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Semaphore阅读]]></title>
      <url>%2F20191203%2Fjavasource%2Futil%2F9_Semaphore%2F</url>
      <content type="text"><![CDATA[SemaphoreSemaphore是一个计数信号量，必须由获取它的线程释放。常用于限制可以访问某些资源的线程数量，利用Semaphore限流。 Semaphore有两种模式，公平模式和非公平模式。公平模式就是调用acquire的顺序就是获取许可证的顺序，遵循FIFO;而非公平锁是抢占式的，有可能一个新的线程获取许可证的时候刚刚有释放的许可，但是还有正在等待许可的线程还在等待。 Semaphore内部主要是通过Sync继承了AQS来实现信号量的功能，内部工作流程还是基于AQS。 构造函数1234567public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125;public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; Semaphore的构造函数有两个： Semaphore(int permits) ：提供了一个许可数量的入参，默认给内部Sync的是非公平方式。 Semaphore(int permits, boolean fair) ：也需要提供提个许可数量的入参，fair来指定是公平模式还是非公平模式。 Sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 1192457210091910933L; //设置状态数 Sync(int permits) &#123; setState(permits); &#125; //获取许可数 final int getPermits() &#123; return getState(); &#125; //非公平模式下的获取 final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; int available = getState(); int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining))//如果许可小于0 或者 设置成功 return remaining; &#125; &#125; //共享模式下释放 protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; int current = getState(); int next = current + releases;//可用的许可 if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next))//设置成功返回true return true; &#125; &#125; //减少许可的数据 final void reducePermits(int reductions) &#123; for (;;) &#123; int current = getState(); int next = current - reductions; if (next &gt; current) // underflow 不能大于当前许可的数量 throw new Error(&quot;Permit count underflow&quot;); if (compareAndSetState(current, next)) return; &#125; &#125; //获取返回所有可用的许可 final int drainPermits() &#123; for (;;) &#123; int current = getState(); if (current == 0 || compareAndSetState(current, 0)) return current; &#125; &#125;&#125; Sync定义了非公平模式的获取 和 释放许可的方法，还定义了减少许可】获取所有许可的方法。内部NonfairSync和FairSync都继承于Sync。 NonfairSync和FairSync1234567891011static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = -2694183684443567898L; NonfairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires);//直接调用Sync的nonfairTryAcquireShared &#125;&#125; NonfairSync类继承了Sync类，表示采用非公平策略获取资源，其只有一个tryAcquireShared方法，重写了AQS的该方法，直接调用了父类的nonfairTryAcquireShared。 12345678910111213141516171819static final class FairSync extends Sync &#123; private static final long serialVersionUID = 2014338818796000944L; FairSync(int permits) &#123; super(permits); &#125; protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; if (hasQueuedPredecessors())//如果前面有其他节点在等待，返回-1 return -1; int available = getState(); int remaining = available - acquires;//剩余的许可 if (remaining &lt; 0 || compareAndSetState(available, remaining))//剩余的许可小于0或者比较设置成功 return remaining; &#125; &#125;&#125; FairSync类继承了Sync类，表示采用公平策略获取资源，使用公平策略来获取资源，会判断同步队列中是否存在其他的等待节点。 Semaphore的核心方法acquire此方法从信号量获取一个（多个）许可，在提供一个许可前一直将线程阻塞，或者线程被中断。 123public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 该方法调用了AQS的acquireSharedInterruptibly，这个方法会先去执行tryAcquireShared去获取资源，如果返回的小于0，就是执行AQS的doAcquireSharedInterruptibly，直接加入阻塞队列，如果前面没有节点（pre是head），会尝试去获取，否则就进入阻塞。 releaserelease方法释放指定数量的许可。 123public void release() &#123; sync.releaseShared(1);&#125; release方法也是直接调用了AQS的releaseShared，在释放许可成功后，会唤醒其他节点。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[CountDownLatch阅读]]></title>
      <url>%2F20191202%2Fjavasource%2Futil%2F8_CountDownLatch%2F</url>
      <content type="text"><![CDATA[CountDownLatchcountDownLatch这个类使一个线程等待其他线程各自执行完毕后再执行。是通过一个计数器来实现的，计数器的初始值是线程的数量。每当一个线程执行完毕后，计数器的值就-1，当计数器的值为0时，表示所有线程都执行完毕，然后在闭锁上等待的线程就可以恢复工作了。 countDownLatch的实现也很简单，也是通过内部Sync实现了AQS就完成了功能。 Sync123456789101112131415161718192021222324252627private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125;&#125; Sync的构造方法就会给AQS的state设置一个数，释放资源（tryReleaseShared）的时候通过CAS操作去将state-1。 CountDownLatch的实现一般我们会定义CountDownLatch的时候，new的时候会设置一个count，也就是等待count个线程完成之后，在执行的当前的线程。 1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); this.sync = new Sync(count);&#125; 如果count小于当然就是报错，然后就创建了一个内部的Sync。 调用await的时候，就是将当前线程进行阻塞：123public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; await方式直接调用的AQS的acquireSharedInterruptibly方法，AQS中acquireSharedInterruptibly调用了doAcquireSharedInterruptibly：12345678910111213141516171819202122232425private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; doAcquireSharedInterruptibly和其他同步阻塞方法一样，先将node包装为共享模式然后加入Waiter队列，如果node的前一个节点是头结点就尝试去获取资源，如果获取到将本节点设置为头结点然后唤醒剩余共享节点返回，否则就将此线程阻塞。 如果我们等待其他线程每完成一个就会调用countDown方法：123public void countDown() &#123; sync.releaseShared(1);&#125; releaseShared就相当于先执行了tryReleaseShared（先以CAS的方式将state-1），然后执行AQS的doReleaseShared方法。doReleaseShared方法可以参考，就是对共享模式的node进行唤醒，如果state为0的时候，就会唤醒，此时此线程已等待其他线程执行完毕，就可以开始执行了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ReentrantLock阅读]]></title>
      <url>%2F20191201%2Fjavasource%2Futil%2F5_ReentrantLock%2F</url>
      <content type="text"><![CDATA[ReentrantLockReentrantLock是一个互斥锁，也是一个可重入锁。ReentrantLock锁在同一时刻只能被一个线程持有，但是它可被单个线程多次获取，每获取一次AQS的state就加1。ReentrantLock内部的实现（公平锁和非公平锁）都是基于内部Sync的实现。 内部结构ReentrantLock内部定义了三个重要的内部类，Sync、FairSync、NonfairSync。 Sync继承自抽象类AbstractQueuedSynchronizer，FairSync（公平锁）和 NonfairSync（非公平锁）继承于Sync。 Sync123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263abstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; abstract void lock(); //非公平锁的TryAcquire final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123;//没有被任何线程持有 if (compareAndSetState(0, acquires)) &#123;//CAS 获取 setExclusiveOwnerThread(current);//获取成功，将当前线程设置为Owner return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123;//如果当前线程已获取锁，将state+1返回 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125; protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread())//如果当前线程不是持有锁的线程抛异常 throw new IllegalMonitorStateException(); boolean free = false;//标明释放释放锁 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125; //持有锁的线程是否是当前线程 protected final boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() == Thread.currentThread(); &#125; //newCondition final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; //持有锁的线程 final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; final boolean isLocked() &#123; return getState() != 0; &#125; private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; Sync是ReentrantLock实现同步控制的基础。Sync内部定义了一些方法：lock（获取锁的方法，在子类实现）、nonfairTryAcquire（非公平锁的尝试获取资源）、tryRelease（释放资源）。 NonfairSync1234567891011121314static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; NonfairSync是内部非公平锁的定义，非公平锁获取锁的流程： 调用lock方法,lock方法首先会进行CAS操作,将state属性尝试设置为1,如果成功,则代表获取到锁,将exclusiveOwnerThread属性设置为当前获取锁的线程。 如果线程CAS失败,则调用AQS的acquire方法,去获取锁,tryAcquire(1)是子类自己的实现,调用了nonfairTryAcquire方法。如果调用了nonfairTryAcquire方法获取锁失败，那就会吧当前线程包装为Node加入同步队列。 FairSync12345678910111213141516171819202122232425262728static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; acquire(1); &#125; //tryAcquire方法的公平锁版本,虽然是公平的,但是不保证一定会获取锁,除非是递归调用或者是第一个节点或者是前面无等待线程 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //hasQueuedPredecessors方法判断当先线程前面是否还有等待线程，如果有等待线程,则不去竞争获取锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error(&quot;Maximum lock count exceeded&quot;); setState(nextc); return true; &#125; return false; &#125;&#125; 公平锁在加锁的时候不会先尝试去加锁，直接去调用AQS的acquire方法去获取锁，在自己定义的尝试获取资源中，如果state为0，也会先去判断当前线程前面是否还有线程等待，如果没有等待的线程才会自己获取锁，否则加入等待队列；如果是当前线程获取到了锁则state+1. 公平锁和非公平锁的不同 公平锁能保证：老的线程排队使用锁，新线程仍然排队使用锁。 非公平锁保证：老的线程排队使用锁；但是无法保证新线程抢占已经在排队的线程的锁。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[synchronized]]></title>
      <url>%2F20191127%2Fjava%2F5_synchronized%2F</url>
      <content type="text"><![CDATA[synchronized 可以使用任意一个非空的对象当做锁。synchronized属于独占式的悲观锁，也是可重入锁。它可以保证同一时刻只有一个线程执行某个方法或某个代码块，还可保证共享变量的可见性。 synchronized的三种作用范围 作用于方法，锁住的是对象实例。 作用于代码块，指定加锁对象。 作用于静态方法，锁住的是class实例，相当于类的全局锁。 java对象头和Monitor（来自深入理解java虚拟机）在HotSpot虚拟机中，对象在内存中存储的布局可以分为3块区域：对象头（Header）、实例数据（Instance Data）和对齐填充（Padding）。 对象头：对象头主要包括两部分信息，第一部分用于存储对象自身的的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态表示、线程持有的锁、偏向线程ID、偏向时间戳等，这部分数据长度在32为和64为虚拟机中分别为32bit和64bit，简称Mark Word。对象头的另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。如果对象是一个数组，在对象头还必须有一块用于记录数组长度的数据（1字节），这样虚拟机可以通过普通java对象的元数据信息确定java对象的大小。 由于对象运行时的数据很多，已经超过了32/64位bit能记录的限度，但是对象头信息是与对象自身定义的数据无关的额外存储，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间存储尽量多的数据。 实例数据：这是对象真正存储的有效信息，就是代码中定义的各种字段内容（包括从父类继承的）。 对齐填充：这部分不是必然存在的，仅仅是占位符的作用，JVM 要求对象起始地址必须是8字节的整数倍。（对象大小必须是8字节的整数倍） Mark Word 默认存储 锁状态 25bit 4bit 1bit是否是偏向锁 2bit锁标志位 无锁状态 对象HashCode 对象分代年龄 0 01 可能变化的结构： 锁状态25bit4bit1bit2bit23bit2bit是否是偏向锁锁标志位轻量级锁指向栈中锁记录的指针00重量级锁指向重量级锁的指针10GC标记空，不需要记录信息11偏向锁偏向线程ID偏向时间戳对象分代年龄101 在锁标志位为10时，也就是代表重量级锁（synchronized），其中指针指向的是Monitor对象的起始地址。每个对象都与一个Monitor关联，对象和其Monitor之间有多种实现的方式（Monitor可以和对象一起创建销毁或获取锁对象的时候生成），但是当一个Monitor被某个线程持有便处于锁定状态。 Monitor是由C++实现的，核心组件如下 ： WaitSet：调用wait的方法被阻塞的线程被放在这； ContentionList：竞争队列，所有请求锁的线程被先放在这个队列； EntryList：Contention中资格成功候选资源的线程被放入这； OnDeck：任意时刻，只有一个线程正在竞争锁，该线程就是OnDeck； Owner：当前获取到锁资源的线程被称为Owner； !Owner：当前释放锁的线程； synchronized原理对于同步方法，JVM采用ACC_SYNCHRONIZED标记符来实现；对于同步代码块，JVM采用monitorenter、monitorexit来实现。 方法级同步是隐式的。同步方法的常量池中会有一个ACC_SYNCHRONIZED标识，当某个线程访问某方法的时候，会先检查有没有ACC_SYNCHRONIZED标识，如果有的话，需要去获取监视器锁，然后开始执行方法，执行完之后释放锁。此时如果有其他线程来执行，则会因为获取不到监视器锁而被阻塞。 可以把执行monitorenter指令理解为加锁，执行monitorexit理解为释放锁。 每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为0，当一个线程获得锁（执行monitorenter）后，该计数器自增变为 1 ，当同一个线程再次获得该对象的锁的时候，计数器再次自增。当同一个线程释放锁（执行monitorexit指令）的时候，计数器再自减。当计数器为0的时候。锁将被释放，其他线程便可以获得锁。 JVM每次从队列尾部取出一个数据用于锁的竞争候选者（OnDeck），但是并发情况，ContentionList会被大量的并发线程进行CAS访问，为了降低对尾部元素的竞争，JVM会将一部分线程移动到EntryList中作为候选竞争线程。 Owner线程会在unlock时，将ContentionList中部分线程迁移到EntryList中，并制定EntryList中某个线程为OnDeck现场。（一般是最先进去的线程） Owner线程不直接把锁传递给OnDeck线程，而是把锁竞争权利交给OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了公平性，但是可以极大提升系统的吞吐量。（这种行为成为竞争切换） OnDeck线程获取到锁资源后会变为Owner线程，没有获取到锁资源的话会继续停留在EntryList中（仍是头部）。如果Owner线程为wait阻塞则会被转移到waitset队列，等到被notify或notifyAll唤醒，会重新进入EntryList。 处于ContentionList、EntryList、WaitSet中的线程都是阻塞状态的。（由操作系统完成） Synchronized是非公平锁。Synchronized在线程进入ContentionList时，等待的线程会先尝试获取锁，获取不到才进去ContentionList，自旋获取锁可能会直接抢占OnDeck线程的锁资源。 Synchronized锁优化高效并发是JDK1.5到JDK1.6的的一个重要改进，HotSpot团队实现来了很多锁优化的技术，例如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁。 无锁-&gt;偏向锁-&gt;轻量级锁-&gt;重量级锁，它会随着竞争情况逐渐升级。锁可以升级但不能降级，目的是为了提高获得锁和释放锁的效率。 自旋锁与适应性自旋互斥同步对性能影响最大的是阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态来实现，这些操作会给内核系统的并发性带来很大的压力。同时虚拟机的团队注意到很多应用共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程很不值得。如果物理机上有一个以上的处理器，能让两个或者以上的线程同时执行就可以让后面请求锁的那个线程稍等一下，不放弃处理器的执行时间，看看持有锁的线程是否很快会释放锁。为了让线程等待只需要让线程进行一个自旋，这就是自旋锁。自旋锁在JDK1.4.2就被引入，默认是关闭的，可通过-XX:+UseSpinning参数开启，在JDK1.6中就改为默认开启了。自旋不能代替阻塞，自旋虽然避免了线程切换带来的开销，但是需要占用处理器的时间，如果占用处理的时间很长，那就白白消耗处理器的资源，反而性能被浪费。因此自旋等待时间有个限度，如果超过限度的自旋次数还没获取锁就去挂起线程。自旋的默认次数是10次，可使用-XX:PreBlockSpin来修改。在JDK1.6中引入了自适应的自旋锁。自适应意味着自旋的时间不在固定，而是由前一次在同一个锁上的自旋时间以及锁的拥有者状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行，那虚拟机会认为这次自旋也有可能再次获取成功，进而它的允许自旋等待时间将会更长。如果对于某个锁，自旋很少成功获取过，那么在以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器的资源。 锁消除锁消除是指虚拟机即时编译器运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除主要判定依据来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据均不会逃逸到出去从而被其他线程访问到，那就可以吧他们当做展示数据对待，认为它们是线程私有的，同步加锁自然无需执行。 锁消除主要是由于很多同步措施不是我们自己加入的，同步的代码在java程序中的普遍程度超过了大多数人的想象。如下代码无论从源码字面还是程序语义上都没有同步。 123public String concatString(String s1, String s2, String s3) &#123; return s1 + s2 + s3;&#125; 由于String是不可变的类，对字符串的连接操作总是通过生成新的String对象来进行，因此Javac编译器会对String连接做字段优化。所以上述代码可能会被优化为如下: 1234567public String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 每个StringBuffer.append()方法中都有一个同步块，锁就是sb对象，如果虚拟机发现它的动态作用域被限制在concatString()方法的内部。sb的所有引用不会逃逸到concatString()方法的外部，其他线程也不会访问到它。因此虽然这里有锁，但是可以被安全的消除，在即时编译红藕，这段代码就会忽略掉所有的同步而直接执行。 锁粗化原则上，在编写代码的时候，推荐将同步快的作用范围限制的很小，只在共享数据的实际作用域中才进行同步，这样为了使得同步的操作数据尽可能的小，如果存在竞争，那等待锁的线程也可以尽快拿到锁。如果一系列连续操作都对同一对象反复加锁和解锁，甚至加锁操作出现在循环体中，即便没有线程竞争也会造成不必要的性能消耗。例如1234567public String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 上述代码就是这种情况，虚拟机检测到这样的零碎操作都对同一对象加锁，则会把加锁同步的范围扩大道整个操作序列的外部，这样只需要加锁一次即可。 轻量级锁轻量级锁是相对于使用操作系统互斥量来实现的传统锁而言，轻量级锁不是来代替重量级锁，而是在没有多线程竞争的前提下减少传统的重量级锁使用操作系统的互斥量产生的性能消耗。 加锁过程如下： 在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。 拷贝对象头中的Mark Word复制到锁记录（Lock Record）中； 拷贝成功后，虚拟机将使用CAS操作尝试将锁对象的Mark Word更新为指向Lock Record的指针，并将线程栈帧中的Lock Record里的owner指针指向Object的 Mark Word。 如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，即表示此对象处于轻量级锁定状态，这时候线程堆栈与对象头的状态如图所示。 如果这个更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁就要膨胀为重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。 偏向锁偏向锁的目的是消除数据在无竞争情况下的同步原语，如果轻量级锁是在无竞争情况下使用CAS操作去消除同步使用的互斥量，那偏向锁就是无竞争情况下吧整个同步都消除，CAS操作也不需要。 偏向锁意思是这个锁会偏向于第一个获取它的线程，如果在接下来的过程中，该锁没有被其他线程获取，则持有偏向锁的线程将永远不需要进行同步。 当锁对象第一次被线程获取到的时候，虚拟机将会吧对象头中的标志位设为01，即偏向模式，同时使用CAS操作将获取到这个锁的线程ID记录到对象的Mark Word中，如果CAS成功，持有偏向锁的线程以后每次即进入这个锁相关的同步块时，虚拟机可以不进行任何同步操作。 当有另外一个线程尝试获取这个锁时，偏向锁就结束了。根据对象目前是否处于被锁定状态，撤销偏向后恢复到未锁定或轻量级锁的状态。 锁偏向可以提高带有同步但无竞争的程序性能。但是程序中大多数锁总是被多个不同的线程访问，那偏向模式则是多余的，可以通过-XX:UseBiasedLocking来禁止偏向锁优化。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[java集合简述]]></title>
      <url>%2F20191124%2Fjava%2F4_%E9%9B%86%E5%90%88%E7%AE%80%E4%BB%8B%2F</url>
      <content type="text"><![CDATA[java集合java集合类存放在java.util下面，主要有三种：Set，List，Map。 Collection 是集合Set、List和Queue最基本的接口 Iterator 可以使用迭代器遍历集合中的元素 Map 是key value映射形式的基本接口 ArrayList 有序，底层是数组，查询快，增删慢，线程不安全，扩容 n*1.5+1 List Vector 有序，底层是数组，查询快，增删慢，线程安全，扩容n*2 LinkedList 有序，底层双向循环链表，查询慢，增删快，线程不安全 Collection HashSet 无序，元素不可重复，封装HashMap实现，存取都比较快 集合 Set TreeSet 无序，元素不可重复，底层使用二叉树实现，内部是TreeMap的SortedSet LinkedHashSet 使用Hash表存储，用双向链表记录插入顺序 Queue 在两端出入的List，可使用数组或者链表进行实现 HashMap 底层是hash存储，线程不安全，key和value都可为null Map HashTable 底层是hash存储，线程安全，key和value都不可以为null TreeMap 使用二叉树实现 ListList的实现类主要是ArrayList，Vector，LinkedList ArrayListArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间中。当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 Vector（线程安全）Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问 ArrayList 慢。 LinkList（链表）LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供了 List 接口中没有定义的方法，专门用于操作表头和表尾元素，可以当作堆 栈、队列和双向队列使用。 Setset主要是存储无序元素，元素的值不能重复。主要有HashSet，TreeSet和LinkedHashSet。 HashSetHashSet内部其实是封装了HashMap，通过对内部HashMap的操作来实现HashSet的功能。 TreeSetTreeSet是使用二叉树的原理对新 add()的对象按照指定的顺序排序(升序、降序)，每增加一个对象都会进行排序，将对象插入的二叉树指定的位置。TreeSet是基于TreeMap实现的，TreeSet的元素支持2种排序方式：自然排序或者根据提供的Comparator进行排序。TreeSet的特点： 不能有重复的元素； 具有排序功能； TreeSet中的元素必须实现Comparable接口并重写compareTo()方法，TreeSet判断元素是否重复 、以及确定元素的顺序 靠的都是这个方法； 对于Java类库中定义的类，TreeSet可以直接对其进行存储，如String，Integer等,因为这些类已经实现了Comparable接口); 对于自定义类，如果不做适当的处理，TreeSet中只能存储一个该类型的对象实例，否则无法判断是否重复。 依赖TreeMap。 相对HashSet,TreeSet的优势是有序，劣势是相对读取慢。根据不同的场景选择不同的集合。 LinkedHashSetLinkedHashSet具有set集合不重复的特点，同时具有可预测的迭代顺序，也就是我们插入的顺序，它也是线程不安全的集合。LinkedHashSet继承自HashSet，唯一的区别是LinkedHashSet内部使用的是LinkHashMap。这样做的意义或者好处就是LinkedHashSet中的元素顺序是可以保证的，也就是说遍历序和插入序是一致的。 Queue队列就是一个先入先出（FIFO）的数据结构。 没有实现的阻塞接口的LinkedList，实现了java.util.Queue接口和java.util.AbstractQueue接口 实现阻塞接口的（BlockingQueue）： ArrayBlockingQueue ：一个由数组支持的有界队列。 LinkedBlockingQueue ：一个由链接节点支持的可选有界队列。 PriorityBlockingQueue ：一个由优先级堆支持的无界优先级队列。 DelayQueue ：一个由优先级堆支持的、基于时间的调度队列。 SynchronousQueue ：一个利用 BlockingQueue 接口的简单聚集（rendezvous）机制。 MapMap是存储的key value形式的数据，Map的主要是实现有5种，HashMap，ConcurrentHashMap，HashTable，TreeMap，LinkedHashMap HashMapHashMap是通过hash表来实现键值对的存储，在JDK1.8与1.7的实现上还不同，具体的源码分析可以见 HashMap阅读 （1.8|1.7） ConcurrentHashMapConcurrentHashMap 是线程安全的HashMap，但是此实现下的get方法其实是弱一致性的，有可能获取到过期的数据，具体的源码分析可以见 ConcurrentHashMap(1.7|1.8)阅读 HashTableHashtable 是遗留类，很多映射的常用功能与 HashMap 类似，不同的是它承自 Dictionary 类，并且是线程安全的，任一时间只有一个线程能写 Hashtable，并发性不如 ConcurrentHashMap，因为ConcurrentHashMap(1.7)引入了分段锁。但是HashTable的方法都是强一致性的，对数据的一致性要求没有那么苛刻不建议使用HashTable，可以使用ConcurrentHashMap替代。 TreeMap（二叉树实现）TreeMap 实现 SortedMap 接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的。在使用 TreeMap 时，key 必须实现 Comparable 接口或者在构造 TreeMap 传入自定义的Comparator，否则会在运行时抛出 java.lang.ClassCastException 类型的异常。 LinkedHashMapLinkedHashMap保存了记录的插入顺序，在用 Iterator 遍历LinkedHashMap 时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 LinkedHashMap继承了HashMap，所以他们很多地方是相似的。LinkedHashMap结构中还维护着一个双向链表，用于记录顺序，所以可以做到跟存入顺序一样取出元素。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[ConcurrentHashMap(1.7|1.8)阅读]]></title>
      <url>%2F20191121%2Fjavasource%2Futil%2F4_ConcurrentHashMap%2F</url>
      <content type="text"><![CDATA[ConcurrentHashMapjdk1.7ConcurrentHashMap 和 HashMap非常类似，ConcurrentHashMap在实现上采取了分段锁的思想来实现的。 ConcurrentHashMap在内部采用了一个叫做 Segment 的结构，一个Segment就类似HashMap中的table，这样在定位一个元素的时候，需要进行两次hash操作，一次定位到Segment，第二次定位到Segment中的table的index。这样带来的好处的是写操作只需要针对对应的Segment的进行写，因此Segment的数量就是理论最大的并发数。 ConcurrentHashMap的结构类似如下： Segment123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; //重试次数 单核 1 多核64 static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; //Segment中的table transient volatile HashEntry&lt;K,V&gt;[] table; //元素的数量 transient int count; //对table的大小造成影响的操作的数量 transient int modCount; //阈值 transient int threshold; //负载因子 final float loadFactor; //构造函数 Segment(float lf, int threshold, HashEntry&lt;K,V&gt;[] tab) &#123; this.loadFactor = lf; this.threshold = threshold; this.table = tab; &#125; final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //获取锁（针对Segment），获取到node为null，否则调用scanAndLockForPut方法 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; //Segment中的table HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); for (HashEntry&lt;K,V&gt; e = first;;) &#123; //对应index上的链表节点不为空，看看是不是有相等的key，有相等的key就替换； if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next;//遍历下一个 &#125; else &#123; //链表节点为空 if (node != null) node.setNext(first);//加到链表的头部 else //node为空就得新建 node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); //需不需要rehash else setEntryAt(tab, index, node);//直接插入node到指定index位置 ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; @SuppressWarnings(&quot;unchecked&quot;) private void rehash(HashEntry&lt;K,V&gt; node) &#123; HashEntry&lt;K,V&gt;[] oldTable = table;//旧的table int oldCapacity = oldTable.length; int newCapacity = oldCapacity &lt;&lt; 1; threshold = (int)(newCapacity * loadFactor); HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity];//新的table int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) &#123;//遍历旧的table HashEntry&lt;K,V&gt; e = oldTable[i]; //每个table的第一个entry if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; //重新计算新的index if (next == null) // Single node on list 只有一个元素 newTable[idx] = e;//直接在新的table新index上赋值该节点 else &#123; // Reuse consecutive sequence at same slot HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123;//遍历链表 int k = last.hash &amp; sizeMask; //在新table的位置 if (k != lastIdx) &#123;//头结点和头结点的next元素的节点发生了变化 lastIdx = k; lastRun = last; &#125; &#125; // 1. lastRun 和 lastIdx 没有发生变化,也就是整个链表的每个元素位置和一样,都没有发生变化 // 2. lastRun 和 lastIdx 发生了变化,记录变化位置和变化节点,然后把变化的这个节点设置到新table newTable[lastIdx] = lastRun; // Clone remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; // 处理扩容时那个添加的节点 int nodeIndex = node.hash &amp; sizeMask; // add the new node node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable; &#125; //自选获取锁 private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash);//获取头节点 HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node 是为了找到对应hash桶,遍历链表时找到就停止 while (!tryLock()) &#123; //自旋获取锁 HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; if (e == null) &#123;//结束遍历节点 if (node == null) // speculatively create node node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; &#125; else if (key.equals(e.key))// 找到节点 停止遍历 retries = 0; else e = e.next; &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123;// 达到自旋的最大次数 lock();//阻塞 break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123;//// 头结点变化,需要重新遍历,说明有新的节点加入或者移除 e = first = f; // re-traverse if entry changed retries = -1; &#125; &#125; return node; &#125; //自旋获取锁 private void scanAndLock(Object key, int hash) &#123; // similar to but simpler than scanAndLockForPut HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; int retries = -1; while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; if (retries &lt; 0) &#123; if (e == null || key.equals(e.key)) retries = 0; else e = e.next; &#125; else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; (f = entryForHash(this, hash)) != first) &#123; e = first = f; retries = -1; &#125; &#125; &#125;&#125; Segment中主要的方法就是put添加元素，rehash 对table进行扩容，scanAndLockForPut，scanAndLock自旋获取锁。 成员变量12345678910111213static final int DEFAULT_INITIAL_CAPACITY = 16;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int DEFAULT_CONCURRENCY_LEVEL = 16;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final int MIN_SEGMENT_TABLE_CAPACITY = 2;static final int MAX_SEGMENTS = 1 &lt;&lt; 16; // slightly conservativestatic final int RETRIES_BEFORE_LOCK = 2; ConcurrentHashMap 主要的默认参数和HashMap差不多。 DEFAULT_CONCURRENCY_LEVEL 是默认的并发数（Segment数组的数量） MIN_SEGMENT_TABLE_CAPACITY 每个Segment最小的容量 MAX_SEGMENTS 每个Segment最大的容量 RETRIES_BEFORE_LOCK默认的自旋次数 put123456789101112131415161718192021222324252627282930313233public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key);//对应key的hash值 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;//获取对应hash值在segments数组的index if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); //如果对应内存偏移量中没有，则创建ensureSegment return s.put(key, hash, value, false);&#125;private Segment&lt;K,V&gt; ensureSegment(int k) &#123; final Segment&lt;K,V&gt;[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V&gt; seg; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; Segment&lt;K,V&gt; proto = ss[0]; // use segment 0 as prototype 以初始化创建的第一个index下标的值为模板 int cap = proto.table.length; float lf = proto.loadFactor; int threshold = (int)(cap * lf); HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // recheck 再次检查有没有其他线程已经创建了 Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) // 通过cas自旋的方式来创建 break; &#125; &#125; &#125; return seg;&#125; ConcurrentHashMap中value不能为null，否则会抛出空指针异常，然后获取到对应key的hash值对应的Segment。如果对应的Segment不存在，则通过CAS的方式去创建Segment，这是不加锁方式下又可能保证线程安全的方法。 get1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; int h = hash(key);//对应key的hash值 long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE;//获取对应hash值存储所在segments数组中内存偏移量 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; //获取到对应Segment中的table for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; ConcurrentHashMap 的get方法就是先获取到对应的Segment，在获取到Segment中的table对应的HashEntry的头节点，但是通过UNSAFE.getObjectVolatile 获取到的是内存中最新的数据，在遍历的过程中，有可能数据被其他线程修改，导致最终返回的数据可能是过时的数据，因此此方法是弱一致性的。 size1234567891011121314151617181920212223242526272829303132333435363738394041public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; // 是否溢出 long sum; // 存储本次循环过程中计算得到的modCount的值 long last = 0L; // 存储上一次遍历过程中计算得到的modCount的和 int retries = -1; // first iteration isn&apos;t retry try &#123; //无限for循环，结束条件就是任意前后两次遍历过程中modcount值的和是一样的，说明第二次遍历没有做任何变化 for (;;) &#123;// // //为了防止由于有线程不断在更新map而导致每次遍历过程一直发现modCount和上一次不一样导致线程一直进行遍历验证前后两次modCoun,加了一个最多重复的次数限制,超过这个次数则直接强制对所有的segment进行加锁(会导致可以延迟创建的Segment在这个过程中被创建） if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; //由于只有在retries等于RETRIES_BEFORE_LOCK时才会执行强制加锁，并且由于是用的retries++，所以强制加锁完毕后，retries的值是一定会大于RETRIES_BEFORE_LOCK的， if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; jdk1.8在jdk1.8中没有采用分段锁的方式保证在多线程下的安全，采用的是CAS+synchronized来保证在多线程的安全。底层的数据存储也变成了数组+链表+红黑树的方式。 NodeNode 和HashMap中的Node结构大致类似，只不过value和next通过volatile进行了修饰，保证了内存的可见性。还增加了一个find方法，通过这个node遍历之后的全部node找对对应key的节点。 1234567891011121314151617final int hash;final K key;volatile V val;volatile Node&lt;K,V&gt; next;Node&lt;K,V&gt; find(int h, Object k) &#123; Node&lt;K,V&gt; e = this; if (k != null) &#123; do &#123; K ek; if (e.hash == h &amp;&amp; ((ek = e.key) == k || (ek != null &amp;&amp; k.equals(ek)))) return e; &#125; while ((e = e.next) != null); &#125; return null;&#125; ConcurrentHashMap的初始化123456789101112131415161718192021222324private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; //如果sizeCtl &lt; 0 说明已经有其他线程进行了初始化，此时只需要将CPU的时间片让出即可 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; //进行初始化 try &#123; if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; sc = n - (n &gt;&gt;&gt; 2);//0.75*capacity &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 初始化的操作会在第一次put操作的时候进行，初始化的时候会调整table的大小。 put方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //value不能为空 if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode());//获取key的hash值 （(h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS;） int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0)//第一次put的时候对table进行初始化 tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果table对应的index上的Node为空 进行初始化 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; else if ((fh = f.hash) == MOVED)// 当前Map在扩容，先协助扩容，在更新值。 tab = helpTransfer(tab, f); else &#123; //hash冲突 V oldVal = null; synchronized (f) &#123;//通过synchronized 进行加锁 if (tabAt(tab, i) == f) &#123;//链表头结点 if (fh &gt;= 0) &#123; binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123;//如果key存在的情况 oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123;//节点不存在的情况，直接加在链表的尾部 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; //如果节点是红黑树节点，插入到红黑树节点中 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD)//如果链表长度大于等于8 treeifyBin(tab, i); //转变为红黑树 if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount);// 统计节点个数，检查是否需要resize return null;&#125; 1.8的ConcurrentHashMap进行put操作的时候，如果第一次进行put会先初始化table数组，如果对应的bucket为空，通过CAS将node放入对应的bucket，如果当前Map正在进行扩容，则先协助扩容；最后对这个节点加锁，如果节点存在进行更新值，如果不存在加在链表的尾部，如果是红黑树节点插入红黑树，最后会判断如果链表长度超过8会将当前链表转换为红黑树。 helpTransfer12345678910111213141516171819202122final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) &#123; Node&lt;K,V&gt;[] nextTab; int sc; //tab不为空 &amp;&amp; f 属于ForwardingNode类型（Node的hash值为-1） //如果nextTable为null,则表示迁移完成了 if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) &#123; int rs = resizeStamp(tab.length);//要调整的大小 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; //每有一个线程来帮助迁移，sizeCtl就+1 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) &#123; transfer(tab, nextTab); break; &#125; &#125; return nextTab; &#125; return table;&#125; 此方法是帮助Map进行扩容 addCount123456789101112131415161718192021222324252627282930313233343536373839404142434445464748private final void addCount(long x, int check) &#123; CounterCell[] as; long b, s; //更新baseCount if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; s = sumCount(); &#125; if (check &gt;= 0) &#123;//是不是需要检查 Node&lt;K,V&gt;[] tab, nt; int n, sc; //符合扩容条件，map.size 大于阈值 table不为空，链表长度超过8 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n);//根据长度得到一标识 if (sc &lt; 0) &#123;//正在扩容 // 如果 sc 的低 16 位不等于 标识符（校验异常 sizeCtl 变化了） // 如果 sc == 标识符 + 1 （扩容结束了，不再有线程进行扩容）（默认第一个线程设置 sc ==rs 左移 16 位 + 2，当第一个线程结束扩容了，就会将 sc 减一。这个时候，sc 就等于 rs + 1） // 如果 sc == 标识符 + 65535（帮助线程数已经达到最大） // 如果 nextTable == null（结束扩容了） // 如果 transferIndex &lt;= 0 (转移状态变化了) // 结束循环 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果可以帮助扩容，那么将 sc 加 1. 表示多了一个线程在帮助扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 如果不在扩容，将 sc 更新：标识符左移 16 位 然后 + 2. 也就是变成一个负数。高 16 位是标识符，低 16 位初始是 2. else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) // 更新 sc 为负数后，开始扩容。 transfer(tab, null); s = sumCount(); &#125; &#125;&#125; addCount 方法主要进行了两个操作 1 更新baseCount 2 检查是不是需要扩容主要说下 检查扩容的部分，首先如果满足扩容条件的话，如果sc是负数则代表正在扩容，此时如果 sizeCtl变化|扩容结束|帮助线程达到最大|等结束循环。如果可以帮助扩容的话就在增加一个线程帮助扩容；如果还没开始扩容就把sc设为负数开始扩容。 transfer 扩容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; //stride最小为16 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range if (nextTab == null) &#123; // initiating try &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];//扩容两倍 nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; nextTable = nextTab; transferIndex = n; &#125; int nextn = nextTab.length; //正在被迁移的node，ForwardingNode的hash 是MOVED，key value next 都是null，其中的nextTable指向新的tab ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); boolean advance = true;//advance为true，可以继续迁移下一个节点，false则停止迁移 boolean finishing = false; // to ensure sweep before committing nextTab for (int i = 0, bound = 0;;) &#123; //i迁移位置的索引，bound迁移的边界 Node&lt;K,V&gt; f; int fh; while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) //finishing 为true停止while循环 advance = false; else if ((nextIndex = transferIndex) &lt;= 0) &#123;//transferIndex（上一次迁移的边界）赋值给nextInde，transferIndex小于等于0，说明原数组的所有位置的迁移都有相应的线程去处理了，该线程可以不用迁移了 i = -1; advance = false; &#125; //将nextBound赋值给bound，nextBound = nextIndex - stride（上一个边界减去步长） else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; //i &lt; 0 所有迁移任务完成 if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; //所有迁移完成，将nextTable设为空，sizeCtl为新tab.length * 0.75 if (finishing) &#123; nextTable = null; table = nextTab; sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; //该线程完成迁移，sizeCtl - 1，对应之前helpTransfer()中+1 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; //不相等说明还有其他线程没完成迁移，该线程结束任务 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; finishing = advance = true;//如果相等，则说明说有线程都完成任务了，设置finish为true i = n; // recheck before commit &#125; &#125; else if ((f = tabAt(tab, i)) == null)//如果旧tab[i]为null，则放入ForwardingNode advance = casTabAt(tab, i, null, fwd); else if ((fh = f.hash) == MOVED)//该节点为ForwardingNode，则说明已经被迁移过了，就可以开始迁移下一个节点了 advance = true; // already processed else &#123; synchronized (f) &#123;//迁移开始加锁 if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; if (fh &gt;= 0) &#123;//fh &gt;= 0,说明是链表结构 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; else if (f instanceof TreeBin) &#123; //红黑树结构 TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; setTabAt(nextTab, i, ln); setTabAt(nextTab, i + n, hn); setTabAt(tab, i, fwd); advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 遍历整个table，当前节点为空，则采用CAS的方式在当前位置放入fwd 当前节点已经为fwd(with hash field “MOVED”)，则已经有有线程处理完了了，直接跳过 ，这里是控制并发扩容的核心 当前节点为链表节点或红黑树，重新计算链表节点的hash值，移动到nextTable相应的位置（构建了一个反序链表和顺序链表，分别放置在i和i+n的位置上）。移动完成后，用Unsafe.putObjectVolatile在tab的原位置赋为为fwd, 表示当前节点已经完成扩容。 get12345678910111213141516171819public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 读取元素的操作就很简单，获取到对应的hash值，如果 table为空或对应的头节点为空直接返回null，不然就找到对应的bucket找到对应的node返回。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[aqs源码]]></title>
      <url>%2F20191118%2Fjavasource%2Futil%2F3_AbstractQueuedSynchronizer%2F</url>
      <content type="text"><![CDATA[aqsAQS（AbstractQueuedSynchronizer）是JAVA中众多锁以及并发工具的基础，其底层采用乐观锁，大量使用了CAS操作， 并且在冲突时，采用自旋方式重试，以实现轻量级和高效地获取锁。 AQS虽然被定义为抽象类，但事实上它并不包含任何抽象方法。AQS是被设计为支持多种用途，如果定义抽象方法，子类在继承的时候就需要实现所有抽象方法，所以AQS将需要子类覆盖的方法都设计为protect方法，默认抛出UnsupportedOperationException异常，。如果子类用到这些方法就必须重写，否则会抛出异常，如果没有用到则不需要做任何操作。 AbstractQueuedSynchronizer只继承了AbstractOwnableSynchronizer，实现了java.io.Serializable接口。 AbstractOwnableSynchronizer类是一种同步器，这个类仅有set和get独占线程资源。123456789101112131415161718&gt; public abstract class AbstractOwnableSynchronizer&gt; implements java.io.Serializable &#123;&gt; &gt; private static final long serialVersionUID = 3737899427754241961L;&gt; &gt; protected AbstractOwnableSynchronizer() &#123; &#125;&gt;&gt; private transient Thread exclusiveOwnerThread;&gt; &gt; protected final void setExclusiveOwnerThread(Thread t) &#123;&gt; exclusiveOwnerThread = t;&gt; &#125;&gt;&gt; protected final Thread getExclusiveOwnerThread() &#123;&gt; return exclusiveOwnerThread;&gt; &#125;&gt; &#125;&gt; exclusiveOwnerThread 即独占资源的线程。 AQS原理AQS维护了一个state变量和node双向链表。 state是已获取资源占有许可的数量。例如线程调用acquire(1)获取资源的许可，acquire会调用一次tryAcquire(1)获取资源。如果获取成功，则state加1并且调用父类的设置独占线程将当前线程设置为独占线程。如果获取失败，则说明已经有线程占用了这个资源，需要等待占用释放。此时将该线程封装成node节点，加入双向链表，之后Locksupport.pack()堵塞当前线程。如果这个线程被唤醒则继续循环调用tryAcquire获取许可，如果获取到了将自己的node节点设置为链表的头结点并把之前的头结点去掉。如果线程释放资源，调用release方法，release方法会调用tryRelease方法尝试释放资源,如果释放成功，则state减1，再调用AQS的父类AbstractOwnableSynchronizer的设置独占线程为null，再locksupport.unpack()双向node链表的头node节点的线程，恢复其执行。 源码成员变量1234567891011121314151617181920212223242526272829private transient volatile Node head;private transient volatile Node tail;private volatile int state;private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long stateOffset;private static final long headOffset;private static final long tailOffset;private static final long waitStatusOffset;private static final long nextOffset;static &#123; try &#123; stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;state&quot;)); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;head&quot;)); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;tail&quot;)); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(&quot;waitStatus&quot;)); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(&quot;next&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125;&#125; 有一个头尾节点和state变量，实现CAS的Unsafe的工具类，还有一些偏移量，都用于Unsafe的CAS操作，通过静态代码块进行初始化，通过objectFieldOffset获取对应字段相对于该对象的起始地址的偏移量。 Node节点12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static final class Node &#123; //共享模式 static final Node SHARED = new Node(); //独占模式 static final Node EXCLUSIVE = null; //当线程等待超时或者被中断，则取消等待 static final int CANCELLED = 1; //后继节点处于等待状态，当前节点（为-1）被取消或者中断时会通知后继节点，使后继节点的线程得以运行 static final int SIGNAL = -1; //当前节点处于等待队列，节点线程等待在Condition上，当其他线程对condition执行signall方法时，等待队列转移到同步队列，加入到对同步状态的获取。 static final int CONDITION = -2; //与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。 static final int PROPAGATE = -3; //状态 volatile int waitStatus; //上一个节点 volatile Node prev; //下一个节点 volatile Node next; //节点所代表的线程 volatile Thread thread; //Node既可以作为同步队列节点使用，也可以作为Condition的等待队列节点使用 Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; enq方法123456789101112131415private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; enq方法是将node加入链表，如果tail尾节点为空则必须进行初始化，如果tail不为空，则将node的前指针指向tail，通过CAS将tail的指向改为node，然后设置t.next为node，完成node插入链表尾部。 addWaiter方法1234567891011121314private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node;&#125; addWaiter方法包装node节点，放入node双向链表。如果tail不为空则说明初始化过了直接将node加入链表尾部，如果为空则进行初始化再将node加入链表尾部。 共享模式acquireShared（获取锁）1234public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125; 尝试去获取资源，如果没有获取资源返回负数，tryAcquireShared方法需要子类自己去实现，如果不实现会直接抛异常（在读写锁的Sync实现）；如果没有获取到资源加入等待队列等待获取资源。 doAcquireShared123456789101112131415161718192021222324252627282930313233private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //找先驱结点 final Node p = node.predecessor(); if (p == head) &#123; //尝试获取资源 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //获取锁之后，设置当前节点为头节点，去唤醒 setHeadAndPropagate(node, r); p.next = null; // help GC //如果是因为中断醒来则设置中断标记位 if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; //挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; // 获取锁失败 if (failed) cancelAcquire(node); &#125;&#125; 先吧当前节点加入到队列尾部，然后进入自旋，自旋的目的是为了获取资源或者阻塞，如果此节点的前一个node是head节点，就去获取资源，如果获取失败就执行shouldParkAfterFailedAcquire，将前一个node设置为SIGNAL，获取成功就setHeadAndPropagate。 setHeadAndPropagate12345678910111213//两个入参，一个是当前成功获取共享锁的节点，一个就是tryAcquireShared方法的返回值，它可能大于0也可能等于0private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below //设置新的头节点 setHead(node); //propagate &gt; 0 代表还有资源，还可以继续唤醒 | h.waitStatus 是 -1 or -3 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0) &#123; Node s = node.next; //如果当前节点的后继节点是共享类型获取没有后继节点，则进行唤醒 if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 会唤醒后面的所有节点 doReleaseShared（唤醒）12345678910111213141516171819202122232425private void doReleaseShared() &#123; for (;;) &#123; //从头结点开始 head已是上面设置的head节点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; //表示需要唤醒（-1） if (ws == Node.SIGNAL) &#123; //CAS 将状态置为0 if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases //唤醒 unparkSuccessor(h); &#125; //如果后继节点暂时不需要唤醒，则把当前节点状态设置为PROPAGATE确保以后可以传递下去 else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; //如果头结点没有发生变化，表示设置完成，退出循环 //如果头结点发生变化，比如说其他线程获取到了锁，为了使自己的唤醒动作可以传递，必须进行重试 if (h == head) // loop if head changed break; &#125;&#125; unparkSuccessor方法1234567891011121314151617 private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; //next 节点为空 或者状态为取消 if (s == null || s.waitStatus &gt; 0) &#123; s = null; //从后向前找 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 用unpark()唤醒等待队列中最前边的那个未放弃线程，node的waitStatus为signal或condition，则可以唤醒，先重置node的waitStatus为0（允许失败），找到下一个需要唤醒的节点唤醒。 从后往前找是因为下一个任务有可能被取消了，节点就有可能为null shouldParkAfterFailedAcquire1234567891011121314private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) return true; if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125; 主要是进行的状态的检查，如果前一个节点的状态是-1则返回true；如果前一个节点取消了，那就向前找到一个没有被取消的节点，将取消的节点舍弃，如果前一个节点没有被取消则将节点状态设置为-1. releaseShared（ 释放锁）1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 独占模式acquire（获取锁）12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 首先也是尝试获取资源，如果获取到资源则直接返回了，如果没有获取到资源则执行acquireQueued(addWaiter(Node.EXCLUSIVE), arg)，将该线程加入队列节点尾部。 acquireQueued123456789101112131415161718192021final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 和共享模式类似，先获取该节点的前一个节点，如果前一个节点是头结点就尝试获取资源。如果获取到资源则把这个接地点设为头节点 直接返回了；如果没有获取到资源则进入阻塞挂起。 挂起逻辑同上。 cancelAcquire12345678910111213141516171819202122232425262728293031323334private void cancelAcquire(Node node) &#123; //如果节点不存在直接返回 if (node == null) return; node.thread = null; Node pred = node.prev; //跳过前面已经取消的前置节点 while (pred.waitStatus &gt; 0) node.prev = pred = pred.prev; Node predNext = pred.next; //将node的状态设置为1 其他节点在处理时就可以跳过 node.waitStatus = Node.CANCELLED; //如果是尾节点直接删除返回 if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; compareAndSetNext(pred, predNext, null); &#125; else &#123; int ws; //否则当前节点的前置节点不是头节点且它后面的节点等待它唤醒 if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) //删除该node compareAndSetNext(pred, predNext, next); &#125; else &#123; //要么当前节点的前置节点是头结点,直接唤醒当前节点的后继节点 unparkSuccessor(node); &#125; node.next = node; // help GC &#125;&#125; 获取锁资源失败的处理，即自己实现的获取资源的逻辑出异常的时候会进入到这里。（共享模式同这里的） release（释放锁）12345678910111213141516171819202122232425public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 条件队列(ConditionObject)使用场景123456789101112131415161718192021//首先创建一个可重入锁，它本质是独占锁private final ReentrantLock takeLock = new ReentrantLock();//创建该锁上的条件队列private final Condition notEmpty = takeLock.newCondition();//使用过程public E take() throws InterruptedException &#123; //首先进行加锁 takeLock.lockInterruptibly(); try &#123; //如果队列是空的，则进行等待 notEmpty.await(); //取元素的操作... //如果有剩余，则唤醒等待元素的线程 notEmpty.signal(); &#125; finally &#123; //释放锁 takeLock.unlock(); &#125; //取完元素以后唤醒等待放入元素的线程&#125; Condition一般都是配合一个显式锁Lock一起使用，Lock接口的方法中有一个newCondition()方法用于生成Condition对象。通过ReentrantLock的lock方法，如果获取不到锁当前线程会进入AQS队列阻塞；被唤醒后继续获取锁，如果获取到锁，移出AQS队列，继续执行；遇到Condition的await方法，加入“条件队列”，阻塞线程；被其他线程的signal方法唤醒，从“条件队列”中删除，并加入到AQS队列，如果获取到锁就继续执行。可以看到上述操作，线程节点（Node）其实在两个队列之间切换，由于“条件队列”在被唤醒时 都是从头开始遍历，所以只需要使用单向链表实现即可。 12345678910111213141516public interface Condition &#123; void await() throws InterruptedException; void awaitUninterruptibly(); long awaitNanos(long nanosTimeout) throws InterruptedException; boolean await(long time, TimeUnit unit) throws InterruptedException; boolean awaitUntil(Date deadline) throws InterruptedException; void signal(); void signalAll();&#125; ConditionObject 实现了 Condition接口，Condition接口中一个有7个接口： await : 使用这个锁必须放在一个显式锁的lock和unlock之间，调用该方法后当前线程会释放锁并被阻塞，直到其他线程通过调用同一个Condition对象的signal或者signalAll方法或被中断，再次被唤醒。（可被中断） awaitUninterruptibly : 此方式是不可被中断的，只能通过其他线程调用同一个Condition对象的signal或者signalAll方法，才能被唤醒。（不响应中断） awaitNanos : 等待纳秒时间 await(long time, TimeUnit unit) : 等待一个指定时间 awaitUntil : 等待直到一个截止时间 signal : 唤醒等待队列中的第一个节点 signalAll : 唤醒等待队列中的所有节点 await1234567891011121314151617181920212223242526public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); //加入条件队列 Node node = addConditionWaiter(); //释放当前线程占用的排它锁 int savedState = fullyRelease(node); int interruptMode = 0; //节点不在AQS的阻塞队列中 while (!isOnSyncQueue(node)) &#123; //阻塞该线程 LockSupport.park(this); //判断中断标记在阻塞等待期间 是否改变 if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; //当被唤醒后，该线程会尝试去获取锁，只有获取到了才会从await()方法返回，否则的话，会挂起自己 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled //清理取消节点对应的线程 unlinkCancelledWaiters(); if (interruptMode != 0) //抛出中断异常，或者重新进入中断 reportInterruptAfterWait(interruptMode);&#125; 先将该节点加入到条件队列，然后释放掉当前的锁，如果该节点不在AQS的阻塞队列中就阻塞该线程，等待signal；被唤醒后该线程会尝试去获取锁 signal12345678910111213141516171819202122232425262728293031public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //第一个节点 Node first = firstWaiter; if (first != null) doSignal(first);&#125;private void doSignal(Node first) &#123; do &#123; //firstWaiter 下一个节点 if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125;final boolean transferForSignal(Node node) &#123; //改变线程状态 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; //加入AQS阻塞队列 Node p = enq(node); int ws = p.waitStatus; //唤醒 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; 将条件队列的第一个节点移除，加入到AQS的阻塞队列中。 signalAll1234567891011121314151617public final void signalAll() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); Node first = firstWaiter; if (first != null) doSignalAll(first);&#125;private void doSignalAll(Node first) &#123; lastWaiter = firstWaiter = null; do &#123; Node next = first.nextWaiter; first.nextWaiter = null; transferForSignal(first); first = next; &#125; while (first != null);&#125; signalAll 会遍历全部节点唤醒加入到AQS阻塞队列。 条件队列与同步队列1.同步队列依赖一个双向链表来完成同步状态的管理，当前线程获取同步状态失败 后，同步器会将线程构建成一个节点，并将其加入同步队列中。2.通过signal或signalAll将条件队列中的节点转移到同步队列。（由条件队列转化为同步队列） 条件队列节点来源： 调用await方法阻塞线程； 当前线程存在于同步队列的头结点，调用await方法进行阻塞（从同步队列转化到条件队列） 例如： 假设初始状态如下，节点A、节点B在同步队列中。 节点A的线程获取锁权限，此时调用await方法。节点A从同步队列移除， 并加入条件队列中。 调用 signal方法，从条件队列中取出第一个节点，并加入同步队列中，等待获取资源]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[synchronized和lock]]></title>
      <url>%2F20191116%2Fjava%2F3_synchronizedAndlock%2F</url>
      <content type="text"><![CDATA[锁的种类锁的种类很多，包括：自旋锁(CAS)、阻塞锁、可重入锁、读写锁、互斥锁、悲观锁、乐观锁、公平锁、可中断锁等等，主要介绍下可重入锁、读写锁、可中断锁和公平锁。 可重入锁 如果锁具备可重入性，则称作为可重入锁。synchronized和ReentrantLock都是可重入锁，可重入性在我看来实际上表明了锁的分配机制：基于线程的分配，而不是基于方法调用的分配。举比如说，当一个线程执行到method1 的synchronized方法时，而在method1中会调用另外一个synchronized方法method2，此时该线程不必重新去申请锁，而是可以直接执行方法method2。 读写锁 读写锁将对一个资源的访问分成了2个锁，如文件，一个读锁和一个写锁。正因为有了读写锁，才使得多个线程之间的读操作不会发生冲突。ReadWriteLock就是读写锁，它是一个接口，ReentrantReadWriteLock实现了这个接口。可以通过readLock()获取读锁，通过writeLock()获取写锁。 可中断锁 可中断锁，即可以中断的锁。在Java中，synchronized就不是可中断锁，而Lock是可中断锁。如果某一线程A正在执行锁中的代码，另一线程B正在等待获取该锁，可能由于等待时间过长，线程B不想等待了，想先处理其他事情，我们可以让它中断自己或者在别的线程中中断它，这种就是可中断锁。Lock接口中的lockInterruptibly()方法就体现了Lock的可中断性。 公平锁 公平锁即尽量以请求锁的顺序来获取锁。同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁，这种就是公平锁。非公平锁即无法保证锁的获取是按照请求锁的顺序进行的，这样就可能导致某个或者一些线程永远获取不到锁。synchronized是非公平锁，它无法保证等待的线程获取锁的顺序。对于ReentrantLock和ReentrantReadWriteLock，默认情况下是非公平锁，但是可以设置为公平锁。 synchronized和lock的用法synchronizedsynchronized是Java的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码，同时它还可以保证共享变量的内存可见性。 修饰代码块12345public void method()&#123; synchronized (Object o)&#123; // &#125;&#125; 作用于代码块，synchronized后跟括号，括号里是变量，每次只会有一个线程进入该代码块。 修饰方法123public synchronized void method()&#123; //&#125; 作用于方法时，一次只有一个线程进入该方法，其他线程此时想调用只能排队等候。 修饰类1234public static void menthed()&#123; synchronized(Service.class) &#123; &#125;&#125; 如果线程进入，则线程在该类中所有操作不能进行，包括静态变量和静态方法，对于含有静态方法和静态变量的代码块的同步，通常使用这种方式。 Lockjava.util.concurrent.locks 包下有以下这些类： ReetrantLock实现了Lock接口，ReadWriteLock是读写锁的接口，由ReentrantReadWriteLock实现。 Lock1234567891011121314public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; Lock接口中定义了这6个接口。 lock():用来获取锁，如果锁已经被其他线程获取，则会处于等待状态。使用Lock则必须主动释放锁，发生异常也不会自动释放锁，所以要在try{}catch()中进行，finally中释放锁。 lockInterruptibly():通过这个方法去获取锁时，如果线程正在等待获取锁，则这个线程能够响应中断，即中断线程的等待状态。 tryLock():尝试获取锁，如果获取成功，则返回true，如果获取失败则返回false。这个方法会立即返回，拿不到锁也不会等待。 tryLock(long time, TimeUnit unit):也是尝试获取锁，不过会有设定的等待时间。 unlock():释放锁 newCondition(): 创建一个Condition，Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式。 ReentrantLockReentrantLock 实现了Lock接口，是一个可重入锁，内部定义了公平锁和非公平锁，默认是非公平锁。 12345678910111213141516171819public class ReentrantLockTest &#123; public static void main(String[] args) throws InterruptedException &#123; ReentrantLock lock = new ReentrantLock(); for (int i = 1; i &lt;= 3; i++) &#123; lock.lock(); &#125; for(int i=1;i&lt;=3;i++)&#123; try &#123; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; ReentrantLock 可以通过lock()方法加锁多次，在通过unlock()方法释放锁多次使得程序正常退出，所以ReentrantLocl是可重入锁。 ReentrantLock和synchronized都是独占锁,只允许线程互斥的访问临界区。synchronized是隐式的，ReentrantLocl是显示的。 ReentrantLock和synchronized都是可重入的。synchronized因为可重入因此可以放在被递归执行的方法上,且不用担心线程最后能否正确释放锁；而ReentrantLock在重入时要却确保重复获取锁的次数必须和重复释放锁的次数一样，否则可能导致其他线程无法获得该锁。 ReadWriteLock12345public interface ReadWriteLock &#123; Lock readLock(); Lock writeLock();&#125; ReadWriteLock是读写锁，定义了一个获取读锁，一个获取写锁的方法。如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁；如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则申请的线程会一直等待释放写锁。 synchronized和lock的区别 Lock是一个接口，而synchronized是java中的关键字。 synchronized在发生异常的时候会自动释放锁，而Lock在发生异常的时候仍需要手动去释放锁。 Lock可以让等待的线程响应中断，而synchronized不可以，会是等待线程一直等待下去，直到获取锁。 Lock可以知道是否获取到锁。 ReadWriteLock可以提高多读的效率。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[线程池阅读]]></title>
      <url>%2F20191115%2Fjavasource%2Futil%2F2_ExecutorService%2F</url>
      <content type="text"><![CDATA[类继承的结构 Executor是最顶层的接口，定义了execute(Runnable runnable)方法。ExecutorService继承了Executor，继承了execute方法，还定义很多接口方法，例如shutdown、isTerminated、submit等方法。 在下面一层是AbstractExecutorService，这是一个抽象类，实现一些很有用的方法供子类使用。 ThreadPoolExecutor是我们线程池的实现。 ThreadPoolExecutorThreadPoolExecutor实现了一个线程池需要的各个方法，它实现了任务提交、线程管理、监控等等方法。 我们还可以在它的基础上进行扩展，比如实现定时任务的类 ScheduledThreadPoolExecutor（用来在给定延时后执行异步任务或者周期性执行任务） 就继承自 ThreadPoolExecutor。 构造函数参数123456789101112131415161718192021222324public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 我们创建一个线程池参数最全的构造方法如上，这些是我们最关心的参数。 corePoolSize 核心线程数 maximumPoolSize 最大线程数 keepAliveTime 空闲线程的存活时间 unit 存活时间的单位 workQueue 任务队列，BlockingQueue 接口的某个实现（常使用 ArrayBlockingQueue 和 LinkedBlockingQueue）。 threadFactory 用于创建线程，一般都使用默认的（Executors.defaultThreadFactory()），我们可以通过它将我们的线程的名字设置得比较可读一些，如 Message-Thread-1， Message-Thread-2 类似这样。 handler 拒绝策略 状态流转123456789private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; COUNT_BITS 设置为 29(32-3)，前三位用于存放线程状态，后29位用于存放线程数CAPACITY = 2^29-1=536870911 即线程池的最大数量RUNNING 111 00000000000000000000000000000 接受新的任务，处理等待队列中的任务SHUTDOWN 000 00000000000000000000000000000 不接受新的任务提交，但是会继续处理等待队列中的任务STOP 001 00000000000000000000000000000 不接受新的任务提交，不再处理等待队列中的任务，中断正在执行任务的线程TIDYING 010 00000000000000000000000000000 所有的任务都销毁了,线程池的状态在转换为 TIDYING 状态时，会执行钩子方法 terminated()TERMINATED 011 00000000000000000000000000000 terminated() 方法结束后，线程池的状态就会变成这个 RUNNING -&gt; SHUTDOWN：当调用了 shutdown() 后，会发生这个状态转换，这也是最重要的 (RUNNING or SHUTDOWN) -&gt; STOP：当调用 shutdownNow() 后，会发生这个状态转换，这下要清楚 shutDown() 和 shutDownNow() 的区别了 SHUTDOWN -&gt; TIDYING：当任务队列和线程池都清空后，会由 SHUTDOWN 转换为 TIDYING STOP -&gt; TIDYING：当任务队列清空后，发生这个转换 TIDYING -&gt; TERMINATED：这个前面说了，当 terminated() 方法结束后 Worker1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; private static final long serialVersionUID = 6138294804551838833L; final Thread thread; Runnable firstTask; volatile long completedTasks; Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; public void run() &#123; runWorker(this); &#125; protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125;&#125; Worker是线程池中的内部类，是线程池中真正执行任务的线程，Worker继承了AbstractQueuedSynchronizer（aqs）实现了Runable。Worker中thread是真正的线程；firstTask是在创建线程的时候，如果同时指定了这个线程起来以后需要执行的第一个任务，那么第一个任务就是存放在这里的；completedTasks 存放了此线程完成的任务数构造函数传入firstTask，也可以传 null。run方法调用了外部类的runWorker方法。其余的方法用 AQS 操作，来获取这个线程的执行权，用了独占锁。 runWorker123456789101112131415161718192021222324252627282930313233343536373839final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 这个方法由worker线程启动后调用，如果指定了该worker的firstTask，则先执行这个任务，之后通过while循环从队列中取任务。首先lock，然后判断线程池状态大于等于 STOP，那么意味着该线程也要中断。beforeExecute方法是一个钩子方法，留给需要的子类进行实现;然后执行任务;afterExecutey也是钩子方法，将task和异常作为参数，留给子类实现使用;最后将task置为空，准备getTask，worker的完成任数加1，释放独占锁。如果能执行到最后的finally（对线程池进行关闭）有两种可能 1 getTask 返回 null，也就是说，队列中已经没有任务需要执行了，执行关闭。2 任务执行过程中发生了异常。 getTask1234567891011121314151617181920212223242526272829303132333435363738private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); //检查状态 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; //减少工作线程的数量，返回null CAS操作 decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); //核心线程是否超时回收 | 线程数大于核心线程数 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; // 线程数大于最大线程数，因为有可能开发者调用了 setMaximumPoolSize() 将线程池的 maximumPoolSize 调小了，那么多余的 Worker 就需要被关闭 // 并且 线程数 &gt; 1 获取队列为King， if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; //减少线程数 返回空 if (compareAndDecrementWorkerCount(c)) return null; //CAS continue; &#125; try &#123; // 到 workQueue 中获取任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 此方法有三种可能： 阻塞直到获取到任务返回。()默认 corePoolSize 之内的线程是不会被回收的，它们会一直等待任务) 超时退出。keepAliveTime 起作用的时候，也就是如果这么多时间内都没有任务，那么应该执行关闭 如果发生了以下条件，此方法必须返回 null: 池中有大于 maximumPoolSize 个 workers 存在(通过调用 setMaximumPoolSize 进行设置) 线程池处于 SHUTDOWN，而且 workQueue 是空的，前面说了，这种不再接受新的任务 线程池处于 STOP，不仅不接受新的线程，连 workQueue 中的线程也不再执行 execute 方法1234567891011121314151617181920212223242526public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); //当前线程数少于核心线程数，那么直接添加一个 worker 来执行任务,创建一个新的线程，并把当前任务 command 作为这个线程的第一个任务(firstTask) if (workerCountOf(c) &lt; corePoolSize) &#123; //添加任务成功，那么就结束了,返回 false 代表线程池不允许提交任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; //如果线程池处于 RUNNING 状态，把这个任务添加到任务队列 workQueue 中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //如果线程池已不处于 RUNNING 状态，那么移除已经入队的这个任务，并且执行拒绝策略 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //线程池还是 RUNNING 的，并且线程数为 0，那么开启新的线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; //如果失败，说明当前线程数已经达到 maximumPoolSize，执行拒绝策略 else if (!addWorker(command, false)) reject(command);&#125; 执行的流程很简单，如果当前线程数少于核心线程数直接add一个worker执行，如果大于等于核心线程数会加进任务队列等待worker执行，如果任务队列满了之后，继续添加worker执行，如果此时线程数超过最大线程数就会执行拒绝策略。 拒绝策略CallerRunsPolicy12345678public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125;&#125; 如果线程池没有被关闭，那么由提交任务的线程自己来执行这个任务。 12345678public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException(&quot;Task &quot; + r.toString() + &quot; rejected from &quot; + e.toString()); &#125;&#125; 线程池的默认策略，直接抛出异常。 12345public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125;&#125; 不处理直接忽略。 123456789public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125;&#125; 把队列队头的任务干掉，然后提交这个任务。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HashMap阅读 （1.8|1.7）]]></title>
      <url>%2F20191114%2Fjavasource%2Futil%2F1_HashMap%2F</url>
      <content type="text"><![CDATA[HashMap 内部默认的参数 变量 值 含义 DEFAULT_INITIAL_CAPACITY 16 默认容量 MAXIMUM_CAPACITY 1 &lt;&lt; 30 最大容量 DEFAULT_LOAD_FACTOR 0.75 负载因子 TREEIFY_THRESHOLD 8 链表超过8转为红黑树 UNTREEIFY_THRESHOLD 6 红黑树转为链表的阈值 MIN_TREEIFY_CAPACITY 6 当table的长度小于64时，只是进行扩容 HashMap 内 Node(1.8)123456789101112131415161718192021222324252627282930313233343536373839static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;=&quot; + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; 内部存储key value的结构，本质是一个链表，其中包括key，value，key value的hash值异或的hash和下一个节点。 HashMap的扰动函数1.8JDK1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 1.7JDK12345678910final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 自己的高半区和低半区做异或，为了混合原始哈希码的高位和低位，以此来加大低位的随机性。JDK 1.7做了四次右位移异或混合，目的都一致。 HashMap get 方法1.7JDK1234567public V get(Object key) &#123; if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125; 如果key是空值，单独获取 12345678910private V getForNullKey() &#123; if (size == 0) &#123; return null; &#125; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) return e.value; &#125; return null;&#125; null的key总是存储在table的0index中。 12345678910111213141516final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 获取非空的key，先根据key的hash值和table的长度得到下标索引，在对应的index上的链表遍历查询。indexFor 即hash值与table.length 相与。 1.8JDK1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; 12345678910111213141516171819final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 首先进行校验 table不为空 &amp;&amp; table长度大于0 &amp;&amp; table索引位置(使用table.length - 1和hash值进行位与运算)的节点不为空。其次看first节点（索引位节点）是不是目标节点，如果是目标节点则返回。如果是红黑树节点，则调用红黑树的查找节点方法进行查找，如果是链表节点遍历查询。 HashMap put 方法1.7JDK12345678910111213141516171819202122public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null;&#125; 第一步，如果table为空的话进行初始化。第二步，如果key是空，将value存储table[0]中，先遍历如果有更新新值返回旧值，如果没有addEntry。第三步，根据key计算hash值与table.length相与找到index，先遍历如果有更新新值返回旧值，如果没有addEntry。 123456789void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; addEntry方法中判断了这个bucketIndex的链表没有冲突且元素size超过负载因子*容量的大小就进行resize的操作，然后重新计算key 的hash值和在table的index，最后进行createEntry。createEntry 在链表头部中增加了一个节点。 12345678910111213141516171819202122232425262728void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; resize 方法中调用了transfer，将原数组的中的元素转移到新数组中，这个过程中将链表反转到新数组中，此时多线程进行操作可能会导致链表出现环状，此时get这个key的index是这个环list会导致CPU100%。 1.8jDK123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 如果table为空或者长度为0的时候辉县进行初始化，其次索引位置上的节点为null的时候会创建新的节点。其次判断p节点的key和hash值是否跟传入的相等，如果相等此节点即为要查询的节点；如果p节点是红黑树节点，调用红黑树的putTreeVal查找目标节点；如果p是链表节点，找不到目标节点则创建一个新的节点，如果节点数超过8则转换为红黑树。最后如果e节点不为空，则代表目标节点存在，使用传入的value覆盖该节点的value，并返回oldValue;如果没找到目标节点，超过阈值会执行resize扩容， 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; // 1.老表的容量不为0，即老表不为空 if (oldCap &gt; 0) &#123; // 1.1 判断老表的容量是否超过最大容量值：如果超过则将阈值设置为Integer.MAX_VALUE，并直接返回老表, // 此时oldCap * 2比Integer.MAX_VALUE大，因此无法进行重新分布，只是单纯的将阈值扩容到最大 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 1.2 将newCap赋值为oldCap的2倍，如果newCap&lt;最大容量并且oldCap&gt;=16, 则将新阈值设置为原来的两倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; // 2.如果老表的容量为0, 老表的阈值大于0, 是因为初始容量被放入阈值，则将新表的容量设置为老表的阈值 else if (oldThr &gt; 0) newCap = oldThr; else &#123; // 3.老表的容量为0, 老表的阈值为0，这种情况是没有传初始容量的new方法创建的空表，将阈值和容量设置为默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; // 4.如果新表的阈值为空, 则通过新的容量*负载因子获得阈值 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; // 5.将当前阈值设置为刚计算出来的新的阈值，定义新表，容量为刚计算出来的新容量，将table设置为新定义的表。 threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 6.如果老表不为空，则需遍历所有节点，将节点赋值给新表 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; // 将索引值为j的老表头节点赋值给e oldTab[j] = null; // 将老表的节点设置为空, 以便垃圾收集器回收空间 // 7.如果e.next为空, 则代表老表的该位置只有1个节点，计算新表的索引位置, 直接将该节点放在该位置 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 8.如果是红黑树节点，则进行红黑树的重hash分布(跟链表的hash分布基本相同) else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 9.如果是普通的链表节点，则进行普通的重hash分布 Node&lt;K,V&gt; loHead = null, loTail = null; // 存储索引位置为:“原索引位置”的节点 Node&lt;K,V&gt; hiHead = null, hiTail = null; // 存储索引位置为:“原索引位置+oldCap”的节点 Node&lt;K,V&gt; next; do &#123; next = e.next; // 9.1 如果e的hash值与老表的容量进行与运算为0,则扩容后的索引位置跟老表的索引位置一样 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) // 如果loTail为空, 代表该节点为第一个节点 loHead = e; // 则将loHead赋值为第一个节点 else loTail.next = e; // 否则将节点添加在loTail后面 loTail = e; // 并将loTail赋值为新增的节点 &#125; // 9.2 如果e的hash值与老表的容量进行与运算为1,则扩容后的索引位置为:老表的索引位置＋oldCap else &#123; if (hiTail == null) // 如果hiTail为空, 代表该节点为第一个节点 hiHead = e; // 则将hiHead赋值为第一个节点 else hiTail.next = e; // 否则将节点添加在hiTail后面 hiTail = e; // 并将hiTail赋值为新增的节点 &#125; &#125; while ((e = next) != null); // 10.如果loTail不为空（说明老表的数据有分布到新表上“原索引位置”的节点），则将最后一个节点 // 的next设为空，并将新表上索引位置为“原索引位置”的节点设置为对应的头节点 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; // 11.如果hiTail不为空（说明老表的数据有分布到新表上“原索引+oldCap位置”的节点），则将最后 // 一个节点的next设为空，并将新表上索引位置为“原索引+oldCap”的节点设置为对应的头节点 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; // 12.返回新表 return newTab;&#125; 在JDK1.8中，resize操作不需要重新计算索引，且迁移新表后数据不会倒置。不需要重新计算hash，只需要用原来的hash值，加上高一位做为索引。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[迭代器模式]]></title>
      <url>%2F20170817%2FDesign_pattern%2F19_iterator%2F</url>
      <content type="text"><![CDATA[迭代器模式介绍迭代器模式：提供一种方法访问一个容器对象中各个元素，而又不暴露该对象的内部细节。（行为型模式）迭代器模式是应该是java中使用的最多的一种设计模式，迭代器模式如下： 抽象容器：一般是一个接口，提供一个iterator()方法，例如java中的Collection接口，List接口，Set接口等。 具体容器：就是抽象容器的具体实现类，比如List接口的有序列表实现ArrayList，List接口的链表实现LinkList，Set接口的哈希列表的实现HashSet等。 抽象迭代器：定义遍历元素所需要的方法，一般来说会有这么三个方法：取得第一个元素的方法first()，取得下一个元素的方法next()，判断是否遍历结束的方法isDone()（或者叫hasNext()），移出当前对象的方法remove(), 迭代器实现：实现迭代器接口中定义的方法，完成集合的迭代。 优缺点和适用场景优点 迭代器简化了聚合的接口 可以提供多种遍历方式 在同一个聚合上可以有多个遍历 缺点 对于比较简单的遍历（像数组或者有序列表），使用迭代器方式遍历较为繁琐，大家可能都有感觉，像ArrayList，我们宁可愿意使用for循环和get方法来遍历集合 适用场景一般来说，我们只要实现一个集合，就需要同时提供这个集合的迭代器，就像java中的Collection，List、Set、Map等，这些集合都有自己的迭代器。java本身已经把迭代器做到内部中了，我们一般情况自己很少自定义的迭代器。 DEMO看了JDK源码简单写了一个 首先是抽象迭代器 12345678910package factory.pattern.iterator;/** * Created by FK on 2017/8/17. * 抽象迭代器类 */public interface Iterator&lt;E&gt; &#123; public boolean hasNext(); public E next();&#125; 抽象集合1234567891011package factory.pattern.iterator;/** * Created by FK on 2017/8/17. */public interface List&lt;E&gt; extends Iterable&lt;E&gt; &#123; void add(E e); E get(int index); Iterator&lt;E&gt; iterator(); int getSize();&#125; 抽象集合继承了iterable,iterable可以使得多个迭代器互不干扰12345678package factory.pattern.iterator;/** * Created by FK on 2017/8/17. */public interface Iterable&lt;T&gt; &#123; Iterator&lt;T&gt; iterator();&#125; 具体的集合实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package factory.pattern.iterator;/** * Created by FK on 2017/8/17. */public class ArrayList&lt;E&gt; implements List&lt;E&gt; &#123; private Object[] elementData; private int size = 0; private int index = 0; public ArrayList() &#123; this.elementData = new Object[10]; this.size = 0; this.index = 0; &#125; @Override public void add(E e) &#123; elementData[index++] = e; size++; &#125; @Override public E get(int index) &#123; return (E) elementData[index]; &#125; @Override public Iterator&lt;E&gt; iterator() &#123; return new ConcreteIterator(); &#125; @Override public int getSize() &#123; return size; &#125; private class ConcreteIterator implements Iterator&lt;E&gt;&#123; int cursor; @Override public boolean hasNext() &#123; return cursor != size ; &#125; @Override public E next() &#123; return (E) elementData[cursor++]; &#125; &#125;&#125; 测试类12345678910111213141516171819package factory.pattern.iterator;/** * Created by FK on 2017/8/17. */public class Test &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add(&quot;one&quot;); list.add(&quot;two&quot;); list.add(&quot;three&quot;); list.add(&quot;four&quot;); Iterator&lt;String&gt; iterator = list.iterator(); while (iterator.hasNext())&#123; String str = iterator.next(); System.out.println(str); &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[解释器模式]]></title>
      <url>%2F20170811%2FDesign_pattern%2F18_interpreter%2F</url>
      <content type="text"><![CDATA[解释器模式介绍解释器模式：给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。（行为型模式） 解释器模式uml图一般如下： AbstractExpression 抽象解释器 &nbsp;&nbsp;&nbsp;&nbsp; 具体的解释任务由各个实现类完成，具体的解释器分别由TerminalExpression和NonterminalExpression完成。 TerminalExpression终结符表达式 &nbsp;&nbsp;&nbsp;&nbsp;实现与文法中的元素相关联的解释操作，通常一个解释器模式中只有一个终结符表达式，但有多个实例，对应不同的终结符。具体到我们例子就是VarExpression类，表达式中的每个终结符都在堆栈中产生了一个VarExpression对象。 NonterminalExpression 非终结符表达式 &nbsp;&nbsp;&nbsp;&nbsp;文法中的每条规则对应于一个非终结表达式，具体到我们的例子就是加减法规则分别对应到AddExpression和SubExpression两个类。非终结符表达式根据逻辑的复杂程度而增加，原则上每个文法规则都对应一个非终结符表达式。 Context 环境角色 &nbsp;&nbsp;&nbsp;&nbsp;具体到我们的例子中是采用HashMap代替。 正则表达式就是使用了解释器模式解释器模式在实际的系统开发中使用的非常少，因为它会引起效率、性能以及维护等问题，一般在大中型的框架型项目能够找到它的身影，比如一些数据分析工具、报表设计工具、科学计算工具等等，若你确实遇到“一种特定类型的问题发生的频率足够高”的情况，准备使用解释器模式时，可以考虑一下Expression4J、MESP（Math Expression String Parser）、Jep等开源的解析工具包，功能都异常强大，而且非常容易使用，效率也还不错，实现大多数的数学运算完全没有问题. 优缺点优点解释器是一个简单语法分析工具，它最显著的优点就是扩展性，修改语法规则只要修改相应的非终结符表达式就可以了，若扩展语法，则只要增加非终结符类就可以了。 缺点 每个语法都要产生一个非终结符表达式，语法规则比较复杂时，就可能产生大量的类文件，为维护带来了非常多的麻烦。 解释器模式采用递归调用方法，如果要排查一个语法错误，要一个一个断点的调试下去，会很麻烦。 解释器模式使用了大量的循环和递归，特别是用于解析复杂、冗长的语法时，效率会很低。 DEMO设计一个四则运算（这里只写了加减），可以应用各种模型公式。uml图如下： 代码如下： 抽象解释器 12345678910package factory.pattern.interpreter;import java.util.HashMap;/** * Created by FK on 2017/8/11. */public abstract class Expression &#123; public abstract int interpreter(HashMap&lt;String, Integer&gt; var);&#125; 抽象非终结符表达式，定义文法中的规则 1234567891011121314package factory.pattern.interpreter;/** * Created by FK on 2017/8/11. */public abstract class SymbolExpression extends Expression &#123; protected Expression left; protected Expression right; public SymbolExpression(Expression left, Expression right) &#123; this.left = left; this.right = right; &#125;&#125; 具体的非终结符表达式 123456789101112131415161718package factory.pattern.interpreter;import java.util.HashMap;/** * Created by FK on 2017/8/11. */public class AddExpression extends SymbolExpression&#123; public AddExpression(Expression left, Expression right) &#123; super(left, right); &#125; @Override public int interpreter(HashMap&lt;String, Integer&gt; var) &#123; return super.left.interpreter(var) + super.right.interpreter(var); &#125;&#125; 具体的非终结符表达式 1234567891011121314151617package factory.pattern.interpreter;import java.util.HashMap;/** * Created by FK on 2017/8/11. */public class SubExpression extends SymbolExpression &#123; public SubExpression(Expression left, Expression right) &#123; super(left, right); &#125; @Override public int interpreter(HashMap&lt;String, Integer&gt; var) &#123; return super.left.interpreter(var) - super.right.interpreter(var); &#125;&#125; 终结符表达式 12345678910111213141516171819package factory.pattern.interpreter;import java.util.HashMap;/** * Created by FK on 2017/8/11. */public class VarExpression extends Expression &#123; private String key; public VarExpression(String key) &#123; this.key = key; &#125; @Override public int interpreter(HashMap&lt;String, Integer&gt; var) &#123; return var.get(key); &#125;&#125; Calcuator的作用是封装，根据迪米特原则，Client只与直接的朋友Calcuator交流，与其他类没关系。 123456789101112131415161718192021222324252627282930313233343536373839404142package factory.pattern.interpreter;import java.util.HashMap;import java.util.Stack;/** * Created by FK on 2017/8/11. */public class Calculator &#123; //表达式 private Expression expression; public Calculator(String expStr)&#123; Stack&lt;Expression&gt; stack = new Stack&lt;&gt;(); //表达式拆分为字符数组 char[] charArray = expStr.toCharArray(); Expression left = null; Expression right = null; for(int i=0;i&lt;charArray.length;i++)&#123; switch (charArray[i])&#123; case &apos;+&apos; : left = stack.pop(); right = new VarExpression(String.valueOf(charArray[++i])); stack.push(new AddExpression(left, right)); break; case &apos;-&apos;: left = stack.pop(); right = new VarExpression(String.valueOf(charArray[++i])); stack.push(new SubExpression(left,right)); break; default: stack.push(new VarExpression(String.valueOf(charArray[i]))); &#125; &#125; this.expression = stack.pop(); &#125; public int run(HashMap&lt;String, Integer&gt; var)&#123; return this.expression.interpreter(var); &#125;&#125; 测试12345678910111213141516171819202122232425262728293031323334353637383940package factory.pattern.interpreter;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.util.HashMap;/** * Created by FK on 2017/8/11. */public class Test &#123; public static void main(String[] args) throws IOException &#123; String expStr = getExpStr(); HashMap&lt;String, Integer&gt; var = getValue(expStr); Calculator calculator = new Calculator(expStr); System.out.println(&quot;运算结果为：&quot;+expStr +&quot;=&quot;+calculator.run(var)); &#125; public static String getExpStr() throws IOException &#123; System.out.println(&quot;输入表达式&quot;); return (new BufferedReader((new InputStreamReader(System.in)))).readLine(); &#125; public static HashMap&lt;String, Integer&gt; getValue(String expreStr) throws IOException &#123; HashMap&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); for(char ch : expreStr.toCharArray())&#123; if(ch != &apos;+&apos; &amp;&amp; ch != &apos;-&apos;)&#123; if(!map.containsKey(String.valueOf(ch)))&#123; System.out.print(&quot;请输入&quot;+ch+&quot;的值:&quot;); String in = (new BufferedReader(new InputStreamReader(System.in))).readLine(); map.put(String.valueOf(ch),Integer.valueOf(in)); &#125; &#125; &#125; return map; &#125;&#125; 输出结果 123456输入表达式a+b-c请输入a的值:100请输入b的值:20请输入c的值:40运算结果为：a+b-c=80]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[命令模式]]></title>
      <url>%2F20170808%2FDesign_pattern%2F17_command%2F</url>
      <content type="text"><![CDATA[命令模式介绍 在软件系统中，行为请求者与行为实现者通常是一种紧耦合关系，但是有时候，比如需要对行为进行记录、撤销或重做、事务等处理时，这种无法抵御变化的紧耦合关系就不大合适。 将一个请求封装成一个对象，从而是你可用不同的请求对客户进行参数化，对请求排队和记录请求日志，以及支持可撤销的操作。命令模式就是对命令进行封装，把发出命令和执行命令分开，请求方并不知道命令是怎么被接受，也不知道命令是否执行，什么时候执行，怎么被执行的；使用命令模式可以使请求成为一个对象，这个对象可以和其他对象一样被存储和传递。 涉及角色 抽象命令（command）：定义命令的接口，申明执行的方法。 具体命令（concreteCommand）：具体命令，实现要执行的方法，它通常是“虚”的表现；通常会有接受者，并调用接受者的功能来完成命令要执行的操作。 接受者（receiver）：真正执行命令的对象。任何类都可能成为一个接受者，只要实现命令要求实现的相应功能。 调用者（invoker）：要求命令对象执行请求，通常会持有命令对象，可以持有很多的命令对象。 优缺点优点 解除了请求者与实现者之间的耦合，降低了系统的耦合度 对请求排队或记录请求日志，支持撤销操作 可以容易地设计一个组合命令 新命令可以容易地加入到系统中 缺点 因为针对每一个命令都需要设计一个具体命令类，使用命令模式可能会导致系统有过多的具体命令类 适用场景 当需要对行为进行“记录、撤销/重做”等处理时。 系统需要将请求者和接收者解耦，使得调用者和接收者不直接交互。 系统需要在不同时间指定请求、请求排队和执行请求。 系统需要将一组操作组合在一起，即支持宏命令。 DEMOcommand12345678package factory.pattern.command.demo1;/** * Created by FK on 2017/8/8. */public interface Order &#123; void execute();&#125; concreteCommand 123456789101112131415161718package factory.pattern.command.demo1;/** * Created by FK on 2017/8/8. */public class BuyStock implements Order&#123; private Stock abcStock; public BuyStock(Stock abcStock) &#123; this.abcStock = abcStock; &#125; @Override public void execute() &#123; abcStock.buy(); &#125;&#125; 1234567891011121314151617package factory.pattern.command.demo1;/** * Created by FK on 2017/8/8. */public class SellStock implements Order &#123; private Stock abcStock; public SellStock(Stock abcStock)&#123; this.abcStock = abcStock; &#125; @Override public void execute() &#123; abcStock.sell(); &#125;&#125; receive1234567891011121314151617package factory.pattern.command.demo1;/** * Created by FK on 2017/8/8. */public class Stock &#123; private String name = &quot;ABC&quot;; private int quantity = 10; public void buy()&#123; System.out.println(&quot;Stock [ Name: &quot;+name+&quot;,Quantity: &quot; + quantity +&quot; ] bought&quot;); &#125; public void sell()&#123; System.out.println(&quot;Stock [ Name: &quot;+name+&quot;,Quantity: &quot; + quantity +&quot; ] sold&quot;); &#125;&#125; invoker12345678910111213141516171819202122package factory.pattern.command.demo1;import java.util.ArrayList;import java.util.List;/** * Created by FK on 2017/8/8. */public class Broker &#123; private List&lt;Order&gt; orderList = new ArrayList&lt;Order&gt;(); public void takeOrder(Order order)&#123; orderList.add(order); &#125; public void placeOrders()&#123; for (Order order : orderList) &#123; order.execute(); &#125; orderList.clear(); &#125;&#125; TEST123456789101112131415161718package factory.pattern.command.demo1;/** * Created by FK on 2017/8/8. */public class Test &#123; public static void main(String[] args) &#123; Stock abcStock = new Stock(); BuyStock buyStock = new BuyStock(abcStock); SellStock sellStock = new SellStock(abcStock); Broker broker = new Broker(); broker.takeOrder(buyStock); broker.takeOrder(sellStock); broker.placeOrders(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[责任链模式]]></title>
      <url>%2F20170806%2FDesign_pattern%2F16_chainOfResponsibility%2F</url>
      <content type="text"><![CDATA[责任链模式介绍在责任链模式里，很多对象由每一个对象对其下家的引用而连接起来形成一条链。请求会在这个链上传递，直到链上某一个对象可以处理这个请求。（行为型模式） 结构图责任链模式的结构像下面这样： 抽象处理者角色（handler）：定义一个处理请求的接口，还可以定义一个后继连接（可选）。 具体处理者角色（ConcreteHandler）：具体处理者接到请求后，如果可以处理就处理请求，如果不能处理就把请求传给下一个继承。 优缺点优点 降低耦合度：client发送请求并不需要知道是哪个对象处理的请求。 责任链可简化对象的相互链接：它们仅需保持一个指向其后继者的引用，而不需保持它所有的候选接受者的引用。 增强给对象指派职责的灵活性： 通过改变链内的成员或者调动它们的次序，允许动态地新增或者删除责任。 加新的请求处理类很方便。 缺点 不能保证请求一定被处理。 系统性能有一定影响，调试时候不方面，可能造成循环调用。 DEMO责任链模式经常用于过滤，如果要过滤一句话中的文字是，首先定义一个过滤器接口12345678package factory.pattern.chainOfResponsibility;/** * Created by FK on 2017/8/6. */public interface Filter &#123; String doFilter(String str);&#125; 实现过滤HTML标记1234567891011121314package factory.pattern.chainOfResponsibility;/** * Created by FK on 2017/8/6. */public class HtmlFilter implements Filter &#123; @Override public String doFilter(String str) &#123; String r = str; //过滤msg中的HTML标记 r = r.replace(&quot;&lt;&quot;, &quot;&amp;lt;&quot;).replace(&quot;&gt;&quot;, &quot;&amp;gt;&quot;); return r; &#125;&#125; 实现敏感词过滤1234567891011121314package factory.pattern.chainOfResponsibility;/** * Created by FK on 2017/8/6. */public class SensitiveFilter implements Filter &#123; @Override public String doFilter(String str) &#123; String r = str; //过滤敏感词 r = r.replace(&quot;敏感&quot;, &quot;&quot;).replace(&quot;被就业&quot;, &quot;就业&quot;); return r; &#125;&#125; 控制整个链12345678910111213141516171819202122232425package factory.pattern.chainOfResponsibility;import java.util.ArrayList;import java.util.List;/** * Created by FK on 2017/8/6. */public class FilterChain implements Filter &#123; public List&lt;Filter&gt; filters = new ArrayList&lt;&gt;(); public FilterChain addFilter(Filter f)&#123; filters.add(f); return this; &#125; @Override public String doFilter(String str) &#123; String r = str; for(Filter f : filters)&#123; r = f.doFilter(r); &#125; return r; &#125;&#125; 测试1234567891011121314151617package factory.pattern.chainOfResponsibility;/** * Created by FK on 2017/8/6. */public class Test &#123; public static void main(String[] args) &#123; //需要被过滤的语句 String str = &quot;被就业了：），敏感信息，&lt;script&gt;&quot;; //搞一个过过滤链 FilterChain chain = new FilterChain(); chain.addFilter(new HtmlFilter()).addFilter(new SensitiveFilter()); String s = chain.doFilter(str); System.out.println(s); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[代理模式]]></title>
      <url>%2F20170803%2FDesign_pattern%2F15_proxy%2F</url>
      <content type="text"><![CDATA[代理模式介绍代理模式为其他对象提供一种代理以控制对这个对象的访问。（结构型模式）代理模式提供三种角色： 抽象角色：声明真实对象和代理对象的共同接口。 代理角色：代理对象角色内部含有对真实对象的引用，从而可以操作真实对象，同时代理对象提供与真实对象相同的接口以便在任何时刻都能代替真实对象。同时，代理对象可以在执行真实对象操作时，附加其他的操作，相当于对真实对象进行封装。 真实角色：代理角色所代表的真实对象，是我们最终要引用的对象。代理模式对外部提供统一的接口方法，而代理类在接口中实现对真实类的附加操作行为，从而可以在不影响外部调用情况下，进行系统扩展。 分类静态代理静态代理就是我们自己静态定义的代理类，例如我们要进行图片加载的时候，可以通过一个代理类减少图片对象加载的内存占用： DEMO图片接口12345678package factory.pattern.proxy.demo1;/** * Created by FK on 2017/8/3. */public interface Image &#123; void dispalay();&#125; 接口实体类 12345678910111213141516171819202122package factory.pattern.proxy.demo1;/** * Created by FK on 2017/8/3. */public class RealImage implements Image &#123; private String fileName; public RealImage(String fileName) &#123; this.fileName = fileName; loadFormDisk(fileName); &#125; private void loadFormDisk(String fileName) &#123; System.out.println(&quot;Loading &quot; + fileName); &#125; @Override public void dispalay() &#123; System.out.println(&quot;Displaying &quot; + fileName); &#125;&#125; 123456789101112131415161718192021package factory.pattern.proxy.demo1;/** * Created by FK on 2017/8/3. */public class ProxyImage implements Image &#123; private RealImage realImage; private String fileNmme; public ProxyImage(String fileNmme) &#123; this.fileNmme = fileNmme; &#125; @Override public void dispalay() &#123; if( realImage == null)&#123; realImage = new RealImage(fileNmme); &#125; realImage.dispalay(); &#125;&#125; 测试12345678910111213package factory.pattern.proxy.demo1;/** * Created by FK on 2017/8/3. */public class Test &#123; public static void main(String[] args) &#123; Image image = new ProxyImage(&quot;test.jpg&quot;); image.dispalay(); System.out.println(); image.dispalay(); &#125;&#125; 动态代理动态代理不需要实现接口，是利用JDK的API来实现代理对象的生成，所以动态代理也是JDK代理。 JDK中生成代理对象的API 代理类所在包:java.lang.reflect.Proxy JDK实现代理只需要使用newProxyInstance方法,但是该方法需要接收三个参数,完整的写法是:12&gt; static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces,InvocationHandler h )&gt; 注意该方法是在Proxy类中是静态方法,且接收的三个参数依次为: ClassLoader loader,:指定当前目标对象使用类加载器,获取加载器的方法是固定的 Class&lt;?&gt;[] interfaces,:目标对象实现的接口的类型,使用泛型方式确认类型 InvocationHandler h:事件处理,执行目标对象的方法时,会触发事件处理器的方法,会把当前执行目标对象的方法作为参数传入 DEMO12345678910111213141516171819202122232425262728package factory.pattern.proxy.demo2;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;/** * Created by FK on 2017/8/4. */public class ProxyFactory &#123; private Object target; public ProxyFactory(Object target) &#123; this.target = target; &#125; public Object getProxyInstance()&#123; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; Object returnValue = method.invoke(target, args); return returnValue; &#125; &#125;); &#125;&#125; 测试 1234567891011121314151617package factory.pattern.proxy.demo2;import factory.pattern.proxy.demo1.Image;import factory.pattern.proxy.demo1.RealImage;/** * Created by FK on 2017/8/4. */public class Test &#123; public static void main(String[] args) &#123; Image image = new RealImage(&quot;test1.jpg&quot;); System.out.println(image.getClass()); Image proxy = (Image) new ProxyFactory(image).getProxyInstance(); System.out.println(proxy.getClass()); proxy.dispalay(); &#125;&#125; 应用场合远程代理就是为一个对象在不同的地址空间提供局部代表，这样可以隐藏一个对象存在不同地址空间的事实。 虚拟代理根据需要创建开销很大的对象。通过它来存放实例化需要很长时间的真实对象。 html网页加载的时候图片是下载之后才能看到，未打开的图片框只存放了真实图片的路径和尺寸。 安全代理安全代理用来控制真实对象访问时的权限。 智能指引当调用真实的对象时，代理处理另外一些事。 计算真是对象的引用次数，当该对象没有引用时，可以自动释放它；或当第一次引用一个持久化对象，将它装载如内存。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[享元模式]]></title>
      <url>%2F20170801%2FDesign_pattern%2F14_flyweight%2F</url>
      <content type="text"><![CDATA[享元模式介绍享元模式使用共享来避免大量拥有相同内容对象的开销，避免内存的损耗。享元对象能做到共享的关键是区分内蕴状态和外蕴状态。内蕴状态是存储在享元对象内部的，不会随环境的改变而有所不同（内蕴状态可以共享）。外蕴状态是随环境的改变而改变的，不可以共享，外蕴状态不可以影响享元对象的内蕴状态，它们是相互独立的。 优点 大幅度地降低内存中对象的数量 缺点 使得系统更加复杂 享元模式将享元对象的状态外部化，而读取外部状态使得运行时间稍微变长 结构(涉及角色) Flyweight：抽象享元角色，规定具体享元角色要实现的方法。 ConcreteFlyweight：具体享元角色，实现抽象享元规定的接口。 FlyweightFactory：享元工厂角色，负责创建和管理享元角色。 DEMO抽象享元角色，抽象享元中接受一个参数state，state是外蕴状态，由外部传入的不可被共享。 12345678package factory.pattern.flyweight;/** * Created by FK on 2017/8/1. */public interface FlyWeight &#123; public void operation(String state);&#125; 具体享元角色，内部intrinsticState是内蕴状态，内蕴状态在被对象创建后就不会在改变了。 123456789101112131415161718package factory.pattern.flyweight;/** * Created by FK on 2017/8/1. */public class ConcreteFlyWeight implements FlyWeight &#123; private Character intrinsicState = null; public ConcreteFlyWeight(Character intrinsicState) &#123; this.intrinsicState = intrinsicState; &#125; @Override public void operation(String state) &#123; System.out.println(&quot;Intrinsic State = &quot; + this.intrinsicState); System.out.println(&quot;Extrinsic State = &quot; + state); &#125;&#125; 享元工厂类（客户端不可以直接将具体享元类实例化， 必须通过一个工厂对象得到享元对象） 123456789101112131415161718192021222324252627package factory.pattern.flyweight;import java.util.HashMap;import java.util.Map;/** * Created by FK on 2017/8/1. */public class FlyWeightFactory &#123; private Map&lt;Character, FlyWeight&gt; files = new HashMap&lt;&gt;(); //享元工厂在系统中只有一个，可以使用单利模式来获取 private static FlyWeightFactory flyWeightFactory = new FlyWeightFactory(); private FlyWeightFactory()&#123;&#125; public static FlyWeightFactory getInstance()&#123; return flyWeightFactory; &#125; public FlyWeight factory(Character state)&#123; FlyWeight fly = files.get(state); if(fly == null)&#123; fly = new ConcreteFlyWeight(state); files.put(state, fly); &#125; return fly; &#125;&#125; 测试：1234567891011121314151617181920package factory.pattern.flyweight;/** * Created by FK on 2017/8/1. */public class Test &#123; public static void main(String[] args) &#123; FlyWeightFactory factory = FlyWeightFactory.getInstance(); FlyWeight fly = factory.factory(new Character(&apos;a&apos;)); fly.operation(&quot;first call&quot;); fly = factory.factory(new Character(&apos;b&apos;)); fly.operation(&quot;Second Call&quot;); fly = factory.factory(new Character(&apos;a&apos;)); fly.operation(&quot;Third Call&quot;); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[外观模式]]></title>
      <url>%2F20170801%2FDesign_pattern%2F13_facede%2F</url>
      <content type="text"><![CDATA[外观模式介绍为子系统中的一组接口提供一个一致的界面，定义一个高层接口，这个接口使得这一子系统更加容易使用。就像下图，facade把众多子系统中通过一个接口统一起来： 适用场景 设计初期阶段，应该有意识的将不同层分离，层与层之间建立外观模式。 开发阶段，子系统越来越复杂，增加外观模式提供一个简单的调用接口。 维护一个大型遗留系统的时候，可能这个系统已经非常难以维护和扩展，但又包含非常重要的功能，为其开发一个外观类，以便新系统与其交互。 优点 实现了子系统与客户端之间的松耦合关系。 客户端屏蔽了子系统组件，减少了客户端所需处理的对象数目，并使得子系统使用起来更加容易。 提高了安全性。 DEMO子系统：1234567891011121314151617181920212223242526272829303132333435363738394041424344package factory.pattern.facade;/** * Created by FK on 2017/8/1. */public interface Shape &#123; void draw();&#125;package factory.pattern.facade;/** * Created by FK on 2017/8/1. */public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Circle::draw()&quot;); &#125;&#125;package factory.pattern.facade;/** * Created by FK on 2017/8/1. */public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Rectangle::draw()&quot;); &#125;&#125;package factory.pattern.facade;/** * Created by FK on 2017/8/1. */public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Square::draw()&quot;); &#125;&#125; facade :12345678910111213141516171819202122232425262728package factory.pattern.facade;/** * Created by FK on 2017/8/1. */public class ShapeFacade &#123; private Shape circle; private Shape rectangle; private Shape square; public ShapeFacade() &#123; circle = new Circle(); rectangle = new Rectangle(); square = new Square(); &#125; public void drawCircle()&#123; circle.draw(); &#125; public void drawRectangle()&#123; rectangle.draw(); &#125; public void drawSquare()&#123; square.draw(); &#125;&#125; 测试类：1234567891011121314package factory.pattern.facade;/** * Created by FK on 2017/8/1. */public class FacadeTest &#123; public static void main(String[] args) &#123; ShapeFacade shapeFacade = new ShapeFacade(); shapeFacade.drawCircle(); shapeFacade.drawRectangle(); shapeFacade.drawSquare(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[装饰器模式]]></title>
      <url>%2F20170801%2FDesign_pattern%2F12_decorator%2F</url>
      <content type="text"><![CDATA[装饰器模式介绍装饰器模式允许向一个现有的对象添加新功能，同时又不改变其结构。（结构型模式）这种形式在没有原类文件和使用继承的情况下动态的扩展了一个对象的功能。类的继承是在编译是时候增加的功能，而装饰器模式在运行时增加的功能 装饰器模式构成 Component : 组件对象接口，可以给这些对象动态添加职责 ConcreteComponent ： 具体的组件对象，实现了组件接口。这个对象通常是被装饰器修饰的原始对象，可以给这个对象添加职责。 Decorate : 所有装饰器的父类，需要定义一个与组件接口一直的接口（实现装饰器的复用），并持有component对象，这个对象就是被装饰的对象。如果不继承组件接口类，则只能为某个组件添加单一的功能，即装饰器对象不能在装饰其他的装饰器对象。 ConcreteDecorator：具体的装饰器类，实现具体要向被装饰对象添加的功能。用来装饰具体的组件对象或者另外一个具体的装饰器对象。 DEMOComponent 12345678package factory.pattern.Decorator;/** * Created by FK on 2017/8/1. */public interface Shape &#123; void draw();&#125; ConcreteComponent 1234567891011121314151617181920212223package factory.pattern.Decorator;/** * Created by FK on 2017/8/1. */public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Shape : Circle&quot;); &#125;&#125;package factory.pattern.Decorator;/** * Created by FK on 2017/8/1. */public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Shape : Rectangle&quot;); &#125;&#125; Decorate 1234567891011121314151617package factory.pattern.Decorator;/** * Created by FK on 2017/8/1. */public abstract class ShapeDecorator implements Shape &#123; protected Shape decoratorShape; public ShapeDecorator(Shape decoratorShape) &#123; this.decoratorShape = decoratorShape; &#125; public void draw()&#123; decoratorShape.draw(); &#125;&#125; ConcreteDecorator 123456789101112131415161718192021222324package factory.pattern.Decorator;import java.util.ArrayList;import java.util.List;/** * Created by FK on 2017/8/1. */public class RedShapeDecorator extends ShapeDecorator &#123; public RedShapeDecorator(Shape decoratorShape) &#123; super(decoratorShape); &#125; @Override public void draw() &#123; decoratorShape.draw(); setRedBorder(decoratorShape); &#125; public void setRedBorder(Shape redBorder) &#123; System.out.println(&quot;Border Color : Red&quot;); List&lt;String&gt; list = new ArrayList&lt;&gt;(); &#125;&#125; TEST 12345678910111213141516171819package factory.pattern.Decorator;/** * Created by FK on 2017/8/1. */public class DecoratorPatternDemo &#123; public static void main(String[] args) &#123; Shape shape = new Circle(); Shape redCircle = new RedShapeDecorator(new Circle()); Shape redRectangle = new RedShapeDecorator(new Rectangle()); System.out.println(&quot;Circle with normal border&quot;); shape.draw(); System.out.println(&quot;\nCircle of red border&quot;); redCircle.draw(); System.out.println(&quot;\nRectangle of red border&quot;); redRectangle.draw(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[组合模式]]></title>
      <url>%2F20170729%2FDesign_pattern%2F11_composite%2F</url>
      <content type="text"><![CDATA[组合模式介绍组合模式将对象组合成树形结构表示“部分-整体”的层次结构，组合模式使用户对单个对象和组合对象的使用具有一致性。（结构型）就像文件系统一样，文件由目录和文件组成，每个目录都可以装载目录，目录的内容既可以是文件，也可以是目录。计算机的文件系统就是以递归结构来组织的，这种情景就适用于组合模式。 使用场景和涉及的角色适用性 你想表示对象的部分-整体层次结构 你希望用户忽略组合对象与单个对象的不同，用户将统一地使用组合结构中的所有对象。 涉及角色 Component 是组合中的对象声明接口，在适当的情况下，实现所有类共有接口的默认行为。声明一个接口用于访问和管理Component子部件。 Leaf 在组合中表示叶子结点对象，叶子结点没有子结点。 Composite 定义有枝节点行为，用来存储子部件，在Component接口中实现与子部件有关操作，如增加(add)和删除(remove)等。 DEMO123456789101112131415161718192021222324252627282930package factory.pattern.composite.test;/** * Created by FK on 2017/7/30. */public abstract class Component &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Component()&#123;&#125; public Component(String name) &#123; this.name = name; &#125; protected abstract void add(Component company); protected abstract void remove(Component company); protected abstract void display(int depth);&#125; 枝节点行为，具体目录类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package factory.pattern.composite.test;import java.util.ArrayList;import java.util.List;/** * Created by FK on 2017/7/30. */public class CatalogComponent extends Component &#123; List&lt;Component&gt; list; public List&lt;Component&gt; getList() &#123; return list; &#125; public void setList(List&lt;Component&gt; list) &#123; this.list = list; &#125; public CatalogComponent() &#123; list = new ArrayList&lt;&gt;(); &#125; public CatalogComponent(String name) &#123; super(name); list = new ArrayList&lt;&gt;(); &#125; @Override protected void add(Component company) &#123; list.add(company); &#125; @Override protected void remove(Component company) &#123; list.remove(company); &#125; @Override protected void display(int depth) &#123; StringBuffer sb = new StringBuffer(); for(int i=0;i&lt;depth;i++)&#123; sb.append(&quot;-&quot;); &#125; System.out.println(new String(sb) + this.getName()); for(Component c : list)&#123; c.display(depth + 2); &#125; &#125;&#125; 叶子结点对象,文件123456789101112131415161718192021222324252627282930313233package factory.pattern.composite.test;/** * Created by FK on 2017/7/30. */public class Leaf extends Component &#123; public Leaf() &#123; super(); &#125; public Leaf(String name) &#123; super(name); &#125; @Override protected void add(Component company) &#123; &#125; @Override protected void remove(Component company) &#123; &#125; @Override protected void display(int depth) &#123; StringBuffer sb = new StringBuffer(); for(int i=0;i&lt;depth;i++)&#123; sb.append(&quot;-&quot;); &#125; System.out.println(new String(sb) + this.getName()); &#125;&#125; 测试类1234567891011121314151617package factory.pattern.composite.test;/** * Created by FK on 2017/7/30. */public class Test &#123; public static void main(String[] args) &#123; Component c = new CatalogComponent(); Component c1 = new CatalogComponent(&quot;一级目录1&quot;); Component c2 = new CatalogComponent(&quot;二级目录1&quot;); c2.add(new Leaf(&quot;文件1&quot;)); c1.add(c2); c.add(c1); c.add(new CatalogComponent(&quot;一级目录2&quot;)); c.display(0); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[过滤器模式]]></title>
      <url>%2F20170727%2FDesign_pattern%2F10_filter%2F</url>
      <content type="text"><![CDATA[过滤器模式介绍过滤器模式允许开发者用不同的标准过滤一组对象。（结构型模式）使用过滤器模式可以很方便的进行扩展，单独一个过滤器的执行是独立的，不依赖其他过滤器。 DEMO例如，一个Person类有姓名、性别、婚姻状况属性 ：1234567891011121314151617181920212223242526272829303132333435363738394041424344package factory.pattern.filter;/** * Created by fk5431 on 7/27/17. */public class Person &#123; private String name; private String sex; private String marital; public Person(String name, String sex, String marital)&#123; this.name = name; this.sex = sex; this.marital = marital; &#125; public String getName() &#123; return name; &#125; public String getSex() &#123; return sex; &#125; public String getMarital() &#123; return marital; &#125; public void setName(String name) &#123; this.name = name; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public void setMarital(String marital) &#123; this.marital = marital; &#125; @Override public String toString() &#123; return &quot;Persion name : &quot; + this.name + &quot; sex &quot; + this.sex + &quot; marital &quot; + this.marital; &#125;&#125; 建立一个过滤器标准12345678910package factory.pattern.filter;import java.util.List;/** * Created by fk5431 on 7/27/17. */public interface Filter &#123; List&lt;Person&gt; filter(List&lt;Person&gt; persions);&#125; 实现男性过滤和未婚过滤1234567891011121314151617181920212223242526272829303132333435363738394041package factory.pattern.filter;import java.util.ArrayList;import java.util.List;/** * Created by fk5431 on 7/27/17. */public class MaleFilter implements Filter &#123; @Override public List&lt;Person&gt; filter(List&lt;Person&gt; persions) &#123; List&lt;Person&gt; result = new ArrayList&lt;Person&gt;(); for(Person p : persions)&#123; if (&quot;MALE&quot;.equalsIgnoreCase(p.getSex()))&#123; result.add(p); &#125; &#125; return result; &#125;&#125;package factory.pattern.filter;import java.util.ArrayList;import java.util.List;/** * Created by fk5431 on 7/27/17. */public class SingleFilter implements Filter &#123; @Override public List&lt;Person&gt; filter(List&lt;Person&gt; persions) &#123; List&lt;Person&gt; result = new ArrayList&lt;Person&gt;(); for(Person p : persions)&#123; if (&quot;SINGLE&quot;.equalsIgnoreCase(p.getMarital()))&#123; result.add(p); &#125; &#125; return result; &#125;&#125; 过滤器可以进行叠加和其他操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package factory.pattern.filter;import java.util.List;/** * Created by fk5431 on 7/27/17. */public class FilterAnd implements Filter &#123; private Filter filter; private Filter otherfilter; public FilterAnd(Filter filter, Filter otherfilter)&#123; this.filter = filter; this.otherfilter = otherfilter; &#125; @Override public List&lt;Person&gt; filter(List&lt;Person&gt; persions) &#123; List&lt;Person&gt; tmpList = filter.filter(persions); return otherfilter.filter(tmpList); &#125;&#125;package factory.pattern.filter;import java.util.List;/** * Created by fk5431 on 7/27/17. */public class FilterOr implements Filter &#123; private Filter filter; private Filter otherfilter; public FilterOr(Filter filter, Filter otherfilter)&#123; this.filter = filter; this.otherfilter = otherfilter; &#125; @Override public List&lt;Person&gt; filter(List&lt;Person&gt; persions) &#123; List&lt;Person&gt; tmpList = filter.filter(persions); List&lt;Person&gt; tmpList2 = otherfilter.filter(persions); for(Person p : tmpList2)&#123; if(!tmpList.contains(p))&#123; tmpList.add(p); &#125; &#125; return tmpList; &#125;&#125; 最后进行测试1234567891011121314151617181920212223242526272829303132333435363738394041424344package factory.pattern.filter;import java.util.ArrayList;import java.util.List;/** * Created by fk5431 on 7/27/17. */public class Test &#123; public static void main(String[] args) &#123; List&lt;Person&gt; persons = new ArrayList&lt;&gt;(); persons.add(new Person(&quot;霍一&quot;, &quot;FEMALE&quot;, &quot;MARRIED&quot;)); persons.add(new Person(&quot;邓二&quot;, &quot;MALE&quot;, &quot;MARRIED&quot;)); persons.add(new Person(&quot;张三&quot;, &quot;MALE&quot;, &quot;SINGLE&quot;)); persons.add(new Person(&quot;李四&quot;, &quot;FEMALE&quot;, &quot;MARRIED&quot;)); persons.add(new Person(&quot;王五&quot;, &quot;MALE&quot;, &quot;SINGLE&quot;)); persons.add(new Person(&quot;赵六&quot;, &quot;FEMALE&quot;, &quot;SINGLE&quot;)); persons.add(new Person(&quot;孙七&quot;, &quot;MALE&quot;, &quot;SINGLE&quot;)); persons.add(new Person(&quot;罗八&quot;, &quot;MALE&quot;, &quot;MARRIED&quot;)); persons.add(new Person(&quot;刘九&quot;, &quot;FEMALE&quot;, &quot;SINGLE&quot;)); persons.add(new Person(&quot;史十&quot;, &quot;FEMALE&quot;, &quot;SINGLE&quot;)); List&lt;Person&gt; malePerson = new MaleFilter().filter(persons); for(Person p : malePerson)&#123; System.out.println(p.toString()); &#125; System.out.println(); System.out.println(); System.out.println(); System.out.println(); List&lt;Person&gt; singlePerson = new MaleFilter().filter(persons); for(Person p : singlePerson)&#123; System.out.println(p.toString()); &#125; System.out.println(); System.out.println(); System.out.println(); System.out.println(); List&lt;Person&gt; singleAndMalePerson = new FilterAnd(new MaleFilter(), new SingleFilter()).filter(persons); for(Person p : singleAndMalePerson)&#123; System.out.println(p.toString()); &#125; &#125;&#125; 输出结果如下： Persion name : 邓二 sex MALE marital MARRIED Persion name : 张三 sex MALE marital SINGLE Persion name : 王五 sex MALE marital SINGLE Persion name : 孙七 sex MALE marital SINGLE Persion name : 罗八 sex MALE marital MARRIED Persion name : 邓二 sex MALE marital MARRIED Persion name : 张三 sex MALE marital SINGLE Persion name : 王五 sex MALE marital SINGLE Persion name : 孙七 sex MALE marital SINGLE Persion name : 罗八 sex MALE marital MARRIED Persion name : 张三 sex MALE marital SINGLE Persion name : 王五 sex MALE marital SINGLE Persion name : 孙七 sex MALE marital SINGLE]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[桥接模式]]></title>
      <url>%2F20170726%2FDesign_pattern%2F9_Bridge%2F</url>
      <content type="text"><![CDATA[桥接模式介绍桥接适用于把抽象化与实现化解耦，使得二者可以独立变化。（结构型模式）用来解决两个或者多个纬度的变化，使用桥接模式可以降低复杂度。将两个角色之间的继承关系改为聚合关系，这样两者可以独立的变化。 例子就像大话设计模式中讲的一样，每个手机都有其对应的功能（软件），而这些功能在不同手机上可能不兼容，那么列出一个手机品牌和其对应的部分功能的结构图如下：但是这样的话，不管要增加一个手机品牌还是要增加一个软件，操作都会很复杂。因此用桥接模式把这这两个维度之间的继承关系改为聚合关系会使这个问题变得简单，聚合关系的结构图如下： DEMO手机软件抽象类12345678package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public abstract class HandSetSoft &#123; public abstract void run();&#125; 手机游戏1234567891011package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public class HandSetGame extends HandSetSoft &#123; @Override public void run() &#123; System.out.println(&quot;运行手机游戏&quot;); &#125;&#125; 手机通讯录1234567891011package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public class HandSetAdressList extends HandSetSoft &#123; @Override public void run() &#123; System.out.println(&quot;运行手机通讯录&quot;); &#125;&#125; 手机品牌1234567891011121314package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public abstract class HandSetBrand &#123; HandSetSoft handSetSoft; public void setHandSetSoft(HandSetSoft handSetSoft)&#123; this.handSetSoft = handSetSoft; &#125; public abstract void run();&#125; 手机品牌N1234567891011package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public class HandSetBrandN extends HandSetBrand &#123; @Override public void run() &#123; handSetSoft.run(); &#125;&#125; 手机品牌A1234567891011package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public class HandSetBrandA extends HandSetBrand &#123; @Override public void run() &#123; handSetSoft.run(); &#125;&#125; 测试类1234567891011121314151617181920package factory.pattern.bridge;/** * Created by FK on 2017/7/26. */public class Test &#123; public static void main(String[] args) &#123; HandSetBrand hb ; hb = new HandSetBrandA(); hb.setHandSetSoft(new HandSetGame()); hb.run(); hb.setHandSetSoft(new HandSetAdressList()); hb.run(); hb = new HandSetBrandN(); hb.setHandSetSoft(new HandSetGame()); hb.run(); hb.setHandSetSoft(new HandSetAdressList()); hb.run(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[适配器模式]]></title>
      <url>%2F20170725%2FDesign_pattern%2F8_Adapter%2F</url>
      <content type="text"><![CDATA[适配器模式介绍适配器模式讲一个类的接口转换为被期望用到的另一个接口,使得原本由于接口不兼容而不能一起工作的那些类可以在一起工作.(结构型模式) 适配器模式中的角色一般适配器模式中有以下三个角色: 目标接口(Target) : 客户期待的接口. 需要适配的类(Adaptee) : 需要适配的类. 适配器(Adapter) : 包装一个需要适配的对象,吧原接口转换为目标接口. 优点 通过适配器,客户端调用同一接口. 复用的现存的类 将目标类和适配者类解耦 缺点过多的使用适配器，会让系统非常零乱，不易整体进行把握. DEMO目标接口12345678910package factory.pattern.Adapter;/** * Created by fk5431 on 7/25/17. */public class Target &#123; public void Request()&#123; System.out.println(&quot;普通请求&quot;); &#125;&#125; 需要适配的类12345678910package factory.pattern.Adapter;/** * Created by fk5431 on 7/25/17. */public class Adaptee &#123; public void SpecificRequest()&#123; System.out.println(&quot;特殊请求&quot;); &#125;&#125; 适配器12345678910111213package factory.pattern.Adapter;/** * Created by fk5431 on 7/25/17. */public class Adapter extends Target &#123; private Adaptee adaptee = new Adaptee(); @Override public void Request() &#123; adaptee.SpecificRequest(); &#125;&#125; 测试1234567891011package factory.pattern.Adapter; /** * Created by fk5431 on 7/25/17. */ public class Test &#123; public static void main(String[] args) &#123; Target target = new Adapter(); target.Request(); &#125; &#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[原型模式]]></title>
      <url>%2F20170724%2FDesign_pattern%2F7_Prototype%2F</url>
      <content type="text"><![CDATA[原型模式介绍用原型实例制定创建对象的种类，并通过拷贝这些原型创建新的对象。（创建型模式）原型模式比较简单的一种模式，实现一个接口就完成了原型模式。一般原型模式很少单独出现，会与其他模式混用。 适用场景使用原型模式创建对象比直接new一个对象在性能上要好的多，因为Object类的clone方法是一个本地方法，它直接操作内存中的二进制流，特别是复制大对象时，性能的差别非常明显。使用原型模式的另一个好处是简化对象的创建，使得创建对象就像我们在编辑文档时的复制粘贴一样简单。因为以上优点，所以在需要重复地创建相似对象时可以考虑使用原型模式。比如需要在一个循环体内创建对象，假如对象创建过程比较复杂或者循环次数很多的话，使用原型模式不但可以简化创建过程，而且可以使系统的整体性能提高很多。 注意事项 使用原型模式复制对象不会调用类的构造方法。因为对象的复制是通过调用Object类的clone方法来完成的，它直接在内存中复制数据，因此不会调用到类的构造方法。不但构造方法中的代码不会执行，甚至连访问权限都对原型模式无效。还记得单例模式吗？单例模式中，只要将构造方法的访问权限设置为private型，就可以实现单例。但是clone方法直接无视构造方法的权限，所以，单例模式与原型模式是冲突的，在使用时要特别注意。 深拷贝与浅拷贝。Object类的clone方法只会拷贝对象中的基本的数据类型，对于数组、容器对象、引用对象等都不会拷贝，这就是浅拷贝。如果要实现深拷贝，必须将原型模式中的数组、容器对象、引用对象等另行拷贝。如果有数组等等其他对象要进行深拷贝时候：12345678910111213public class Prototype implements Cloneable &#123; private ArrayList list = new ArrayList(); public Prototype clone()&#123; Prototype prototype = null; try&#123; prototype = (Prototype)super.clone(); prototype.list = (ArrayList) this.list.clone(); &#125;catch(CloneNotSupportedException e)&#123; e.printStackTrace(); &#125; return prototype; &#125; &#125; DEMO12345678910111213141516package factory.pattern.Proto;/** * Created by FK on 2017/7/25. */public class Prototype implements Cloneable&#123; public Prototype clone()&#123; Prototype prototype = null; try &#123; prototype = (Prototype) super.clone(); &#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace(); &#125; return prototype; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[建造者模式]]></title>
      <url>%2F20170716%2FDesign_pattern%2F6_builder%2F</url>
      <content type="text"><![CDATA[建造者模式定义将一个复杂对象的构造与它的表示分离，使同样的构建过程可以创建不同的表示，这样的设计模式被称为建造者模式。(创建型模式) 使用场景1 创建一些复杂的对象时,这些对象的内部组成间的构建顺序是稳定的,但是对象的内部组成构件面临着复杂的变化。2 要创建的复杂对象的算法,独立于该对象的组成部分,也独立与组成部分的装配方法时。 优点: 使用建造者模式可以让客户端不知道产品内部的组成细节. 具体的建造类之间是相互独立的,对系统的扩展是非常有利的. 由于具体的建造者是独立的,因此可以对建造过程逐步细化,而对其他的模块没有任何影响. 建造者模式一般包含的角色 builder: 给出一个抽象接口,以规范产品对象的各个组成成分的建造.这个接口规定要实现负责对象的哪些部分的创建,不涉及具体对象部件的创建, ConcreteBuilder: 实现Builder接口,针对不同的商业逻辑,具体化复杂对象的各部分的创建.在建造过程完成后,提供产品实例. Director: 调用具体建造者来创建复杂对象的各个部分,在指导者中不涉及具体产品的信息,只负责保证对象各部分完整创建或按某顺序创建. Product: 要创建的负责对象. Demo如果要创建一个小人,肯定要创建人的头,身体,手,脚,现在系统将人分为胖人和瘦人,那么设计如下: 首先是Persion12345678910111213141516171819202122package factory.pattern.Builder;import java.util.ArrayList;import java.util.List;/** * Created by fk5431 on 7/24/17. */public class Persion &#123; private List&lt;String&gt; parts = new ArrayList&lt;String&gt;(); public void Add(String part)&#123; parts.add(part); &#125; public void Show()&#123; for(String part : parts)&#123; System.out.println(part); &#125; &#125;&#125; 然后是Builder123456789101112package factory.pattern.Builder; /** * Created by fk5431 on 7/24/17. */ public interface Builder &#123; void BuildHead(); void BuildBody(); void BuildHand(); void BuildFeet(); Persion getResult(); &#125; 然后瘦人胖人类分别实现接口123456789101112131415161718192021222324252627282930package factory.pattern.Builder;/** * Created by fk5431 on 7/24/17. */public class FatPersonBuilder implements Builder &#123; private Persion product; public FatPersonBuilder()&#123; product = new Persion(); &#125; public void BuildHead() &#123; product.Add(&quot;胖人头&quot;); &#125; public void BuildBody() &#123; product.Add(&quot;胖人身体&quot;); &#125; public void BuildHand() &#123; product.Add(&quot;胖人手&quot;); &#125; public void BuildFeet() &#123; product.Add(&quot;胖人脚&quot;); &#125; public Persion getResult() &#123; return product; &#125;&#125; 123456789101112131415161718192021222324252627282930package factory.pattern.Builder;/** * Created by fk5431 on 7/24/17. */public class ThinPersonBuilder implements Builder &#123; Persion product; public ThinPersonBuilder()&#123; product = new Persion(); &#125; public void BuildHead() &#123; product.Add(&quot;瘦人头&quot;); &#125; public void BuildBody() &#123; product.Add(&quot;瘦人身体&quot;); &#125; public void BuildHand() &#123; product.Add(&quot;瘦人手&quot;); &#125; public void BuildFeet() &#123; product.Add(&quot;瘦人脚&quot;); &#125; public Persion getResult() &#123; return product; &#125;&#125; 然后是指导者1234567891011121314package factory.pattern.Builder;/** * Created by fk5431 on 7/24/17. */public class Director &#123; public Persion Persion(Builder builder)&#123; builder.BuildBody(); builder.BuildFeet(); builder.BuildHand(); builder.BuildHead(); return builder.getResult(); &#125;&#125; 最后测试一下12345678public class Test &#123; public static void main(String[] args) &#123; Director d = new Director(); Persion p = d.Persion(new ThinPersonBuilder()); p.Show(); &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[双重检查锁定]]></title>
      <url>%2F20170620%2FDesign_pattern%2F5_double-checked-locking%2F</url>
      <content type="text"><![CDATA[双重检查锁定产生原因在写Java程序的时候,有时候会推迟高开销对象的初始化,在使用的时候在进行初始化,达到lazy loading的效果.但是进行延迟初始化的时候可能会产生很多问题(多线程环境),例如:12345678910public class UnsafeLazyLoading &#123; private static UnsafeLazyLoading unsafeLazyLoading; private UnsafeLazyLoading ()&#123;&#125; public static UnsafeLazyLoading getInstance()&#123; if( unsafeLazyLoading == null)&#123; //sign 1 unsafeLazyLoading = new UnsafeLazyLoading(); //sing 2 &#125; return unsafeLazyLoading; &#125;&#125; 就比如简单的单例模式要获取唯一的实例,如果在多线程环境下如果线程A运行到 sign 1标识的行,此时线程B运行到 sing 2标识的行,线程A就会看到需要的实例还没有被初始化,就会产生问题. 处理这个可以加同步锁,代码如下:12345678910public class UnsafeLazyLoading &#123; private static UnsafeLazyLoading unsafeLazyLoading; private UnsafeLazyLoading ()&#123;&#125; public synchronized static UnsafeLazyLoading getInstance()&#123; if( unsafeLazyLoading == null)&#123; //sign 1 unsafeLazyLoading = new UnsafeLazyLoading(); //sing 2 &#125; return unsafeLazyLoading; &#125;&#125; 但是每次在获取实例的时候都会进入同步锁,会严重影响系统的性能.所以通过双重检查锁定来实现延迟初始化,代码如下:123456789101112131415public class UnsafeLazyLoading &#123; private static UnsafeLazyLoading unsafeLazyLoading; private UnsafeLazyLoading ()&#123;&#125; public static UnsafeLazyLoading getInstance()&#123; if( unsafeLazyLoading == null)&#123; //sign 1 synchronized (UnsafeLazyLoading.class)&#123; if( unsafeLazyLoading == null)&#123; unsafeLazyLoading = new UnsafeLazyLoading(); &#125; &#125; &#125; return unsafeLazyLoading; &#125;&#125; 上面这种方法看起很好 在多个线程试图在同一时间创建对象时，会通过加锁来保证只有一个线程能创建对象。 在对象创建好之后，执行getInstance()将不需要获取锁，直接返回已创建好的对象。 但是执行到 sing1 标识的地方的时候,线程有可能unsafeLazyLoading不为空的时候,但是unsafeLazyloading引用的对象还有可能没有完成初始化的过程. ###问题根源在上述代码执行到 unsafelazyloading = new UnsafeLazyLoading(); 的时候,此时创建一个对象可分解为以下三步:1234&gt; memory = allocate(); //1：分配对象的内存空间&gt; ctorInstance(memory); //2：初始化对象&gt; instance = memory; //3：设置instance指向刚分配的内存地址 &gt; 上面三行伪代码中的2和3之间，可能会被重排序（在一些JIT编译器上，这种重排序是真实发生的，详情见参考文献1的“Out-of-order writes”部分）。2和3之间重排序之后的执行时序如下：12345&gt; memory = allocate(); //1：分配对象的内存空间&gt; instance = memory; //3：设置instance指向刚分配的内存地址&gt; //注意，此时对象还没有被初始化！&gt; ctorInstance(memory); //2：初始化对象&gt; 根据《The Java Language Specification, Java SE 7 Edition》（后文简称为java语言规范），所有线程在执行java程序时必须要遵守intra-thread semantics。intra-thread semantics保证重排序不会改变单线程内的程序执行结果。换句话来说，intra-thread semantics允许那些在单线程内，不会改变单线程程序执行结果的重排序。上面三行伪代码的2和3之间虽然被重排序了，但这个重排序并不会违反intra-thread semantics。这个重排序在没有改变单线程程序的执行结果的前提下，可以提高程序的执行性能。为了更好的理解intra-thread semantics，请看下面的示意图（假设一个线程A在构造对象后，立即访问这个对象）：只要保证2排在4的前面，即使2和3之间重排序了，也不会违反intra-thread semantics。但是在多线程执行并发的时候示意图如下:由于单线程内要遵守intra-thread semantics，从而能保证A线程的程序执行结果不会被改变。但是当线程A和B按上图的时序执行时，B线程将看到一个还没有被初始化的对象。所以在双重检查锁定代码的（unsafeLazyLoading = new UnsafeLazyLoading(); ）如果发生重排序，另一个并发执行的线程B就有可能在第4行判断instance不为null。线程B接下来将访问instance所引用的对象，但此时这个对象可能还没有被A线程初始化！下面是这个场景的具体执行时序： 时间 线程A 线程B t1 A1：分配对象的内存空间 t2 A3：设置instance指向内存空间 t3 B1：判断instance是否为空 t4 B2：由于instance不为null，线程B将访问instance引用的对象 t5 A2：初始化对象 t6 A4：访问instance引用的对象 这里A2和A3虽然重排序了，但java内存模型的intra-thread semantics将确保A2一定会排在A4前面执行。因此线程A的intra-thread semantics没有改变。但A2和A3的重排序，将导致线程B在B1处判断出instance不为空，线程B接下来将访问instance引用的对象。此时，线程B将会访问到一个还未初始化的对象。 在知晓了问题发生的根源之后，我们可以想出两个办法来实现线程安全的延迟初始化： 不允许2和3重排序； 允许2和3重排序，但不允许其他线程“看到”这个重排序。 以上引用内容来自 http://ifeve.com/double-checked-locking-with-delay-initialization/ 解决方案基于volatile的双重检定只需要把要获取的实例unsafeLazyLoading声明为volatile就可以,如下:123456789101112131415public class UnsafeLazyLoading &#123; private volatile static UnsafeLazyLoading unsafeLazyLoading; private UnsafeLazyLoading ()&#123;&#125; public static UnsafeLazyLoading getInstance()&#123; if( unsafeLazyLoading == null)&#123; //sign 1 synchronized (UnsafeLazyLoading.class)&#123; if( unsafeLazyLoading == null)&#123; unsafeLazyLoading = new UnsafeLazyLoading(); &#125; &#125; &#125; return unsafeLazyLoading; &#125;&#125; 当声明对象的引用为volatile后，上述说到的2和3之间的重排序，在多线程环境中将会被禁止。 基于类初始化 JVM在类的初始化阶段（即在Class被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。因此就可以采用静态内部类的形式实现延迟加载的效果,像上一篇文章最后的代码一样.1234567891011121314package factory.pattern.singleton;/** * Created by fk5431 on 6/19/17. */public class SingletonStaticClass &#123; //静态内部类 private static class SingletonHodler&#123; private static final SingletonStaticClass INSTANCE = new SingletonStaticClass(); &#125; private SingletonStaticClass()&#123;&#125; public static final SingletonStaticClass getInstance()&#123; return SingletonHodler.INSTANCE; &#125;&#125; 这样虽然允许了上述的2,3之间的重排序,但是非构造线程无法被重排序所影响.]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[单例模式]]></title>
      <url>%2F20170619%2FDesign_pattern%2F4_singleton-pattern%2F</url>
      <content type="text"><![CDATA[单例模式定义一个类有且仅有一个实例，并且自行实例化向整个系统提供。(创建型模式)设计模式中比较简单的几种之一,单例模式就是让一个类在系统运行过程中只会产生唯一的一个实例,单例模式主要: 单例类只能有一个实例。 单例类必须自己创建自己的唯一实例。 单例类必须给所有其他对象提供这一实例。 使用场景 需要频繁实例化然后销毁的对象。 创建对象时耗时过多或者耗资源过多，但又经常用到的对象。 有状态的工具类对象。 频繁访问数据库或文件的对象。 单例模式的实现单例模式的实现一般根据实例化对象时的不同分为懒汉式和饿汉式. 懒汉式典型实现1234567891011121314package factory.pattern.singleton;/** * Created by fk5431 on 6/19/17. */public class SingletonLazy &#123; private static SingletonLazy singletonLazy; private SingletonLazy ()&#123;&#125; public static SingletonLazy getInstance()&#123; if( singletonLazy == null)&#123; singletonLazy = new SingletonLazy(); &#125; return singletonLazy; &#125;&#125; 懒汉式的模式就是在需要进行实例化的时候在进行实例化,这种方式在多线程的时候是有问题的,会有线程安全问题. 懒汉式线程安全形式1234567891011121314package factory.pattern.singleton;/** * Created by fk5431 on 6/19/17. */public class SingletonLazeSafe &#123; private static SingletonLazeSafe singletonLazeSafe; private SingletonLazeSafe()&#123;&#125; public static synchronized SingletonLazeSafe getInstance()&#123; if(singletonLazeSafe == null)&#123; singletonLazeSafe = new SingletonLazeSafe(); &#125; return singletonLazeSafe; &#125;&#125; 懒汉式的线程安全模式在进入获取实例方法时候就会加synchronize,可以保证线程安全获取唯一的实例,但是如果该方法调用过多会有性能方面的影响. 饿汉式1234567891011package factory.pattern.singleton;/** * Created by fk5431 on 6/19/17. */public class SingletonHungary &#123; private static SingletonHungary singletonHungary = new SingletonHungary(); private SingletonHungary()&#123;&#125; public static SingletonHungary getInstance()&#123; return singletonHungary; &#125;&#125; 饿汉式会在类装载时候就进行实例的初始化,虽然没有了synchronize的效率影响,但是在类加载的时候就进行了初始化一方面浪费了内存,也没有实现lazy loading加载的效果. 双重校验锁123456789101112131415161718package factory.pattern.singleton;/** * Created by fk5431 on 6/19/17. */public class DoubleCheckedLocking &#123; private static DoubleCheckedLocking doubleCheckedLocking; private DoubleCheckedLocking()&#123;&#125; public DoubleCheckedLocking getInstance()&#123; if(doubleCheckedLocking == null)&#123; synchronized (DoubleCheckedLocking.class)&#123; if(doubleCheckedLocking == null)&#123; doubleCheckedLocking = new DoubleCheckedLocking(); &#125; &#125; &#125; return doubleCheckedLocking; &#125;&#125; 这种方式采用了双锁机制,一方面保证了多线程的安全,另一方面还提高了效率.但是看起来是完美,但是实际上这种方式是有缺陷的,是错误的一种.(双重检查锁定的问题下次专门写个文章) 静态内部类1234567891011121314package factory.pattern.singleton;/** * Created by fk5431 on 6/19/17. */public class SingletonStaticClass &#123; //静态内部类 private static class SingletonHodler&#123; private static final SingletonStaticClass INSTANCE = new SingletonStaticClass(); &#125; private SingletonStaticClass()&#123;&#125; public static final SingletonStaticClass getInstance()&#123; return SingletonHodler.INSTANCE; &#125;&#125; 这种方式利用了 classloder 机制来保证初始化 instance 时只有一个线程,但是这个是类装载的时候不一定会进行初始化,只有在调用 getInstance 方法时候才会显示的装载SingletonHodler,然后实例化instance. 枚举的方式123public enum EnumSingleton &#123; INSTANCE;&#125; 枚举的方式最简单，又是线程安全的（默认枚举实例的创建是线程安全的）]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[抽象工厂模式]]></title>
      <url>%2F20170618%2FDesign_pattern%2F3_abstract-factory-pattern%2F</url>
      <content type="text"><![CDATA[抽象工厂模式介绍为创建一组相关或相互依赖的对象提供一个接口，而且无需指定他们的具体类。（创建型模式） 和工厂模式区别工厂模式提供一个产品的结构，而抽象工厂模式提供多个产品的结构，可以组成一个产品族。 QQ换皮肤可以使用抽象工厂模式 优点：当一个产品族中的多个对象被设计成一起工作时，它能保证客户端始终只使用同一个产品族中的对象。缺点：扩展非常麻烦，需要修改很多代码。 DEMO可以在前一个例子上给图形增加颜色，就相当于一个产品族了： 先创建一个图形和颜色的接口类： 12345678package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public interface Color &#123; void fill();&#125; 12345678package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public interface Shape &#123; void draw();&#125; 然后分别实现各自两个类进行测试： 1234567891011package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class Black implements Color &#123; @Override public void fill() &#123; System.out.println(&quot;Black : fill()&quot;); &#125;&#125; 1234567891011package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class Red implements Color &#123; @Override public void fill() &#123; System.out.println(&quot;Red : fill()&quot;); &#125;&#125; 1234567891011package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Circle : draw()&quot;); &#125;&#125; 1234567891011package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Rectangle : draw()&quot;); &#125;&#125; 然后实现工厂抽象类： 123456789package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public abstract class AbstractFactory &#123; abstract Color getColorFactory(String color); abstract Shape getShapeFactory(String shape);&#125; 然后扩展工厂抽象类： 12345678910111213141516171819202122232425package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class ShapeFactory extends AbstractFactory &#123; @Override Color getColorFactory(String color) &#123; return null; &#125; @Override Shape getShapeFactory(String shape) &#123; if(shape == null) &#123; return null; &#125; if (&quot;rectangle&quot;.equals(shape))&#123; return new Rectangle(); &#125;else if (&quot;circle&quot;.equals(shape))&#123; return new Circle(); &#125;else &#123; return null; &#125; &#125;&#125; 12345678910111213141516171819202122232425package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class ColorFactory extends AbstractFactory &#123; @Override Color getColorFactory(String color) &#123; if(color == null) &#123; return null; &#125; if(&quot;red&quot;.equals(color))&#123; return new Red(); &#125;else if(&quot;black&quot;.equals(color))&#123; return new Black(); &#125;else &#123; return null; &#125; &#125; @Override Shape getShapeFactory(String shape) &#123; return null; &#125;&#125; 然后写一个工厂创造器：123456789101112131415package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class FactoryProducer &#123; public static AbstractFactory getFactory(String choice)&#123; if(choice.equalsIgnoreCase(&quot;shape&quot;))&#123; return new ShapeFactory(); &#125; else if(choice.equalsIgnoreCase(&quot;color&quot;))&#123; return new ColorFactory(); &#125; return null; &#125;&#125; 最后写一个测试类来试试输出：123456789101112131415161718192021package factory.pattern.abs;/** * Created by FK on 2017/6/18. */public class AbstractFactoryPattern &#123; public static void main(String[] args) &#123; AbstractFactory shapeFactory = FactoryProducer.getFactory(&quot;shape&quot;); Shape shape1 = shapeFactory.getShapeFactory(&quot;circle&quot;); shape1.draw(); Shape shape2 = shapeFactory.getShapeFactory(&quot;rectangle&quot;); shape2.draw(); AbstractFactory colorFactory = FactoryProducer.getFactory(&quot;color&quot;); Color color1 = colorFactory.getColorFactory(&quot;red&quot;); color1.fill(); Color color2 = colorFactory.getColorFactory(&quot;black&quot;); color2.fill(); &#125;&#125; 输出如果如下:1234Circle : draw()Rectangle : draw()Red : fill()Black : fill()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式——工厂模式]]></title>
      <url>%2F20170617%2FDesign_pattern%2F2_factory_pattern%2F</url>
      <content type="text"><![CDATA[工厂模式介绍定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。（创建型模式） 使用场景例如orm框架，在选择数据库的时候只需要替换方言和驱动，不需要对已经实现的具体细节进行改动。 优点：使用工厂模式可以屏蔽具体实现，只需要关心接口的调用；在增加一个产品的时候，只需要在工厂类里扩展一个产品就可以。 缺点：每增加产品就必须增加具体实现类和实现工厂，增加了系统复杂性。（如果产品非常非常多，233333） DEMO工厂模式比较简单，就写个最常用的例子：图形。 12345678package factory.pattern;/** * Created by FK on 2017/6/17. */public interface Shape &#123; void draw();&#125; 创建 shape抽象类 1234567891011package factory.pattern;/** * Created by FK on 2017/6/17. */public class Rectangle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Rectangle : draw()&quot;); &#125;&#125; rectangle实现shape方法 123456789101112package factory.pattern;/** * Created by FK on 2017/6/17. */public class Circle implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Circle : draw()&quot;); &#125;&#125; circle实现shape方法 123456789101112package factory.pattern;/** * Created by FK on 2017/6/17. */public class Square implements Shape &#123; @Override public void draw() &#123; System.out.println(&quot;Square : draw()&quot;); &#125;&#125; square实现shape方法 12345678910111213141516171819202122package factory.pattern;/** * Created by FK on 2017/6/17. */public class ShapeFactory &#123; public Shape getShape(String shapeType)&#123; if(shapeType == null)&#123; return null; &#125; if(shapeType.equalsIgnoreCase(&quot;CIRCLE&quot;))&#123; return new Circle(); &#125; else if(shapeType.equalsIgnoreCase(&quot;RECTANGLE&quot;))&#123; return new Rectangle(); &#125; else if(shapeType.equalsIgnoreCase(&quot;SQUARE&quot;))&#123; return new Square(); &#125; return null; &#125;&#125; 创建一个工厂，生成基于给传入值的实体类的对象。 12345678910111213141516171819package factory.pattern;/** * Created by FK on 2017/6/17. */public class FactoryPattern &#123; public static void main(String[] args) &#123; ShapeFactory shapeFactory = new ShapeFactory(); Shape circle = shapeFactory.getShape(&quot;CIRCLE&quot;); //调用 Circle 的 draw 方法 circle.draw(); Shape rectangle = shapeFactory.getShape(&quot;RECTANGLE&quot;); //调用 Rectangle 的 draw 方法 rectangle.draw(); Shape square = shapeFactory.getShape(&quot;SQUARE&quot;); //调用 Square 的 draw 方法 square.draw(); &#125;&#125; 写个demo来测试下输出是否实现了工厂模式，输出如下：123Circle : draw()Rectangle : draw()Square : draw()]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[设计模式]]></title>
      <url>%2F20170616%2FDesign_pattern%2F1_start%2F</url>
      <content type="text"><![CDATA[设计模式设计模式是一套被反复使用、多数人知晓的、经过分类的、代码设计经验的总结。其实就是经过前人反复使用总结使用得出在不同场景有对应的解决方案。使用设计模式是为了重用代码、让代码更容易被他人理解、保证代码可靠性。 设计原则开闭原则模块应对扩展开放，对修改关闭，也就是在对程序进行拓展的时候，不要去修改原来的代码，实现热插拔的效果。这样可以使得程序扩展性更好，更易于维护。（主要是使用接口和抽象类实现，例如“抽象工厂模式”） 里氏替换原则任何父类出现的地方，子类一定可以出现，就是用子类替换也一定可以运行。（子类可以扩展父类但不能改变父类的功能）（里氏替换原则可以说继承复用的基础） 依赖倒转原则程序要依赖于抽象接口，不要依赖于具体实现。（开闭原则的基础）针对接口编程，依赖抽象类而不依赖具体类。 接口隔离原则使用多个隔离的接口，比使用单个接口要好。其实就降低程序之间的耦合度，增加系统的可维护性。 最少知道原则（迪米特法则）一个实体应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立。也是降低类之间的耦合度。 合成复用原则尽量使用合成/聚合的方式，而不是使用继承。某些情景下可以在一个新对象里面使用一些已有的对象达到复用的作用，而不是通过继承的方式，这样如果已有的类要进行改动就不需要对所有的类进行改动了。 设计模式的分类 创建型模式：单例模式、抽象工厂模式、建造者模式、工厂模式、原型模式。 结构型模式：适配器模式、桥接模式、装饰模式、组合模式、外观模式、享元模式、代理模式。 行为型模式：模版方法模式、命令模式、迭代器模式、观察者模式、中介者模式、备忘录模式、解释器模式、状态模式、策略模式、职责链模式、访问者模式。 J2EE模式：MVC 模式、业务代表模式、组合实体模式、数据访问对象模式、前端控制器模式、拦截过滤器模式、服务定位器模式、传输对象模式。 (图片来自菜鸟教程)]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入分析ConcurrentHashMap]]></title>
      <url>%2F20170503%2Fjava%2F1_concurrentHashMap%2F</url>
      <content type="text"><![CDATA[HashMap的问题HashMap是不支持并发操作的，多线程情况下HashMap可能会导致死循环的发生，导致CPU占用率达到100%。 Hash表的数据结构HashMap通常会用一个指针数组（假设为table[]）来做分散所有的key，当一个key被加入时，会通过Hash算法通过key算出这个数组的下标i，然后就把这个插到table[i]中，如果有两个不同的key被算在了同一个i，那么就叫冲突，又叫碰撞，这样会在table[i]上形成一个链表。如果table[] 大小很小，那么要放入更多的元素的时候，产生的碰撞就会非常频繁，这样会影响Hash表的性能。所以，hash表的容量非常重要，如果有元素要插入时候，如果超过了设定的threshold，那么就必须增大hash表的大小，hash表的每个元素就必须重新被计算一边，也就是rehash。 HashMap的源码12345678910111213141516171819202122232425public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); //计算Hash值 int hash = hash(key); int i = indexFor(hash, table.length); //如果存在值，替换旧值 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; //增加节点 addEntry(hash, key, value, i); return null;&#125; 上面代码是HashMap进行put一个元素时候的源码。 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; //如果大小大于现在的threshold时候，需要resize if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125; 在增加节点时候会判断是否需要rehash操作。 1234567891011121314 void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; //新建一个Hash Table Entry[] newTable = new Entry[newCapacity]; //吧旧oldtable 迁移到新的newTable上 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; resize源码会新建个更大的hash表 12345678910111213141516void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 从OldTable里摘一个元素出来，然后放到NewTable中 for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 迁移源代码 正常ReHash过程就像代码中一样，新建一个新的table容量比oldtale要大，然后将oldtable中元素迁移到newtable中，在单线程下这样没什么问题。 并发下的Rehash假设有两个线程，当第一个线程执行到1Entry&lt;K, V&gt; next = e.next; 时候被挂起。1234假设有三个值， &lt;3,a&gt;,&lt;7,b&gt;,&lt;5,c&gt;,HashMap的初始大小是2 ______ e next|__0___| _______ _______ _______ |__1___| ---&gt; |_&lt;3,a&gt;_| -----&gt; |_&lt;7,b&gt;_| -----&gt; |_&lt;5,c&gt;_| 那么现在线程1如下：12345 ______ |__0___| |__1___| |__2___| |__3___| 那么线程2开始rehash：123456 ______ |__0___| _______|__1___| ----------&gt; |_&lt;5,c&gt;_| ---------&gt; null |__2___| _______ _______ |__3___| ---&gt; |_&lt;7,b&gt;_| -----&gt; |_&lt;3,a&gt;_| ----&gt; null next e 那么如果现在线程1被调度开始执行：12newTable[i] = e;e = next; 先是执行 newTalbe[i] = e; 然后是e = next，导致了e指向了key(7)， 而下一次循环的next = e.next导致了next指向了key(3)123456 ______ |__0___| _______|__1___| ----------&gt; |_&lt;5,c&gt;_| ---------&gt; null |__2___| _______ _______ |__3___| ---&gt; |_&lt;7,b&gt;_| -----&gt; |_&lt;3,a&gt;_| ----&gt; null e next 这样就会导致123456线程1 ______ |__0___| __________________ |__1___| | | |__2___| ___|___ ____|__ |__3___| ---&gt; |_&lt;3,a&gt;_| -----&gt; |_&lt;7,b&gt;_| ----&gt; null 产生循环链表，导致死循环。 concurrentHashMap原理concurrentHashMap采用锁分段技术：假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 HashEntry源码:12345static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next; volatile关键字保证了多线程读取的时候一定是最新值。 ConcurrentHashMap包含一个Segment数组,每个Segment包含一个HashEntry数组,当修改HashEntry数组采用开链法处理冲突,所以它的每个HashEntry元素又是链表结构的元素。 基本操作源码分析构造方法:1234567891011121314151617181920212223242526272829public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; //1 int sshift = 0; int ssize = 1; while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; //2 &#125; this.segmentShift = 32 - sshift; //3 this.segmentMask = ssize - 1; //4 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]);//5 Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; //6 UNSAFE.putOrderedObject(ss, SBASE, s0); this.segments = ss;&#125; 整个初始化是通过参数initialCapacity(初始容量)，loadFactor(增长因子)和concurrencyLevel(并发等级)来初始化segmentShift（段偏移量）、segmentMask（段掩码）和segment数组。 注释1: 最大的并发等级不能超过MAX_SEGMENTS 1&lt;&lt;16(也就是1的二进制向左移16位,65535) 注释2: 如果你传入的是15 就是向上取2的4次方倍 也就是16. 注释3和4: segmentShift和segmentMask在定位segment使用，segmentShift = 32 - ssize向左移位的次数，segmentMask = ssize - 1。ssize的最大长度是65536，对应的 segmentShift最大值为16，segmentMask最大值是65535，对应的二进制16位全为1； 注释5和6: 初始化segment 初始化每个segment的HashEntry长度； 创建segment数组和segment[0]。 HashEntry长度cap同样也是2的N次方，默认情况，ssize = 16，initialCapacity = 16，loadFactor = 0.75f，那么cap = 1，threshold = (int) cap * loadFactor = 0。 get操作1234567891011121314151617public V get(Object key) &#123; Segment&lt;K,V&gt; s; HashEntry&lt;K,V&gt;[] tab; int h = hash(key); //1 long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; //2 (tab = s.table) != null) &#123; for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; 注释1: 根据key计算hash值 注释2: 根据计算出的hash值定位segment 如果segment不为null segment.table也不为null 跳转进里面的循环 里面的一大段东西 大致讲的就是通过hash值定位segment中对应的HashEntry 遍历HashEntry,如果key存在,返回key对应的value 如果不存在则返回null put操作1234567891011public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) s = ensureSegment(j); return s.put(key, hash, value, false);&#125; 判断值是否为null 计算hash值 定位segment 如果不存在，则创建 调用segment的put方法 还有一个putifAbsent的方法 ,唯一的不同就是最后的false变为了true再来看看Segment的put方法12345678910111213141516171819202122232425262728293031323334353637383940414243final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); //1 V oldValue; try &#123; HashEntry&lt;K,V&gt;[] tab = table; int index = (tab.length - 1) &amp; hash; HashEntry&lt;K,V&gt; first = entryAt(tab, index); //2 for (HashEntry&lt;K,V&gt; e = first;;) &#123; //3 if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; e.value = value; ++modCount; &#125; break; &#125; e = e.next; &#125; else &#123; if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue;&#125; 注释1: 获取锁 ，保证线程安全 注释2:定位到具体的HashEntry 注释3: 遍历HashEntry链表,如果key已存在 再判断传入的onlyIfAbsent的值 ,再决定是否覆盖旧值. 最后释放锁,返回旧值. 再说明一下put 和 putifAbsent的用法 这两个方法本身是线程安全的,但是要看你的用法是否恰当 例子:12345678910private static ConcurrentHashMap&lt;String,AtomicInteger&gt; map = new ConcurrentHashMap&lt;&gt;();public static void putInTo(String key) &#123; AtomicInteger obj = map.get(key); if(obj == null)&#123; map.put(key, new AtomicInteger(0)); &#125;else&#123; obj.incrementAndGet(); map.put(key, obj); &#125;&#125; 这段代码可以用最开始提供的测试代码进行测试，会发现如果多个线程调用putInTo方法 最后值会确定不了,每一次都是不一样。 就算是保证原子性的AtomicInteger 也会有误差,可能误差比较小罢了。这个误差的出现就会出现在前几次的操作。 原因: 多个线程同时进入putInTo 比如线程1已经把不存在的键值对存入,而线程2还没完成操作 再继续存入key相同的键值对,从而覆盖了前面存入的数据,导致数据丢失。 这段代码就能保证线程安全 而不用通过synchronized关键字来锁定方法12345678910111213private static ConcurrentMap&lt;String, AtomicLong&gt; wordCounts = newConcurrentHashMap&lt;&gt;(); public static long increase(String word) &#123; AtomicLong number = wordCounts.get(word); if(number == null) &#123; AtomicLong newNumber = newAtomicLong(0); number = wordCounts.putIfAbsent(word, newNumber); if(number == null) &#123; number = newNumber; &#125; &#125; return number.incrementAndGet(); &#125; 获取size12345678910111213141516171819202122232425262728293031323334353637public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; int size; boolean overflow; long sum; long last = 0L; int retries = -1; try &#123; for (;;) &#123; if (retries++ == RETRIES_BEFORE_LOCK) &#123; //1 for (int j = 0; j &lt; segments.length; ++j) ensureSegment(j).lock(); &#125; sum = 0L; size = 0; overflow = false; for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; //2 int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; return overflow ? Integer.MAX_VALUE : size;&#125; 注释1 : RETRIES_BEFORE_LOCK为不变常量2 尝试两次不锁住Segment的方式来统计每个Segment的大小,如果在统计的过程中Segment的count发生变化,这时候再加锁统计Segment的count]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[深入理解volatile]]></title>
      <url>%2F20170502%2Fjava%2F2_volatile%2F</url>
      <content type="text"><![CDATA[java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。java语言提供了volatile，在某些情况下比锁更加方便。如果一个字段被声明成volatile，java线程内存模型确保所有线程看到这个变量的值是一致的。 VolatileVolatile变量具有synchronized的可见性特性，但是不具备原子性。线程可以自动发现volatile变量的最新值，volatile可以用于线程安全，但是只能作用于很有限的一组用例：多个变量之间或者某个变量的当前值与修改后值之间没有约束。 正确使用volatile变量的条件如果说要想使用volatile变量来替代锁，保证线程安全，必须满足一下两个条件： 该变量的写操作不依赖当前值 该变量没有包含在具有其他变量的不变式中 大多数的编程情况都于这两个条件其中之一冲突，所以计数器、互斥锁或任何具有多个变量相关的不定式不能单独用volatile解决。 使用volatile和不用volatile的一个例子jdk版本：jdk1.7.0_412345678910111213141516171819202122232425262728293031323334package com.fk.Thread;/** * Created by fengkai on 02/05/17. */public class VolatileTest &#123; private static boolean flag ; public static void main(String[] args) throws InterruptedException &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; if (flag == !flag) &#123; System.out.println(&quot;end !&quot;); System.exit(1); &#125; &#125; &#125; &#125;).start(); Thread.sleep(1); new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; flag = !flag; &#125; &#125; &#125;).start(); &#125;&#125; 运行后程序会进入死循环，一直运行。 在当前的Java内存模型下，线程可以把变量保存在本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。 12345678910111213141516171819202122232425262728293031323334package com.fk.Thread;/** * Created by fengkai on 02/05/17. */public class VolatileTest &#123; private static volatile boolean flag ; public static void main(String[] args) throws InterruptedException &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; if (flag == !flag) &#123; System.out.println(&quot;end !&quot;); System.exit(1); &#125; &#125; &#125; &#125;).start(); Thread.sleep(1); new Thread(new Runnable() &#123; @Override public void run() &#123; for(;;) &#123; flag = !flag; &#125; &#125; &#125;).start(); &#125;&#125; 程序输出end，然后马上退出。 把该变量声明为volatile（不稳定的），这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。一般说来，多任务环境下各任务间共享的标志都应该加volatile修饰。 正确使用volatile的模式状态标志也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 1234567891011volatile boolean shutdownRequested;...public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 这样使用volatiile简化了编码。这种类型标记通常只有一个状态转换，然后程序停止。 用于一次安全的发布缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原语值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值（由另一个线程写入）和该对象状态的旧值同时存在。（这就是造成著名的双重检查锁定（double-checked-locking）问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象）。实现安全发布对象的一种技术就是将对象引用定义为 volatile 类型。下面一个示例，其中后台线程在启动阶段从数据库加载一些数据。其他代码在能够利用这些数据时，在使用之前将检查这些数据是否曾经发布过。12345678910111213141516171819public class BackgroundFloobleLoader &#123; public volatile Flooble theFlooble; public void initInBackground() &#123; // do lots of stuff theFlooble = new Flooble(); // this is the only write to theFlooble &#125;&#125;public class SomeOtherClass &#123; public void doWork() &#123; while (true) &#123; // do some stuff... // use the Flooble, but only if it is ready if (floobleLoader.theFlooble != null) doSomething(floobleLoader.theFlooble); &#125; &#125;&#125; 如果 theFlooble 引用不是 volatile 类型，doWork() 中的代码在解除对 theFlooble 的引用时，将会得到一个不完全构造的 Flooble。该模式的一个必要条件是：被发布的对象必须是线程安全的，或者是有效的不可变对象（有效不可变意味着对象的状态在发布之后永远不会被修改）。volatile 类型的引用可以确保对象的发布形式的可见性，但是如果对象的状态在发布后将发生更改，那么就需要额外的同步。 独立观察模式安全使用 volatile 的另一种简单模式是：定期 “发布” 观察结果供程序内部使用。例如，假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的 volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。使用该模式的另一种应用程序就是收集程序的统计信息。下面展示了身份验证机制如何记忆最近一次登录的用户的名字。将反复使用 lastUser 引用来发布值，以供程序的其他部分使用。 12345678910111213public class UserManager &#123; public volatile String lastUser; public boolean authenticate(String user, String password) &#123; boolean valid = passwordIsValid(user, password); if (valid) &#123; User u = new User(); activeUsers.add(u); lastUser = user; &#125; return valid; &#125;&#125; 该模式是前面模式的扩展；将某个值发布以在程序内的其他地方使用，但是与一次性事件的发布不同，这是一系列独立事件。这个模式要求被发布的值是有效不可变的 —— 即值的状态在发布后不会更改。使用该值的代码需要清楚该值可能随时发生变化。 volatile bean 模式volatile bean 模式适用于将 JavaBeans 作为“荣誉结构”使用的框架。在 volatile bean 模式中，JavaBean 被用作一组具有 getter 和 setter 方法 的独立属性的容器。volatile bean 模式的基本原理是：很多框架为易变数据的持有者（例如 HttpSession）提供了容器，但是放入这些容器中的对象必须是线程安全的。在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。（这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义）。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性。下面的示例展示了遵守 volatile bean 模式的 JavaBean：12345678910111213141516171819202122@ThreadSafepublic class Person &#123; private volatile String firstName; private volatile String lastName; private volatile int age; public String getFirstName() &#123; return firstName; &#125; public String getLastName() &#123; return lastName; &#125; public int getAge() &#123; return age; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 开销较低的读－写锁策略目前为止，了解了 volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作（读、添加、存储）的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。然而，如果读操作远远超过写操作，您可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。下面显示的线程安全的计数器使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。123456789101112@ThreadSafepublic class CheesyCounter &#123; // Employs the cheap read-write lock trick // All mutative operations MUST be done with the &apos;this&apos; lock held @GuardedBy(&quot;this&quot;) private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; 之所以将这种技术称之为 “开销较低的读－写锁” 是因为您使用了不同的同步机制进行读写操作。因为本例中的写操作违反了使用 volatile 的第一个条件，因此不能使用 volatile 安全地实现计数器 —— 您必须使用锁。然而，您可以在读操作中使用 volatile 确保当前值的可见性，因此可以使用锁进行所有变化的操作，使用 volatile 进行只读操作。其中，锁一次只允许一个线程访问值，volatile 允许多个线程执行读操作，因此当使用 volatile 保证读代码路径时，要比使用锁执行全部代码路径获得更高的共享度 —— 就像读－写操作一样。然而，要随时牢记这种模式的弱点：如果超越了该模式的最基本应用，结合这两个竞争的同步机制将变得非常困难。 性能考虑使用 volatile 变量的主要原因是其简易性：在某些情形下，使用 volatile 变量要比使用相应的锁简单得多。使用 volatile 变量次要原因是其性能：某些情况下，volatile 变量同步机制的性能要优于锁。很难做出准确、全面的评价，例如 “X 总是比 Y 快”，尤其是对 JVM 内在的操作而言。（例如，某些情况下 VM 也许能够完全删除锁机制，这使得我们难以抽象地比较 volatile 和 synchronized 的开销。）就是说，在目前大多数的处理器架构上，volatile 读操作开销非常低 —— 几乎和非 volatile 读操作一样。而 volatile 写操作的开销要比非 volatile 写操作多很多，因为要保证可见性需要实现内存界定（Memory Fence），即便如此，volatile 的总开销仍然要比锁获取低。volatile 操作不会像锁一样造成阻塞，因此，在能够安全使用 volatile 的情况下，volatile 可以提供一些优于锁的可伸缩特性。如果读操作的次数要远远超过写操作，与锁相比，volatile 变量通常能够减少同步的性能开销。 学习资料 ： Java 理论与实践: 正确使用 Volatile 变量]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo初步使用]]></title>
      <url>%2F20170417%2Fstart%2F</url>
      <content type="text"><![CDATA[HexoHexo是一个可以快速搭建博客的框架，使用Markdown解析文章，生成静态的网页。（可以部署在github上哦） hexo的安装hexo只依赖于 Node.js Git 上面的两个的安装就不说了，自行百度，hexo基于上述环境可以使用nmp安装 1npm install -g hexo-cli hexo的基本命令 hexo init [folder] #新建一个网站 hexo n [layout] #新建一篇文章 hexo g #生成静态文件 hexo d #部署网站。 hexo publish [layout] #发表草稿 hexo s #启动服务器 hexo clean #清除缓存文件 (db.json) 和已生成的静态文件 (public) hexo的配置配置内容来自官网 网站 参数 描述 title 网站标题 subtitle 网站副标题 description 网站描述 author 您的名字 language 网站使用的语言 timezone 网站时区。Hexo 默认使用您电脑的时区。时区列表。比如说：America/New_York, Japan, 和 UTC 。 其中，description主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词。author参数用于主题显示文章的作者。 网址 参数 描述 默认值 url 网址 root 网站根目录 permalink 文章的 永久链接 格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 网站存放在子目录如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/。 目录 参数 描述 默认值 source_dir 资源文件夹，这个文件夹用来存放内容。 source public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。 public tag_dir 标签文件夹 tags archive_dir 归档文件夹 archives category_dir 分类文件夹 categories code_dir Include code 文件夹 downloads/code i18n_dir 国际化（i18n）文件夹 :lang skip_render 跳过指定文件的渲染，您可使用 glob 表达式来匹配路径。 提示如果您刚刚开始接触Hexo，通常没有必要修改这一部分的值。 文章 参数 描述 默认值 new_post_name 新文章的文件名称 :title.md _layout 预设布局 post auto_spacing 在中文和英文之间加入空格 false titlecase 把标题转换为 title case false external_link 在新标签中打开链接 true filename_case 把文件名称转换为 (1) 小写或 (2) 大写 0 render_drafts 显示草稿 false post_asset_folder 启动 Asset 文件夹 false relative_link 把链接改为与根目录的相对位址 false future 显示未来的文章 true highlight 代码块的设置 相对地址默认情况下，Hexo生成的超链接都是绝对地址。例如，如果您的网站域名为example.com,您有一篇文章名为hello，那么绝对链接可能像这样：http://example.com/hello.html，它是绝对于域名的。相对链接像这样：/hello.html，也就是说，无论用什么域名访问该站点，都没有关系，这在进行反向代理时可能用到。通常情况下，建议使用绝对地址。 分类 &amp; 标签 参数 描述 默认值 default_category 默认分类 uncategorized category_map 分类别名 tag_map 标签别名 日期 / 时间格式Hexo 使用 Moment.js 来解析和显示时间。 参数 描述 默认值 date_format 日期格式 YYYY-MM-DD time_format 时间格式 H:mm:ss 分页 参数 描述 默认值 per_page 每页显示的文章量 (0 = 关闭分页功能) 10 pagination_dir 分页目录 page 扩展 参数 描述 theme 当前主题名称。值为false时禁用主题 deploy 部署部分的设置 ###我的坑我吧整个hexo init初始化的项目放到github个人blog下……然后github就说解析不了博客了……然后想了想，我把master分支放hexo生成的public里面的东西，然后新建个分支放hexo的东西，这样就可以在哪里有环境就可以写，然后！！在编译器clone自己的项目，不能在同一个项目文件夹写完然后复制public的文件放到master分支，这样hexo的命令就用不了了，提示加载不到一个模块。最后吧一个项目clone两次，一个专门该mater分支，一个写…………坑了一上午]]></content>
    </entry>

    
  
  
</search>
